<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Spark SQL"><meta name=author content="Jacek Laskowski"><link href=https://books.japila.pl/spark-sql-internals/configuration-properties/ rel=canonical><link href=../common-table-expressions/ rel=prev><link href=../connector/expressions/ rel=next><link rel=icon href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.0, mkdocs-material-9.5.19+insiders-4.53.8"><title>Configuration Properties - The Internals of Spark SQL</title><link rel=stylesheet href=../assets/stylesheets/main.d5b5f0fd.min.css><link rel=stylesheet href=../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-4DR1Q2HBMZ"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-4DR1Q2HBMZ",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-4DR1Q2HBMZ",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#configuration-properties class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="The Internals of Spark SQL" class="md-header__button md-logo" aria-label="The Internals of Spark SQL" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> The Internals of Spark SQL </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Configuration Properties </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=blue data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/japila-books/spark-sql-internals title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-sql-internals </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8h5Z"/></svg> Spark SQL </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../features/ class=md-tabs__link> Features </a> </li> <li class=md-tabs__item> <a href=../query-execution/ class=md-tabs__link> Query Execution </a> </li> <li class=md-tabs__item> <a href=../overview/ class=md-tabs__link> Internals </a> </li> <li class=md-tabs__item> <a href=../sql/ class=md-tabs__link> SQL </a> </li> <li class=md-tabs__item> <a href=../connectors/ class=md-tabs__link> Connectors </a> </li> <li class=md-tabs__item> <a href=../Column/ class=md-tabs__link> High-Level APIs </a> </li> <li class=md-tabs__item> <a href=../ui/ class=md-tabs__link> Web UI </a> </li> <li class=md-tabs__item> <a href=../demo/ class=md-tabs__link> Demo </a> </li> <li class=md-tabs__item> <a href=../AggregatingAccumulator/ class=md-tabs__link> Misc </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="The Internals of Spark SQL" class="md-nav__button md-logo" aria-label="The Internals of Spark SQL" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5Z"/></svg> </a> The Internals of Spark SQL </label> <div class=md-nav__source> <a href=https://github.com/japila-books/spark-sql-internals title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-sql-internals </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8h5Z"/></svg> <span class=md-ellipsis> Spark SQL </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../features/ class="md-nav__link "> <span class=md-ellipsis> Features </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <div class="md-nav__link md-nav__container"> <a href=../aggregations/ class="md-nav__link "> <span class=md-ellipsis> Aggregate Queries </span> </a> <label class="md-nav__link " for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Aggregate Queries </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../aggregations/AggUtils/ class=md-nav__link> <span class=md-ellipsis> AggUtils </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/AggregationIterator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregationIterator </span> </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/KVSorterIterator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KVSorterIterator </span> </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/ObjectAggregationIterator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ObjectAggregationIterator </span> </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/ObjectAggregationMap/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ObjectAggregationMap </span> </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/PhysicalAggregation/ class=md-nav__link> <span class=md-ellipsis> PhysicalAggregation </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/SortBasedAggregationIterator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SortBasedAggregationIterator </span> </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/TungstenAggregationIterator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TungstenAggregationIterator </span> </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/UnsafeFixedWidthAggregationMap/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnsafeFixedWidthAggregationMap </span> </span> </a> </li> <li class=md-nav__item> <a href=../aggregations/UnsafeKVExternalSorter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnsafeKVExternalSorter </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <div class="md-nav__link md-nav__container"> <a href=../adaptive-query-execution/ class="md-nav__link "> <span class=md-ellipsis> Adaptive Query Execution </span> </a> <label class="md-nav__link " for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> Adaptive Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../adaptive-query-execution/AQEOptimizer/ class=md-nav__link> <span class=md-ellipsis> AQEOptimizer </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/AQEUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AQEUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/AdaptiveExecutionContext/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AdaptiveExecutionContext </span> </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/AdaptiveRulesHolder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AdaptiveRulesHolder </span> </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/CostEvaluator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CostEvaluator </span> </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/ShufflePartitionsUtil/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShufflePartitionsUtil </span> </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/SimpleCostEvaluator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleCostEvaluator </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <div class="md-nav__link md-nav__container"> <a href=../bloom-filter-join/ class="md-nav__link "> <span class=md-ellipsis> Bloom Filter Join </span> </a> <label class="md-nav__link " for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> Bloom Filter Join </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../bloom-filter-join/BloomFilter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BloomFilter </span> </span> </a> </li> <li class=md-nav__item> <a href=../bloom-filter-join/BloomFilterImpl/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BloomFilterImpl </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_5> <div class="md-nav__link md-nav__container"> <a href=../bucketing/ class="md-nav__link "> <span class=md-ellipsis> Bucketing </span> </a> <label class="md-nav__link " for=__nav_2_5 id=__nav_2_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> Bucketing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../bucketing/BucketSpec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BucketSpec </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_6> <div class="md-nav__link md-nav__container"> <a href=../cache-serialization/ class="md-nav__link "> <span class=md-ellipsis> Cache Serialization </span> </a> <label class="md-nav__link " for=__nav_2_6 id=__nav_2_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_6> <span class="md-nav__icon md-icon"></span> Cache Serialization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../cache-serialization/CachedBatch/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CachedBatch </span> </span> </a> </li> <li class=md-nav__item> <a href=../cache-serialization/CachedBatchSerializer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CachedBatchSerializer </span> </span> </a> </li> <li class=md-nav__item> <a href=../cache-serialization/CachedRDDBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CachedRDDBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../cache-serialization/DefaultCachedBatchSerializer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DefaultCachedBatchSerializer </span> </span> </a> </li> <li class=md-nav__item> <a href=../cache-serialization/SimpleMetricsCachedBatch/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleMetricsCachedBatch </span> </span> </a> </li> <li class=md-nav__item> <a href=../cache-serialization/SimpleMetricsCachedBatchSerializer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleMetricsCachedBatchSerializer </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_7> <div class="md-nav__link md-nav__container"> <a href=../connector/catalog/ class="md-nav__link "> <span class=md-ellipsis> Catalog Plugin API </span> </a> <label class="md-nav__link " for=__nav_2_7 id=__nav_2_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_7_label aria-expanded=false> <label class=md-nav__title for=__nav_2_7> <span class="md-nav__icon md-icon"></span> Catalog Plugin API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../connector/catalog/CatalogExtension/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogExtension </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogHelper </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogManager/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogManager </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogPlugin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogPlugin </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/Catalogs/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Catalogs </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogV2Util/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogV2Util </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/Column/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Column </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/DelegatingCatalogExtension/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DelegatingCatalogExtension </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/FunctionCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FunctionCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/MetadataColumn/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> MetadataColumn </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/StagingTableCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> StagingTableCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/SupportsNamespaces/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsNamespaces </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/SupportsCatalogOptions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsCatalogOptions </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/TableCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/TableCatalogCapability/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableCatalogCapability </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/TableChange/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableChange </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/V2TableWithV1Fallback/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V2TableWithV1Fallback Tables </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_8> <div class="md-nav__link md-nav__container"> <a href=../columnar-execution/ class="md-nav__link "> <span class=md-ellipsis> Columnar Execution </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_8_label aria-expanded=false> <label class=md-nav__title for=__nav_2_8> <span class="md-nav__icon md-icon"></span> Columnar Execution </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_9> <div class="md-nav__link md-nav__container"> <a href=../common-table-expressions/ class="md-nav__link "> <span class=md-ellipsis> Common Table Expressions </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_9_label aria-expanded=false> <label class=md-nav__title for=__nav_2_9> <span class="md-nav__icon md-icon"></span> Common Table Expressions </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> <span class=md-typeset> Configuration Properties </span> </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> <span class=md-typeset> Configuration Properties </span> </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#spark.sql.adaptive class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.adaptive </span> </span> </a> <nav class=md-nav aria-label=spark.sql.adaptive> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> advisoryPartitionSizeInBytes </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.autoBroadcastJoinThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> autoBroadcastJoinThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> coalescePartitions.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.minPartitionSize class=md-nav__link> <span class=md-ellipsis> coalescePartitions.minPartitionSize </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.minPartitionSize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> coalescePartitions.minPartitionSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.initialPartitionNum class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> coalescePartitions.initialPartitionNum </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.parallelismFirst class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> coalescePartitions.parallelismFirst </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.customCostEvaluatorClass class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> customCostEvaluatorClass </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.fetchShuffleBlocksInBatch class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> fetchShuffleBlocksInBatch </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.forceApply class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> forceApply </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.forceOptimizeSkewedJoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> forceOptimizeSkewedJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.localShuffleReader.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> localShuffleReader.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.logLevel class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> logLevel </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> maxShuffledHashJoinLocalMapThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> nonEmptyPartitionRatioForBroadcastJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.optimizer.excludedRules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> optimizer.excludedRules </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> optimizeSkewsInRebalancePartitions.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.skewJoin.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> skewJoin.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.skewJoin.skewedPartitionFactor class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> skewJoin.skewedPartitionFactor </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> skewJoin.skewedPartitionThresholdInBytes </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.allowNamedFunctionArguments class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> allowNamedFunctionArguments </span> </span> </a> </li> <li class=md-nav__item> <a href=#autobroadcastjointhreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> autoBroadcastJoinThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#cacheserializer class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> cache.serializer </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.codegen </span> </span> </a> <nav class=md-nav aria-label=spark.sql.codegen> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.fastHashMap.capacityBit class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.fastHashMap.capacityBit </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.twolevel.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.map.twolevel.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.vectorized.enable class=md-nav__link> <span class=md-ellipsis> aggregate.map.vectorized.enable </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.twolevel.partialOnly class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.map.twolevel.partialOnly </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.hugeMethodLimit class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> hugeMethodLimit </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.fallback class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> fallback </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.join.fullOuterShuffledHashJoin.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> join.fullOuterShuffledHashJoin.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.methodSplitThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> methodSplitThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.wholeStage class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> wholeStage </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#columnvectoroffheapenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> columnVector.offheap.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#defaultcolumnenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> defaultColumn.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#exchangereuse class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> exchange.reuse </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.execution </span> </span> </a> <nav class=md-nav aria-label=spark.sql.execution> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.execution.arrow.pyspark.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> arrow.pyspark.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.arrow.pyspark.fallback.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> arrow.pyspark.fallback.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.arrow.pyspark.selfDestruct.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> arrow.pyspark.selfDestruct.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.pandas.convertToArrowArraySafely class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> pandas.convertToArrowArraySafely </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.pandas.udf.buffer.size class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> pandas.udf.buffer.size </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.rangeExchange.sampleSizePerPartition class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> rangeExchange.sampleSizePerPartition </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.removeRedundantSorts class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> removeRedundantSorts </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.replaceHashWithSortAgg class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> replaceHashWithSortAgg </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.reuseSubquery class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> reuseSubquery </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.sortBeforeRepartition class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> sortBeforeRepartition </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.usePartitionEvaluator class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> usePartitionEvaluator </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sparksqlhive class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.hive </span> </span> </a> <nav class=md-nav aria-label=spark.sql.hive> <ul class=md-nav__list> <li class=md-nav__item> <a href=#filesourcepartitionfilecachesize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> filesourcePartitionFileCacheSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#managefilesourcepartitions class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> manageFilesourcePartitions </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#inmemorycolumnarstoragepartitionpruning class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> inMemoryColumnarStorage.partitionPruning </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.optimizer </span> </span> </a> <nav class=md-nav aria-label=spark.sql.optimizer> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.optimizer.canChangeCachedPlanOutputPartitioning class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> canChangeCachedPlanOutputPartitioning </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.decorrelateInnerQuery.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> decorrelateInnerQuery.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.fallbackFilterRatio </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.pruningSideExtraFilterRatio </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.useStats class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.useStats </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.reuseBroadcastOnly </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.enableCsvExpressionOptimization class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> enableCsvExpressionOptimization </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.excludedRules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> excludedRules </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.expressionProjectionCandidateLimit class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> expressionProjectionCandidateLimit </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.expression.nestedPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> expression.nestedPruning.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.inSetConversionThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> inSetConversionThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.inSetSwitchThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> inSetSwitchThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.maxIterations class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> maxIterations </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.nestedSchemaPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> nestedSchemaPruning.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.nestedPredicatePushdown.supportedFileSources class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> nestedPredicatePushdown.supportedFileSources </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.optimizeOneRowRelationSubquery class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> optimizeOneRowRelationSubquery </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.planChangeLog.batches class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> planChangeLog.batches </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.planChangeLog.level class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> planChangeLog.level </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.planChangeLog.rules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> planChangeLog.rules </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.propagateDistinctKeys.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> propagateDistinctKeys.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.replaceExceptWithFilter class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> replaceExceptWithFilter </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.creationSideThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.creationSideThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.expectedNumItems class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.expectedNumItems </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.maxNumBits class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.maxNumBits </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.rowLevelOperationGroupFilter.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> runtime.rowLevelOperationGroupFilter.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtimeFilter.number.threshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtimeFilter.number.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtimeFilter.semiJoinReduction.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtimeFilter.semiJoinReduction.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.serializer.nestedSchemaPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> serializer.nestedSchemaPruning.enabled </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql </span> </span> </a> <nav class=md-nav aria-label=spark.sql> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.retainGroupColumns class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> retainGroupColumns </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.files class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.files </span> </span> </a> <nav class=md-nav aria-label=spark.sql.files> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.files.maxPartitionBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> maxPartitionBytes </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.maxPartitionNum class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> maxPartitionNum </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.maxRecordsPerFile class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> maxRecordsPerFile </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.minPartitionNum class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> minPartitionNum </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.openCostInBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> openCostInBytes </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.parquet class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.parquet </span> </span> </a> <nav class=md-nav aria-label=spark.sql.parquet> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.parquet.aggregatePushdown class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregatePushdown </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.columnarReaderBatchSize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> columnarReaderBatchSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.enableNestedColumnVectorizedReader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> enableNestedColumnVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.filterPushdown class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> filterPushdown </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.filterPushdown.stringPredicate class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> filterPushdown.stringPredicate </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.mergeSchema class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> mergeSchema </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.output.committer.class class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> output.committer.class </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.sources class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.sources </span> </span> </a> <nav class=md-nav aria-label=spark.sql.sources> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.sources.bucketing.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> bucketing.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.sources.commitProtocolClass class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> commitProtocolClass </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.sources.outputCommitterClass class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> outputCommitterClass </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sparksqlobjecthashaggregatesortbasedfallbackthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.objectHashAggregate.sortBased.fallbackThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownonemptylocationinctas class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowNonEmptyLocationInCTAS </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowautogeneratedaliasforview class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowAutoGeneratedAliasForView </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sessionWindow.buffer.spill.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowstarwithsingletableidentifierincount class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowStarWithSingleTableIdentifierInCount </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sessionWindow.buffer.in.memory.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcenablenestedcolumnvectorizedreader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.orc.enableNestedColumnVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzermaxiterations class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.analyzer.maxIterations </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzerfailambiguousselfjoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.analyzer.failAmbiguousSelfJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlansienabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.ansi.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcliprintheader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cli.print.header </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldebugmaxtostringfields class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.debug.maxToStringFields </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultcatalog class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.defaultCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.histogram.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessiontimezone class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.session.timeZone </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesignoredatalocality class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.ignoreDataLocality </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesvalidatepartitioncolumns class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.validatePartitionColumns </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesusev1sourcelist class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.sources.useV1SourceList </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstoreassignmentpolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.storeAssignmentPolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlthriftserverinterruptoncancel class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.thriftServer.interruptOnCancel </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlhivetablepropertylengththreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.hive.tablePropertyLengthThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcmergeschema class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.orc.mergeSchema </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbucketingautobucketedscanenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.bucketing.autoBucketedScan.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldatetimejava8apienabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.datetime.java8API.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyintervalenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.interval.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbinaryfilemaxlength class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.binaryFile.maxLength </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmapkeydeduppolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.mapKeyDedupPolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxconcurrentoutputfilewriters class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maxConcurrentOutputFileWriters </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxmetadatastringlength class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maxMetadataStringLength </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmavenadditionalremoterepositories class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maven.additionalRemoteRepositories </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxplanstringlength class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maxPlanStringLength </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladdpartitioninbatchsize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.addPartitionInBatch.size </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlscripttransformationexittimeoutinseconds class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.scriptTransformation.exitTimeoutInSeconds </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlavrocompressioncodec class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.avro.compression.codec </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbroadcasttimeout class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.broadcastTimeout </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbucketingcoalescebucketsinjoinenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.bucketing.coalesceBucketsInJoin.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcasesensitive class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.caseSensitive </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcatalogspark_catalog class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.catalog.spark_catalog </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbojoinreorderenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.joinReorder.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboplanstatsenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.planStats.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbostarschemadetection class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.starSchemaDetection </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegen class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.codegen </span> </span> </a> <nav class=md-nav aria-label=spark.sql.codegen> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.vectorized.enable class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.map.vectorized.enable </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.sortAggregate.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> aggregate.sortAggregate.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.splitAggregateFunc.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.splitAggregateFunc.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.comments class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> comments </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.factoryMode class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> factoryMode </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.useIdInClassName class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> useIdInClassName </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.maxFields class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> maxFields </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.splitConsumeFuncByOperator class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> splitConsumeFuncByOperator </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sparksqlcolumnnameofcorruptrecord class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.columnNameOfCorruptRecord </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlconstraintpropagationenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.constraintPropagation.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcsvfilterpushdownenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.csv.filterPushdown.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultsizeinbytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.defaultSizeInBytes </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldialect class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.dialect </span> </span> </a> </li> <li class=md-nav__item> <a href=#executionuseobjecthashaggregateexec class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> execution.useObjectHashAggregateExec </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignorecorruptfiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.files.ignoreCorruptFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignoremissingfiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.files.ignoreMissingFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragecompressed class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryColumnarStorage.compressed </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragebatchsize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryColumnarStorage.batchSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorytablescanstatisticsenable class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryTableScanStatistics.enable </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstorageenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryColumnarStorage.enableVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljoinprefersortmergejoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.join.preferSortMergeJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljsongeneratorignorenullfields class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.jsonGenerator.ignoreNullFields </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlleafnodedefaultparallelism class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.leafNodeDefaultParallelism </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydolooseupcast class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.doLooseUpcast </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycteprecedencepolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.ctePrecedencePolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytimeparserpolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.timeParserPolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfollowthreevaluedlogicinarrayexists class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.followThreeValuedLogicInArrayExists </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfromdaytimestringenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.fromDayTimeString.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacynotreserveproperties class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.notReserveProperties </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyaddsinglefileinaddfile class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.addSingleFileInAddFile </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyexponentliteralasdecimalenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.exponentLiteralAsDecimal.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownegativescaleofdecimal class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowNegativeScaleOfDecimal </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacybucketedtablescanoutputordering class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.bucketedTableScan.outputOrdering </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyjsonallowemptystringenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.json.allowEmptyString.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycreateemptycollectionusingstringtype class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.createEmptyCollectionUsingStringType </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowuntypedscalaudf class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowUntypedScalaUDF </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydatasetnamenonstructgroupingkeyasvalue class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacysetcommandrejectssparkcoreconfs class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.setCommandRejectsSparkCoreConfs </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytypecoerciondatetimetostringenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.typeCoercion.datetimeToString.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowhashonmaptype class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowHashOnMapType </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.parquet.datetimeRebaseModeInWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.parquet.datetimeRebaseModeInRead </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.avro.datetimeRebaseModeInWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.avro.datetimeRebaseModeInRead </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyrddapplyconf class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.rdd.applyConf </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyreplacedatabrickssparkavroenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.replaceDatabricksSparkAvro.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllimitscaleupfactor class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.limit.scaleUpFactor </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqloptimizenullawareantijoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.optimizeNullAwareAntiJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcimpl class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.orc.impl </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangeloglevel class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.planChangeLog.level </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogbatches class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.planChangeLog.batches </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogrules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.planChangeLog.rules </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpysparkjvmstacktraceenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.pyspark.jvmStacktrace.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetbinaryasstring class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.binaryAsString </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetcompressioncodec class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.compression.codec </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.enableVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndate class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.date </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndecimal class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.decimal </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96rebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.int96RebaseModeInWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetpushdowninfilterthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.pushdown.inFilterThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdownstringstartswith class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.string.startsWith </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowntimestamp class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.timestamp </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96astimestamp class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.int96AsTimestamp </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96timestampconversion class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.int96TimestampConversion </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetoutputtimestamptype class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.outputTimestampType </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrecordlevelfilterenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.recordLevelFilter.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrespectsummaryfiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.respectSummaryFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparserquotedregexcolumnnames class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parser.quotedRegexColumnNames </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpivotmaxvalues class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.pivotMaxValues </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionoptionsregex class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.redaction.options.regex </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionstringregex class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.redaction.string.regex </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.runSQLOnFiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.runSQLOnFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlselfjoinautoresolveambiguity class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.selfJoinAutoResolveAmbiguity </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsortenableradixsort class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sort.enableRadixSort </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesdefault class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.sources.default </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsfallbacktohdfs class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.fallBackToHdfs </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramnumbins class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.histogram.numBins </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsparallelfilelistinginstatscomputationenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statisticsparallelFileListingInStatsComputation.enabled* </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsndvmaxerror class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.ndv.maxError </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticspercentileaccuracy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.percentile.accuracy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticssizeautoupdateenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.size.autoUpdate.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsubexpressioneliminationenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.subexpressionElimination.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.subexpressionElimination.skipForShortcutExpr class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.subexpressionElimination.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlshufflepartitions class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.shuffle.partitions </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesfilecompressionfactor class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.fileCompressionFactor </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcespartitionoverwritemode class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.partitionOverwriteMode </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqltruncatetableignorepermissionaclenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.truncateTable.ignorePermissionAcl.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqluiretainedexecutions class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.ui.retainedExecutions </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlvariablesubstitute class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.variable.substitute </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.windowExec.buffer.in.memory.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.windowExec.buffer.spill.threshold </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_11> <div class="md-nav__link md-nav__container"> <a href=../connector/expressions/ class="md-nav__link "> <span class=md-ellipsis> Connector Expressions </span> </a> <label class="md-nav__link " for=__nav_2_11 id=__nav_2_11_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_11_label aria-expanded=false> <label class=md-nav__title for=__nav_2_11> <span class="md-nav__icon md-icon"></span> Connector Expressions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../connector/expressions/Aggregation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Aggregation Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/expressions/SortOrder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SortOrder Expression </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_12> <div class="md-nav__link md-nav__container"> <a href=../cost-based-optimization/ class="md-nav__link "> <span class=md-ellipsis> Cost-Based Optimization </span> </a> <label class="md-nav__link " for=__nav_2_12 id=__nav_2_12_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_12_label aria-expanded=false> <label class=md-nav__title for=__nav_2_12> <span class="md-nav__icon md-icon"></span> Cost-Based Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../cost-based-optimization/BasicStatsPlanVisitor/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BasicStatsPlanVisitor &mdash; Computing Statistics for Cost-Based Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/CatalogColumnStat/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogColumnStat </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/ColumnStat/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ColumnStat </span> </span> </a> </li> <li class=md-nav__item> <a href=../CommandUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CommandUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/EstimationUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EstimationUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/JoinEstimation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JoinEstimation </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/LogicalPlanStats/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LogicalPlanStats &mdash; Statistics Estimates and Query Hints of Logical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/LogicalPlanVisitor/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LogicalPlanVisitor </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/SizeInBytesOnlyStatsPlanVisitor/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SizeInBytesOnlyStatsPlanVisitor &mdash; LogicalPlanVisitor for Total Size (in Bytes) Statistic Only </span> </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/Statistics/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Statistics </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_13> <div class="md-nav__link md-nav__container"> <a href=../default-columns/ class="md-nav__link "> <span class=md-ellipsis> Default Columns </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_13_label aria-expanded=false> <label class=md-nav__title for=__nav_2_13> <span class="md-nav__icon md-icon"></span> Default Columns </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_14> <div class="md-nav__link md-nav__container"> <a href=../direct-queries-on-files/ class="md-nav__link "> <span class=md-ellipsis> Direct Queries on Files </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_14_label aria-expanded=false> <label class=md-nav__title for=__nav_2_14> <span class="md-nav__icon md-icon"></span> Direct Queries on Files </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_15> <div class="md-nav__link md-nav__container"> <a href=../dynamic-partition-pruning/ class="md-nav__link "> <span class=md-ellipsis> Dynamic Partition Pruning </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_15_label aria-expanded=false> <label class=md-nav__title for=__nav_2_15> <span class="md-nav__icon md-icon"></span> Dynamic Partition Pruning </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_16> <div class="md-nav__link md-nav__container"> <a href=../file-based-data-scanning/ class="md-nav__link "> <span class=md-ellipsis> File-Based Data Scanning </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_16_label aria-expanded=false> <label class=md-nav__title for=__nav_2_16> <span class="md-nav__icon md-icon"></span> File-Based Data Scanning </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_17> <div class="md-nav__link md-nav__container"> <a href=../generated-columns/ class="md-nav__link "> <span class=md-ellipsis> Generated Columns </span> </a> <label class="md-nav__link " for=__nav_2_17 id=__nav_2_17_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_17_label aria-expanded=false> <label class=md-nav__title for=__nav_2_17> <span class="md-nav__icon md-icon"></span> Generated Columns </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../generated-columns/GeneratedColumn/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GeneratedColumn </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_18> <div class="md-nav__link md-nav__container"> <a href=../hidden-file-metadata/ class="md-nav__link "> <span class=md-ellipsis> Hidden File Metadata </span> </a> <label class="md-nav__link " for=__nav_2_18 id=__nav_2_18_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_18_label aria-expanded=false> <label class=md-nav__title for=__nav_2_18> <span class="md-nav__icon md-icon"></span> Hidden File Metadata </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../hidden-file-metadata/MetadataAttribute/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> MetadataAttribute </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_19> <div class="md-nav__link md-nav__container"> <a href=../hints/ class="md-nav__link "> <span class=md-ellipsis> Hints (SQL) </span> </a> <label class="md-nav__link " for=__nav_2_19 id=__nav_2_19_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_19_label aria-expanded=false> <label class=md-nav__title for=__nav_2_19> <span class="md-nav__icon md-icon"></span> Hints (SQL) </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../hints/HintErrorHandler/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HintErrorHandler </span> </span> </a> </li> <li class=md-nav__item> <a href=../hints/HintInfo/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HintInfo </span> </span> </a> </li> <li class=md-nav__item> <a href=../hints/JoinHint/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JoinHint </span> </span> </a> </li> <li class=md-nav__item> <a href=../hints/JoinStrategyHint/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JoinStrategyHint </span> </span> </a> </li> <li class=md-nav__item> <a href=../hints/join-strategy-hints/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Join Strategy Hints </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_20> <label class=md-nav__link for=__nav_2_20 id=__nav_2_20_label tabindex=0> <span class=md-ellipsis> Join Queries </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_20_label aria-expanded=false> <label class=md-nav__title for=__nav_2_20> <span class="md-nav__icon md-icon"></span> Join Queries </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../joins/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Join Queries </span> </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-joins-broadcast/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Broadcast Joins </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-logging/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Logging </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_22> <div class="md-nav__link md-nav__container"> <a href=../metadata-columns/ class="md-nav__link "> <span class=md-ellipsis> Metadata Columns </span> </a> <label class="md-nav__link " for=__nav_2_22 id=__nav_2_22_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_22_label aria-expanded=false> <label class=md-nav__title for=__nav_2_22> <span class="md-nav__icon md-icon"></span> Metadata Columns </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../metadata-columns/FileSourceConstantMetadataAttribute/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileSourceConstantMetadataAttribute </span> </span> </a> </li> <li class=md-nav__item> <a href=../metadata-columns/FileSourceGeneratedMetadataAttribute/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileSourceGeneratedMetadataAttribute </span> </span> </a> </li> <li class=md-nav__item> <a href=../metadata-columns/FileSourceMetadataAttribute/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileSourceMetadataAttribute </span> </span> </a> </li> <li class=md-nav__item> <a href=../metadata-columns/MetadataColumnHelper/ class=md-nav__link> <span class=md-ellipsis> MetadataColumnHelper </span> </a> </li> <li class=md-nav__item> <a href=../metadata-columns/MetadataColumnsHelper/ class=md-nav__link> <span class=md-ellipsis> MetadataColumnsHelper </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../named-function-arguments/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Named Function Arguments </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_24> <div class="md-nav__link md-nav__container"> <a href=../parameterized-queries/ class="md-nav__link "> <span class=md-ellipsis> Parameterized Queries </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_24_label aria-expanded=false> <label class=md-nav__title for=__nav_2_24> <span class="md-nav__icon md-icon"></span> Parameterized Queries </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_25> <div class="md-nav__link md-nav__container"> <a href=../partition-file-metadata-caching/ class="md-nav__link "> <span class=md-ellipsis> Partition File Metadata Caching </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_25_label aria-expanded=false> <label class=md-nav__title for=__nav_2_25> <span class="md-nav__icon md-icon"></span> Partition File Metadata Caching </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_26> <div class="md-nav__link md-nav__container"> <a href=../connect/ class="md-nav__link "> <span class=md-ellipsis> Spark Connect </span> </a> <label class="md-nav__link " for=__nav_2_26 id=__nav_2_26_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_26_label aria-expanded=false> <label class=md-nav__title for=__nav_2_26> <span class="md-nav__icon md-icon"></span> Spark Connect </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../connect/CommandPlugin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CommandPlugin </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/ExpressionPlugin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExpressionPlugin </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/RelationPlugin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RelationPlugin </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/SimpleSparkConnectService/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleSparkConnectService </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/SparkConnectAnalyzeHandler/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkConnectAnalyzeHandler </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/SparkConnectInterceptorRegistry/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkConnectInterceptorRegistry </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/SparkConnectPlanner/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkConnectPlanner </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/SparkConnectPlugin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkConnectPlugin </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/SparkConnectServer/ class=md-nav__link> <span class=md-ellipsis> SparkConnectServer </span> </a> </li> <li class=md-nav__item> <a href=../connect/SparkConnectService/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkConnectService </span> </span> </a> </li> <li class=md-nav__item> <a href=../connect/SparkConnectStreamHandler/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkConnectStreamHandler </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_27> <div class="md-nav__link md-nav__container"> <a href=../runtime-filtering/ class="md-nav__link "> <span class=md-ellipsis> Runtime Filtering </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_27_label aria-expanded=false> <label class=md-nav__title for=__nav_2_27> <span class="md-nav__icon md-icon"></span> Runtime Filtering </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_28> <div class="md-nav__link md-nav__container"> <a href=../thrift-server/ class="md-nav__link "> <span class=md-ellipsis> Spark Thrift Server </span> </a> <label class="md-nav__link " for=__nav_2_28 id=__nav_2_28_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_28_label aria-expanded=false> <label class=md-nav__title for=__nav_2_28> <span class="md-nav__icon md-icon"></span> Spark Thrift Server </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../thrift-server/SparkSQLEnv/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkSQLEnv </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/statistics/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Statistics </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_30> <div class="md-nav__link md-nav__container"> <a href=../subexpression-elimination/ class="md-nav__link "> <span class=md-ellipsis> Subexpression Elimination </span> </a> <label class="md-nav__link " for=__nav_2_30 id=__nav_2_30_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_30_label aria-expanded=false> <label class=md-nav__title for=__nav_2_30> <span class="md-nav__icon md-icon"></span> Subexpression Elimination </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../subexpression-elimination/EquivalentExpressions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EquivalentExpressions </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_31> <div class="md-nav__link md-nav__container"> <a href=../subqueries/ class="md-nav__link "> <span class=md-ellipsis> Subqueries </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_31_label aria-expanded=false> <label class=md-nav__title for=__nav_2_31> <span class="md-nav__icon md-icon"></span> Subqueries </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_32> <div class="md-nav__link md-nav__container"> <a href=../table-valued-functions/ class="md-nav__link "> <span class=md-ellipsis> Table-Valued Functions </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_32_label aria-expanded=false> <label class=md-nav__title for=__nav_2_32> <span class="md-nav__icon md-icon"></span> Table-Valued Functions </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_33> <div class="md-nav__link md-nav__container"> <a href=../time-travel/ class="md-nav__link "> <span class=md-ellipsis> Time Travel </span> </a> <label class="md-nav__link " for=__nav_2_33 id=__nav_2_33_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_33_label aria-expanded=false> <label class=md-nav__title for=__nav_2_33> <span class="md-nav__icon md-icon"></span> Time Travel </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../time-travel/TimeTravelSpec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TimeTravelSpec </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_34> <div class="md-nav__link md-nav__container"> <a href=../transactional-writes/ class="md-nav__link "> <span class=md-ellipsis> Transactional Writes </span> </a> <label class="md-nav__link " for=__nav_2_34 id=__nav_2_34_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_34_label aria-expanded=false> <label class=md-nav__title for=__nav_2_34> <span class="md-nav__icon md-icon"></span> Transactional Writes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../transactional-writes/SQLHadoopMapReduceCommitProtocol/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLHadoopMapReduceCommitProtocol </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_35> <div class="md-nav__link md-nav__container"> <a href=../user-defined-functions/ class="md-nav__link "> <span class=md-ellipsis> User-Defined Functions </span> </a> <label class="md-nav__link " for=__nav_2_35 id=__nav_2_35_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_35_label aria-expanded=false> <label class=md-nav__title for=__nav_2_35> <span class="md-nav__icon md-icon"></span> User-Defined Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../user-defined-functions/UDFRegistration/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UDFRegistration </span> </span> </a> </li> <li class=md-nav__item> <a href=../user-defined-functions/UserDefinedPythonFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UserDefinedPythonFunction </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_36> <div class="md-nav__link md-nav__container"> <a href=../vectorized-decoding/ class="md-nav__link "> <span class=md-ellipsis> Vectorized Decoding </span> </a> <label class="md-nav__link " for=__nav_2_36 id=__nav_2_36_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_36_label aria-expanded=false> <label class=md-nav__title for=__nav_2_36> <span class="md-nav__icon md-icon"></span> Vectorized Decoding </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../vectorized-decoding/ColumnVector/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ColumnVector </span> </span> </a> </li> <li class=md-nav__item> <a href=../vectorized-decoding/OffHeapColumnVector/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OffHeapColumnVector </span> </span> </a> </li> <li class=md-nav__item> <a href=../vectorized-decoding/OnHeapColumnVector/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OnHeapColumnVector </span> </span> </a> </li> <li class=md-nav__item> <a href=../vectorized-decoding/WritableColumnVector/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WritableColumnVector </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/intervals/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ANSI Intervals </span> </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/catalog-plugin-api-and-multi-catalog-support/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Catalog Plugin API and Multi-Catalog Support </span> </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/explain-command-improved/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Explaining Query Plans Improved </span> </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/observable-metrics/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Observable Metrics </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive-integration/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Hive Integration </span> </span> </a> </li> <li class=md-nav__item> <a href=../dynamic-partition-inserts/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Dynamic Partition Inserts </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_43> <div class="md-nav__link md-nav__container"> <a href=../vectorized-query-execution/ class="md-nav__link "> <span class=md-ellipsis> Vectorized Query Execution </span> </a> <label class="md-nav__link " for=__nav_2_43 id=__nav_2_43_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_43_label aria-expanded=false> <label class=md-nav__title for=__nav_2_43> <span class="md-nav__icon md-icon"></span> Vectorized Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../vectorized-query-execution/ColumnarBatch/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ColumnarBatch </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_44> <div class="md-nav__link md-nav__container"> <a href=../whole-stage-code-generation/ class="md-nav__link "> <span class=md-ellipsis> Whole-Stage Code Generation </span> </a> <label class="md-nav__link " for=__nav_2_44 id=__nav_2_44_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_44_label aria-expanded=false> <label class=md-nav__title for=__nav_2_44> <span class="md-nav__icon md-icon"></span> Whole-Stage Code Generation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../whole-stage-code-generation/Block/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Block </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/BufferedRowIterator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BufferedRowIterator </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/CodeGenerator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CodeGenerator </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/CodegenContext/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CodegenContext </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateColumnAccessor/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GenerateColumnAccessor </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateMutableProjection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GenerateMutableProjection </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateOrdering/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GenerateOrdering </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GeneratePredicate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GeneratePredicate </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateSafeProjection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GenerateSafeProjection </span> </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateUnsafeProjection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GenerateUnsafeProjection </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_45> <div class="md-nav__link md-nav__container"> <a href=../catalyst-dsl/ class="md-nav__link "> <span class=md-ellipsis> Catalyst DSL </span> </a> <label class="md-nav__link " for=__nav_2_45 id=__nav_2_45_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_45_label aria-expanded=false> <label class=md-nav__title for=__nav_2_45> <span class="md-nav__icon md-icon"></span> Catalyst DSL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../catalyst-dsl/DslLogicalPlan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DslLogicalPlan </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../variable-substitution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Variable Substitution </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../query-execution/ class="md-nav__link "> <span class=md-ellipsis> Query Execution </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <div class="md-nav__link md-nav__container"> <a href=../catalyst/ class="md-nav__link "> <span class=md-ellipsis> Catalyst </span> </a> <label class="md-nav__link " for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Catalyst </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../catalyst/GenericStrategy/ class=md-nav__link> <span class=md-ellipsis> GenericStrategy </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/Optimizer/ class=md-nav__link> <span class=md-ellipsis> Optimizer </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/PlanChangeLogger/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PlanChangeLogger </span> </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/QueryPlan/ class=md-nav__link> <span class=md-ellipsis> QueryPlan </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/QueryPlanner/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> QueryPlanner </span> </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/Rule/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Rule </span> </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/RuleExecutor/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RuleExecutors </span> </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/TreeNode/ class=md-nav__link> <span class=md-ellipsis> TreeNode </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/TreePattern/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TreePattern </span> </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/TreePatternBits/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TreePatternBits </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <div class="md-nav__link md-nav__container"> <a href=../expressions/ class="md-nav__link "> <span class=md-ellipsis> Catalyst Expressions </span> </a> <label class="md-nav__link " for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Catalyst Expressions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../expressions/AggregateExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregateExpression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/AggregateFunction/ class=md-nav__link> <span class=md-ellipsis> AggregateFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/AggregateWindowFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregateWindowFunction Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Aggregator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Aggregator Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ArrayFilter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ArrayFilter Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/AttributeSeq/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AttributeSeq </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Attribute/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Attribute Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BasePredicate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BasePredicate Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BinaryComparison/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BinaryComparison Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BinaryOperator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BinaryOperator </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BloomFilterAggregate/ class=md-nav__link> <span class=md-ellipsis> BloomFilterAggregate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BloomFilterMightContain/ class=md-nav__link> <span class=md-ellipsis> BloomFilterMightContain </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BoundReference/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BoundReference </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CallMethodViaReflection/ class=md-nav__link> <span class=md-ellipsis> CallMethodViaReflection </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CodeGeneratorWithInterpretedFallback/ class=md-nav__link> <span class=md-ellipsis> CodeGeneratorWithInterpretedFallback </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CodegenFallback/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CodegenFallback Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Collect/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Collect Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CollectSet/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CollectSet Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Count/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Count Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CreateNamedStruct/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CreateNamedStruct </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CreateStruct/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CreateStruct Function Builder </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CumeDist/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CumeDist </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DeclarativeAggregate/ class=md-nav__link> <span class=md-ellipsis> DeclarativeAggregate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DecodeUsingSerializer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DecodeUsingSerializer </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DynamicPruningExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DynamicPruningExpression Unary Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DynamicPruningSubquery/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DynamicPruningSubquery Unevaluable Subquery Unary Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/EncodeUsingSerializer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EncodeUsingSerializer </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/EqualNullSafe/ class=md-nav__link> <span class=md-ellipsis> EqualNullSafe </span> </a> </li> <li class=md-nav__item> <a href=../expressions/EqualTo/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EqualTo Predicate Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExecSubqueryExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExecSubqueryExpression Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Exists/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Exists &mdash; Correlated Predicate Subquery Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExpectsInputTypes/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExpectsInputTypes Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExplodeBase/ class=md-nav__link> <span class=md-ellipsis> ExplodeBase </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Expression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/First/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> First Aggregate Function Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Generator/ class=md-nav__link> <span class=md-ellipsis> Generator </span> </a> </li> <li class=md-nav__item> <a href=../expressions/HashExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HashExpression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/HashPartitioning/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HashPartitioning </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3_40> <label class=md-nav__link for=__nav_3_3_40 id=__nav_3_3_40_label tabindex=0> <span class=md-ellipsis> Higher-Order Functions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_3_40_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3_40> <span class="md-nav__icon md-icon"></span> Higher-Order Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../expressions/HigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HigherOrderFunction </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ArrayBasedSimpleHigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ArrayBasedSimpleHigherOrderFunction </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/MapBasedSimpleHigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> MapBasedSimpleHigherOrderFunction </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SimpleHigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleHigherOrderFunction </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../expressions/ImperativeAggregate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ImperativeAggregate Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/In/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> In </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Inline/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Inline </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/InSet/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InSet </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/InSubquery/ class=md-nav__link> <span class=md-ellipsis> InSubquery </span> </a> </li> <li class=md-nav__item> <a href=../expressions/InSubqueryExec/ class=md-nav__link> <span class=md-ellipsis> InSubqueryExec </span> </a> </li> <li class=md-nav__item> <a href=../expressions/InterpretedProjection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InterpretedProjection </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/JsonToStructs/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JsonToStructs </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/LessThanOrEqual/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LessThanOrEqual </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ListQuery/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ListQuery </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Literal/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Literal </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/MonotonicallyIncreasingID/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> MonotonicallyIncreasingID </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/MaxBy/ class=md-nav__link> <span class=md-ellipsis> MaxBy </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Murmur3Hash/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Murmur3Hash </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/MutableProjection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> MutableProjection Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/NamedExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> NamedExpression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Nondeterministic/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Nondeterministic Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/OffsetWindowFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OffsetWindowFunction Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ParseToDate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParseToDate </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ParseToTimestamp/ class=md-nav__link> <span class=md-ellipsis> ParseToTimestamp </span> </a> </li> <li class=md-nav__item> <a href=../expressions/PlanExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PlanExpression Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Predicate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Predicate Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Projection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Projection Functions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/PythonUDF/ class=md-nav__link> <span class=md-ellipsis> PythonUDF </span> </a> </li> <li class=md-nav__item> <a href=../expressions/RowNumber/ class=md-nav__link> <span class=md-ellipsis> RowNumber </span> </a> </li> <li class=md-nav__item> <a href=../expressions/RowNumberLike/ class=md-nav__link> <span class=md-ellipsis> RowNumberLike </span> </a> </li> <li class=md-nav__item> <a href=../expressions/RowOrdering/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RowOrdering </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/RuntimeReplaceable/ class=md-nav__link> <span class=md-ellipsis> RuntimeReplaceable </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ScalaAggregator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ScalaAggregator </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ScalarSubquery/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ScalarSubquery </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExecSubqueryExpression-ScalarSubquery/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ScalarSubquery (ExecSubqueryExpression) </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ScalaUDAF/ class=md-nav__link> <span class=md-ellipsis> ScalaUDAF </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ScalaUDF/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ScalaUDF Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SimpleTypedAggregateExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleTypedAggregateExpression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SortOrder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SortOrder </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SparkUserDefinedFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkUserDefinedFunction </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Stateful/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Stateful </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/StaticInvoke/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> StaticInvoke </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SubqueryExpression/ class=md-nav__link> <span class=md-ellipsis> SubqueryExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/TimeWindow/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TimeWindow </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/TypedImperativeAggregate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TypedImperativeAggregate Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnaryExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnaryExpression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Unevaluable/ class=md-nav__link> <span class=md-ellipsis> Unevaluable </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnixTimestamp/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnixTimestamp </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedAttribute/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnresolvedAttribute </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnresolvedFunction </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedGenerator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnresolvedGenerator </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedOrdinal/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnresolvedOrdinal </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedStar/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnresolvedStar </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnsafeProjection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnsafeProjection </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedAggregator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UserDefinedAggregator </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3_92> <label class=md-nav__link for=__nav_3_3_92 id=__nav_3_3_92_label tabindex=0> <span class=md-ellipsis> User-Defined Functions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_3_92_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3_92> <span class="md-nav__icon md-icon"></span> User-Defined Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-udfs/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> User-Defined Functions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UserDefinedExpression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UserDefinedFunction </span> </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-udfs-blackbox/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UDFs are Blackbox &mdash; Don't Use Them Unless You've Got No Choice </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedAggregateFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UserDefinedAggregateFunction &mdash; User-Defined Untyped Aggregate Functions (UDAFs) </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/WindowExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WindowExpression </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/WindowFunction/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WindowFunction Expressions </span> </span> </a> </li> <li class=md-nav__item> <a href=../expressions/WindowSpecDefinition/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WindowSpecDefinition </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_4> <div class="md-nav__link md-nav__container"> <a href=../execution-planning-strategies/ class="md-nav__link "> <span class=md-ellipsis> Execution Planning Strategies </span> </a> <label class="md-nav__link " for=__nav_3_4 id=__nav_3_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> Execution Planning Strategies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../execution-planning-strategies/Aggregation/ class=md-nav__link> <span class=md-ellipsis> Aggregation </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/BasicOperators/ class=md-nav__link> <span class=md-ellipsis> BasicOperators </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/DataSourceStrategy/ class=md-nav__link> <span class=md-ellipsis> DataSourceStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/DataSourceV2Strategy/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2Strategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/FileSourceStrategy/ class=md-nav__link> <span class=md-ellipsis> FileSourceStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/InMemoryScans/ class=md-nav__link> <span class=md-ellipsis> InMemoryScans </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/JoinSelection/ class=md-nav__link> <span class=md-ellipsis> JoinSelection </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/LogicalQueryStageStrategy/ class=md-nav__link> <span class=md-ellipsis> LogicalQueryStageStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/SparkStrategies/ class=md-nav__link> <span class=md-ellipsis> SparkStrategies </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/SparkStrategy/ class=md-nav__link> <span class=md-ellipsis> SparkStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/SpecialLimits/ class=md-nav__link> <span class=md-ellipsis> SpecialLimits </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/Window/ class=md-nav__link> <span class=md-ellipsis> Window </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/WithCTEStrategy/ class=md-nav__link> <span class=md-ellipsis> WithCTEStrategy </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Analyzer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Logical Query Plan Analyzer </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_6> <div class="md-nav__link md-nav__container"> <a href=../logical-analysis-rules/ class="md-nav__link "> <span class=md-ellipsis> Logical Analysis Rules </span> </a> <label class="md-nav__link " for=__nav_3_6 id=__nav_3_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_6_label aria-expanded=false> <label class=md-nav__title for=__nav_3_6> <span class="md-nav__icon md-icon"></span> Logical Analysis Rules </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logical-analysis-rules/AddMetadataColumns/ class=md-nav__link> <span class=md-ellipsis> AddMetadataColumns </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/AliasViewChild/ class=md-nav__link> <span class=md-ellipsis> AliasViewChild </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/BindParameters/ class=md-nav__link> <span class=md-ellipsis> BindParameters </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/CTESubstitution/ class=md-nav__link> <span class=md-ellipsis> CTESubstitution </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/CleanupAliases/ class=md-nav__link> <span class=md-ellipsis> CleanupAliases </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/DataSourceAnalysis/ class=md-nav__link> <span class=md-ellipsis> DataSourceAnalysis </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ExtractWindowExpressions/ class=md-nav__link> <span class=md-ellipsis> ExtractWindowExpressions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/FindDataSourceTable/ class=md-nav__link> <span class=md-ellipsis> FindDataSourceTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/LookupFunctions/ class=md-nav__link> <span class=md-ellipsis> LookupFunctions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/PreWriteCheck/ class=md-nav__link> <span class=md-ellipsis> PreWriteCheck </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/PreprocessTableCreation/ class=md-nav__link> <span class=md-ellipsis> PreprocessTableCreation </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveAggregateFunctions/ class=md-nav__link> <span class=md-ellipsis> ResolveAggregateFunctions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveAliases/ class=md-nav__link> <span class=md-ellipsis> ResolveAliases </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveCatalogs/ class=md-nav__link> <span class=md-ellipsis> ResolveCatalogs </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveCoalesceHints/ class=md-nav__link> <span class=md-ellipsis> ResolveCoalesceHints </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveCreateNamedStruct/ class=md-nav__link> <span class=md-ellipsis> ResolveCreateNamedStruct </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveDefaultColumns/ class=md-nav__link> <span class=md-ellipsis> ResolveDefaultColumns </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveFunctions/ class=md-nav__link> <span class=md-ellipsis> ResolveFunctions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveGroupingAnalytics/ class=md-nav__link> <span class=md-ellipsis> ResolveGroupingAnalytics </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveInlineTables/ class=md-nav__link> <span class=md-ellipsis> ResolveInlineTables </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveInsertInto/ class=md-nav__link> <span class=md-ellipsis> ResolveInsertInto </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveJoinStrategyHints/ class=md-nav__link> <span class=md-ellipsis> ResolveJoinStrategyHints </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveOrdinalInOrderByAndGroupBy/ class=md-nav__link> <span class=md-ellipsis> ResolveOrdinalInOrderByAndGroupBy </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveReferences/ class=md-nav__link> <span class=md-ellipsis> ResolveReferences </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveRelations/ class=md-nav__link> <span class=md-ellipsis> ResolveRelations </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveSQLOnFile/ class=md-nav__link> <span class=md-ellipsis> ResolveSQLOnFile </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveSessionCatalog/ class=md-nav__link> <span class=md-ellipsis> ResolveSessionCatalog </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveSubquery/ class=md-nav__link> <span class=md-ellipsis> ResolveSubquery </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveWindowFrame/ class=md-nav__link> <span class=md-ellipsis> ResolveWindowFrame </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveWithCTE/ class=md-nav__link> <span class=md-ellipsis> ResolveWithCTE </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/RewriteDeleteFromTable/ class=md-nav__link> <span class=md-ellipsis> RewriteDeleteFromTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/RewriteRowLevelCommand/ class=md-nav__link> <span class=md-ellipsis> RewriteRowLevelCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/TableCapabilityCheck/ class=md-nav__link> <span class=md-ellipsis> TableCapabilityCheck </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/WindowFrameCoercion/ class=md-nav__link> <span class=md-ellipsis> WindowFrameCoercion </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/WindowsSubstitution/ class=md-nav__link> <span class=md-ellipsis> WindowsSubstitution </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_7> <div class="md-nav__link md-nav__container"> <a href=../logical-operators/ class="md-nav__link "> <span class=md-ellipsis> Logical Operators </span> </a> <label class="md-nav__link " for=__nav_3_7 id=__nav_3_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_7_label aria-expanded=false> <label class=md-nav__title for=__nav_3_7> <span class="md-nav__icon md-icon"></span> Logical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logical-operators/AddColumns/ class=md-nav__link> <span class=md-ellipsis> AddColumns </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Aggregate/ class=md-nav__link> <span class=md-ellipsis> Aggregate </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AlterTable/ class=md-nav__link> <span class=md-ellipsis> AlterTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AlterTableAddColumnsCommand/ class=md-nav__link> <span class=md-ellipsis> AlterTableAddColumnsCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AlterTableCommand/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AlterTableCommand </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalysisOnlyCommand/ class=md-nav__link> <span class=md-ellipsis> AnalysisOnlyCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeColumn/ class=md-nav__link> <span class=md-ellipsis> AnalyzeColumn </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeColumnCommand/ class=md-nav__link> <span class=md-ellipsis> AnalyzeColumnCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzePartitionCommand/ class=md-nav__link> <span class=md-ellipsis> AnalyzePartitionCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeTable/ class=md-nav__link> <span class=md-ellipsis> AnalyzeTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeTableCommand/ class=md-nav__link> <span class=md-ellipsis> AnalyzeTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeTablesCommand/ class=md-nav__link> <span class=md-ellipsis> AnalyzeTablesCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AppendData/ class=md-nav__link> <span class=md-ellipsis> AppendData </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ArrowEvalPython/ class=md-nav__link> <span class=md-ellipsis> ArrowEvalPython </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/BaseEvalPython/ class=md-nav__link> <span class=md-ellipsis> BaseEvalPython </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CTERelationDef/ class=md-nav__link> <span class=md-ellipsis> CTERelationDef </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CTERelationRef/ class=md-nav__link> <span class=md-ellipsis> CTERelationRef </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CacheTableCommand/ class=md-nav__link> <span class=md-ellipsis> CacheTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ClearCacheCommand/ class=md-nav__link> <span class=md-ellipsis> ClearCacheCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CollectMetrics/ class=md-nav__link> <span class=md-ellipsis> CollectMetrics </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Command/ class=md-nav__link> <span class=md-ellipsis> Command </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CommentOnTable/ class=md-nav__link> <span class=md-ellipsis> CommentOnTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateDataSourceTableAsSelectCommand/ class=md-nav__link> <span class=md-ellipsis> CreateDataSourceTableAsSelectCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateDataSourceTableCommand/ class=md-nav__link> <span class=md-ellipsis> CreateDataSourceTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateTable/ class=md-nav__link> <span class=md-ellipsis> CreateTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateTableAsSelect/ class=md-nav__link> <span class=md-ellipsis> CreateTableAsSelect </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateTempViewUsing/ class=md-nav__link> <span class=md-ellipsis> CreateTempViewUsing </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateView/ class=md-nav__link> <span class=md-ellipsis> CreateView </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateViewCommand/ class=md-nav__link> <span class=md-ellipsis> CreateViewCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DataSourceV2Relation/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2Relation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DataSourceV2ScanRelation/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2ScanRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DataWritingCommand/ class=md-nav__link> <span class=md-ellipsis> DataWritingCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DeleteFromTable/ class=md-nav__link> <span class=md-ellipsis> DeleteFromTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DescribeColumnCommand/ class=md-nav__link> <span class=md-ellipsis> DescribeColumnCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DescribeRelation/ class=md-nav__link> <span class=md-ellipsis> DescribeRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DescribeTableCommand/ class=md-nav__link> <span class=md-ellipsis> DescribeTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DeserializeToObject/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DeserializeToObject </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Except/ class=md-nav__link> <span class=md-ellipsis> Except </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Expand/ class=md-nav__link> <span class=md-ellipsis> Expand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ExplainCommand/ class=md-nav__link> <span class=md-ellipsis> ExplainCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ExposesMetadataColumns/ class=md-nav__link> <span class=md-ellipsis> ExposesMetadataColumns </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ExternalRDD/ class=md-nav__link> <span class=md-ellipsis> ExternalRDD </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/FlatMapGroupsWithState/ class=md-nav__link> <span class=md-ellipsis> FlatMapGroupsWithState </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Generate/ class=md-nav__link> <span class=md-ellipsis> Generate </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/GlobalLimit/ class=md-nav__link> <span class=md-ellipsis> GlobalLimit </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/GroupingSets/ class=md-nav__link> <span class=md-ellipsis> GroupingSets </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/IgnoreCachedData/ class=md-nav__link> <span class=md-ellipsis> IgnoreCachedData </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InMemoryRelation/ class=md-nav__link> <span class=md-ellipsis> InMemoryRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoDataSourceCommand/ class=md-nav__link> <span class=md-ellipsis> InsertIntoDataSourceCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoDir/ class=md-nav__link> <span class=md-ellipsis> InsertIntoDir </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoHadoopFsRelationCommand/ class=md-nav__link> <span class=md-ellipsis> InsertIntoHadoopFsRelationCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoStatement/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InsertIntoStatement </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoTable/ class=md-nav__link> <span class=md-ellipsis> InsertIntoTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Join/ class=md-nav__link> <span class=md-ellipsis> Join </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LeafNode/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LeafNodes </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LeafRunnableCommand/ class=md-nav__link> <span class=md-ellipsis> LeafRunnableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LoadDataCommand/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LoadDataCommand </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LocalRelation/ class=md-nav__link> <span class=md-ellipsis> LocalRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalPlan/ class=md-nav__link> <span class=md-ellipsis> LogicalPlan </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalPlanDistinctKeys/ class=md-nav__link> <span class=md-ellipsis> LogicalPlanDistinctKeys </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalQueryStage/ class=md-nav__link> <span class=md-ellipsis> LogicalQueryStage </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalRDD/ class=md-nav__link> <span class=md-ellipsis> LogicalRDD </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalRelation/ class=md-nav__link> <span class=md-ellipsis> LogicalRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/MapPartitions/ class=md-nav__link> <span class=md-ellipsis> MapPartitions </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/MergeIntoTable/ class=md-nav__link> <span class=md-ellipsis> MergeIntoTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/MultiInstanceRelation/ class=md-nav__link> <span class=md-ellipsis> MultiInstanceRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/NameParameterizedQuery/ class=md-nav__link> <span class=md-ellipsis> NameParameterizedQuery </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/NamedRelation/ class=md-nav__link> <span class=md-ellipsis> NamedRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Offset/ class=md-nav__link> <span class=md-ellipsis> Offset </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/OrderPreservingUnaryNode/ class=md-nav__link> <span class=md-ellipsis> OrderPreservingUnaryNode </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/OverwriteByExpression/ class=md-nav__link> <span class=md-ellipsis> OverwriteByExpression </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/OverwritePartitionsDynamic/ class=md-nav__link> <span class=md-ellipsis> OverwritePartitionsDynamic </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ParameterizedQuery/ class=md-nav__link> <span class=md-ellipsis> ParameterizedQuery </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ParsedStatement/ class=md-nav__link> <span class=md-ellipsis> ParsedStatement </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Pivot/ class=md-nav__link> <span class=md-ellipsis> Pivot </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Project/ class=md-nav__link> <span class=md-ellipsis> Project </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RebalancePartitions/ class=md-nav__link> <span class=md-ellipsis> RebalancePartitions </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RelationTimeTravel/ class=md-nav__link> <span class=md-ellipsis> RelationTimeTravel </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Repartition/ class=md-nav__link> <span class=md-ellipsis> Repartition </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RepartitionByExpression/ class=md-nav__link> <span class=md-ellipsis> RepartitionByExpression </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RepartitionOperation/ class=md-nav__link> <span class=md-ellipsis> RepartitionOperation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ReplaceData/ class=md-nav__link> <span class=md-ellipsis> ReplaceData </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ResolvedHint/ class=md-nav__link> <span class=md-ellipsis> ResolvedHint </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ResolvedTable/ class=md-nav__link> <span class=md-ellipsis> ResolvedTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RowLevelWrite/ class=md-nav__link> <span class=md-ellipsis> RowLevelWrite </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RunnableCommand/ class=md-nav__link> <span class=md-ellipsis> RunnableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SaveIntoDataSourceCommand/ class=md-nav__link> <span class=md-ellipsis> SaveIntoDataSourceCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SetCatalogAndNamespace/ class=md-nav__link> <span class=md-ellipsis> SetCatalogAndNamespace </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowColumns/ class=md-nav__link> <span class=md-ellipsis> ShowColumns </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowColumnsCommand/ class=md-nav__link> <span class=md-ellipsis> ShowColumnsCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowCreateTable/ class=md-nav__link> <span class=md-ellipsis> ShowCreateTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowCreateTableCommand/ class=md-nav__link> <span class=md-ellipsis> ShowCreateTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowTableProperties/ class=md-nav__link> <span class=md-ellipsis> ShowTableProperties </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowTablePropertiesCommand/ class=md-nav__link> <span class=md-ellipsis> ShowTablePropertiesCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowTables/ class=md-nav__link> <span class=md-ellipsis> ShowTables </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Sort/ class=md-nav__link> <span class=md-ellipsis> Sort </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SubqueryAlias/ class=md-nav__link> <span class=md-ellipsis> SubqueryAlias </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SupportsSubquery/ class=md-nav__link> <span class=md-ellipsis> SupportsSubquery </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/TruncateTableCommand/ class=md-nav__link> <span class=md-ellipsis> TruncateTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedHaving/ class=md-nav__link> <span class=md-ellipsis> UnresolvedHaving </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedHint/ class=md-nav__link> <span class=md-ellipsis> UnresolvedHint </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedRelation/ class=md-nav__link> <span class=md-ellipsis> UnresolvedRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedTable/ class=md-nav__link> <span class=md-ellipsis> UnresolvedTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedTableOrView/ class=md-nav__link> <span class=md-ellipsis> UnresolvedTableOrView </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedTableValuedFunction/ class=md-nav__link> <span class=md-ellipsis> UnresolvedTableValuedFunction </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedWith/ class=md-nav__link> <span class=md-ellipsis> UnresolvedWith </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UpdateTable/ class=md-nav__link> <span class=md-ellipsis> UpdateTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/V2CreateTablePlan/ class=md-nav__link> <span class=md-ellipsis> V2CreateTablePlan </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/V2WriteCommand/ class=md-nav__link> <span class=md-ellipsis> V2WriteCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/View/ class=md-nav__link> <span class=md-ellipsis> View </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Window/ class=md-nav__link> <span class=md-ellipsis> Window </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/WithCTE/ class=md-nav__link> <span class=md-ellipsis> WithCTE </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/WithWindowDefinition/ class=md-nav__link> <span class=md-ellipsis> WithWindowDefinition </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/WriteDelta/ class=md-nav__link> <span class=md-ellipsis> WriteDelta </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/WriteFiles/ class=md-nav__link> <span class=md-ellipsis> WriteFiles </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <div class="md-nav__link md-nav__container"> <a href=../logical-optimizations/ class="md-nav__link "> <span class=md-ellipsis> Logical Optimizations </span> </a> <label class="md-nav__link " for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> Logical Optimizations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logical-optimizations/AQEPropagateEmptyRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AQEPropagateEmptyRelation Adaptive Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CleanupDynamicPruningFilters/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CleanupDynamicPruningFilters Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CollapseWindow/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CollapseWindow Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ColumnPruning/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ColumnPruning Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CombineTypedFilters/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CombineTypedFilters Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CombineUnions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CombineUnions Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ComputeCurrentTime/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ComputeCurrentTime Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ConstantFolding/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ConstantFolding Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ConvertToLocalRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ConvertToLocalRelation Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CostBasedJoinReorder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CostBasedJoinReorder Logical Optimization -- Join Reordering in Cost-Based Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/DecimalAggregates/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DecimalAggregates Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/DynamicJoinSelection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DynamicJoinSelection Adaptive Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateResolvedHint/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EliminateResolvedHint Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateSerialization/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EliminateSerialization Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateSubqueryAliases/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EliminateSubqueryAliases Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateView/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EliminateView Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ExtractPythonUDFFromAggregate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExtractPythonUDFFromAggregate Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ExtractPythonUDFs/ class=md-nav__link> <span class=md-ellipsis> ExtractPythonUDFs </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/GetCurrentDatabase/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GetCurrentDatabase Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/GroupBasedRowLevelOperationScanPlanning/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> GroupBasedRowLevelOperationScanPlanning Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/InferFiltersFromConstraints/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InferFiltersFromConstraints Logical Optimization Rule </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/InjectRuntimeFilter/ class=md-nav__link> <span class=md-ellipsis> InjectRuntimeFilter </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/InlineCTE/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InlineCTE Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/LimitPushDown/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LimitPushDown Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/NullPropagation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> NullPropagation Logical Optimization -- Nullability (NULL Value) Propagation </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/OptimizeIn/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OptimizeIn Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/OptimizeMetadataOnlyQuery/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OptimizeMetadataOnlyQuery Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/OptimizeSubqueries/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OptimizeSubqueries Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PartitionPruning/ class=md-nav__link> <span class=md-ellipsis> PartitionPruning </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PropagateEmptyRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PropagateEmptyRelation Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PruneFileSourcePartitions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PruneFileSourcePartitions Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PruneFilters/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PruneFilters </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PruneHiveTablePartitions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PruneHiveTablePartitions Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PullupCorrelatedPredicates/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PullupCorrelatedPredicates Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushDownLeftSemiAntiJoin/ class=md-nav__link> <span class=md-ellipsis> PushDownLeftSemiAntiJoin </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushDownOperatorsToDataSource/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PushDownOperatorsToDataSource Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushDownPredicate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PushDownPredicate Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushDownPredicates/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PushDownPredicates Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushPredicateThroughJoin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PushPredicateThroughJoin Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReorderJoin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ReorderJoin Logical Optimization -- Reordering Inner and Cross Joins </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReplaceExceptWithAntiJoin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ReplaceExceptWithAntiJoin Logical Optimization Rule -- Rewriting Except (DISTINCT) Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReplaceExceptWithFilter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ReplaceExceptWithFilter Logical Optimization Rule -- Rewriting Except (DISTINCT) Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReplaceExpressions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ReplaceExpressions Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/RewriteCorrelatedScalarSubquery/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RewriteCorrelatedScalarSubquery Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/RewriteExceptAll/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RewriteExceptAll Logical Optimization Rule -- Rewriting Except (ALL) Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/RewritePredicateSubquery/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RewritePredicateSubquery Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/SchemaPruning/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SchemaPruning Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/SimplifyCasts/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimplifyCasts Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/UpdateAttributeNullability/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UpdateAttributeNullability Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/UpdateCTERelationStats/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UpdateCTERelationStats Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/V2ScanRelationPushDown/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V2ScanRelationPushDown Logical Optimization </span> </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/V2Writes/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V2Writes Logical Optimization </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../physical-operators/ class="md-nav__link "> <span class=md-ellipsis> Physical Operators </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Physical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/AdaptiveSparkPlanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AdaptiveSparkPlanExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AggregateCodegenSupport/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregateCodegenSupport Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AliasAwareOutputExpression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AliasAwareOutputExpression Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AliasAwareQueryOutputOrdering/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AliasAwareQueryOutputOrdering Unary Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AlterTableExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AlterTableExec </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AQEShuffleReadExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AQEShuffleReadExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AtomicTableWriteExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AtomicTableWriteExec Physical Commands </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BaseAggregateExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BaseAggregateExec Unary Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BaseJoinExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BaseJoinExec Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BaseSubqueryExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BaseSubqueryExec Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BatchWriteHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BatchWriteHelper Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BatchScanExec/ class=md-nav__link> <span class=md-ellipsis> BatchScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastExchangeExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BroadcastExchangeExec Unary Physical Operator for Broadcast Joins </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastExchangeLike/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BroadcastExchangeLike Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastHashJoinExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BroadcastHashJoinExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastNestedLoopJoinExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BroadcastNestedLoopJoinExec Binary Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastQueryStageExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BroadcastQueryStageExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CacheTableAsSelectExec/ class=md-nav__link> <span class=md-ellipsis> CacheTableAsSelectExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CoalesceExec/ class=md-nav__link> <span class=md-ellipsis> CoalesceExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CollectLimitExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CollectLimitExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CollectMetricsExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CollectMetricsExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ColumnarToRowExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ColumnarToRowExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ColumnarToRowTransition/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ColumnarToRowTransition Unary Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CreateTableAsSelectExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CreateTableAsSelectExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CodegenSupport/ class=md-nav__link> <span class=md-ellipsis> CodegenSupport </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DataSourceScanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSourceScanExec Leaf Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DataSourceV2ScanExecBase/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2ScanExecBase </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DataWritingCommandExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataWritingCommandExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DebugExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DebugExec Unary Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DeleteFromTableExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DeleteFromTableExec </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DescribeTableExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DescribeTableExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DeserializeToObjectExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DeserializeToObjectExec </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DropNamespaceExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DropNamespaceExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/EvalPythonExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> EvalPythonExec Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/Exchange/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Exchange Unary Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ExecutedCommandExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExecutedCommandExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ExpandExec/ class=md-nav__link> <span class=md-ellipsis> ExpandExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ExternalRDDScanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExternalRDDScanExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/FileSourceScanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileSourceScanExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/FilterExec/ class=md-nav__link> <span class=md-ellipsis> FilterExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/GenerateExec/ class=md-nav__link> <span class=md-ellipsis> GenerateExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashAggregateExec/ class=md-nav__link> <span class=md-ellipsis> HashAggregateExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashedRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HashedRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashJoin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HashJoin &mdash; Hash-Based Join Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/InMemoryTableScanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InMemoryTableScanExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/InputAdapter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InputAdapter Unary Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/JoinCodegenSupport/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JoinCodegenSupport </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/LocalTableScanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LocalTableScanExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/LongHashedRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LongHashedRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectConsumerExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ObjectConsumerExec -- Unary Physical Operators with Child Physical Operator with One-Attribute Output Schema </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectHashAggregateExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ObjectHashAggregateExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectProducerExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ObjectProducerExec </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/OrderPreservingUnaryExecNode/ class=md-nav__link> <span class=md-ellipsis> OrderPreservingUnaryExecNode </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/OverwriteByExpressionExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OverwriteByExpressionExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/PartitioningPreservingUnaryExecNode/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PartitioningPreservingUnaryExecNode Unary Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ProjectExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ProjectExec Unary Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/QueryStageExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> QueryStageExec Leaf Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/RangeExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RangeExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ReusedExchangeExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ReusedExchangeExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ReusedSubqueryExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ReusedSubqueryExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/RowDataSourceScanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RowDataSourceScanExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/RowToColumnarExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RowToColumnarExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SerializeFromObjectExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SerializeFromObjectExec Unary Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SetCatalogAndNamespaceExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SetCatalogAndNamespaceExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShowCreateTableExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShowCreateTableExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShowTablesExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShowTablesExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShowTablePropertiesExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShowTablePropertiesExec Physical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleExchangeExec/ class=md-nav__link> <span class=md-ellipsis> ShuffleExchangeExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleExchangeLike/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShuffleExchangeLike Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffledHashJoinExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShuffledHashJoinExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffledJoin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShuffledJoin Physical Operators </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleOrigin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShuffleOrigin </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleQueryStageExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShuffleQueryStageExec Adaptive Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SortAggregateExec/ class=md-nav__link> <span class=md-ellipsis> SortAggregateExec </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9_76> <label class=md-nav__link for=__nav_3_9_76 id=__nav_3_9_76_label tabindex=0> <span class=md-ellipsis> SortMergeJoinExec </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_9_76_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9_76> <span class="md-nav__icon md-icon"></span> SortMergeJoinExec </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/SortMergeJoinExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SortMergeJoinExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SortMergeJoinScanner/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SortMergeJoinScanner </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../physical-operators/SortExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SortExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SparkPlan/ class=md-nav__link> <span class=md-ellipsis> SparkPlan </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SubqueryExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SubqueryExec Unary Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/TableWriteExecHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableWriteExecHelper Unary Physical Commands </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/TruncateTableExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TruncateTableExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/UnaryExecNode/ class=md-nav__link> <span class=md-ellipsis> UnaryExecNode </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/V2CommandExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V2CommandExec Physical Commands </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/V2ExistingTableWriteExec/ class=md-nav__link> <span class=md-ellipsis> V2ExistingTableWriteExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/V2TableWriteExec/ class=md-nav__link> <span class=md-ellipsis> V2TableWriteExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/WholeStageCodegenExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WholeStageCodegenExec Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/WindowExec/ class=md-nav__link> <span class=md-ellipsis> WindowExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/WindowExecBase/ class=md-nav__link> <span class=md-ellipsis> WindowExecBase </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/WriteDeltaExec/ class=md-nav__link> <span class=md-ellipsis> WriteDeltaExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/WriteFilesExec/ class=md-nav__link> <span class=md-ellipsis> WriteFilesExec </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9_91> <label class=md-nav__link for=__nav_3_9_91 id=__nav_3_9_91_label tabindex=0> <span class=md-ellipsis> Distribution and Partitioning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_9_91_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9_91> <span class="md-nav__icon md-icon"></span> Distribution and Partitioning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/Distribution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Distribution </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/Partitioning/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Partitioning (Catalyst) </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9_91_3> <label class=md-nav__link for=__nav_3_9_91_3 id=__nav_3_9_91_3_label tabindex=0> <span class=md-ellipsis> Distribution Specifications </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_3_9_91_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9_91_3> <span class="md-nav__icon md-icon"></span> Distribution Specifications </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/AllTuples/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AllTuples </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastDistribution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BroadcastDistribution </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ClusteredDistribution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ClusteredDistribution </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashClusteredDistribution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HashClusteredDistribution </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/OrderedDistribution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OrderedDistribution </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/UnspecifiedDistribution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnspecifiedDistribution </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9_91_4> <label class=md-nav__link for=__nav_3_9_91_4 id=__nav_3_9_91_4_label tabindex=0> <span class=md-ellipsis> Broadcast Modes </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_3_9_91_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9_91_4> <span class="md-nav__icon md-icon"></span> Broadcast Modes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/BroadcastMode/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BroadcastModes </span> </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashedRelationBroadcastMode/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HashedRelationBroadcastMode </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleSpec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShuffleSpec </span> </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_10> <div class="md-nav__link md-nav__container"> <a href=../physical-optimizations/ class="md-nav__link "> <span class=md-ellipsis> Physical Optimizations </span> </a> <label class="md-nav__link " for=__nav_3_10 id=__nav_3_10_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_10_label aria-expanded=false> <label class=md-nav__title for=__nav_3_10> <span class="md-nav__icon md-icon"></span> Physical Optimizations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-optimizations/AQEShuffleReadRule/ class=md-nav__link> <span class=md-ellipsis> AQEShuffleReadRule </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/AdjustShuffleExchangePosition/ class=md-nav__link> <span class=md-ellipsis> AdjustShuffleExchangePosition </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ApplyColumnarRulesAndInsertTransitions/ class=md-nav__link> <span class=md-ellipsis> ApplyColumnarRulesAndInsertTransitions </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/CoalesceBucketsInJoin/ class=md-nav__link> <span class=md-ellipsis> CoalesceBucketsInJoin </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/CoalesceShufflePartitions/ class=md-nav__link> <span class=md-ellipsis> CoalesceShufflePartitions </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/CollapseCodegenStages/ class=md-nav__link> <span class=md-ellipsis> CollapseCodegenStages </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/DisableUnnecessaryBucketedScan/ class=md-nav__link> <span class=md-ellipsis> DisableUnnecessaryBucketedScan </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/EnsureRequirements/ class=md-nav__link> <span class=md-ellipsis> EnsureRequirements </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/InsertAdaptiveSparkPlan/ class=md-nav__link> <span class=md-ellipsis> InsertAdaptiveSparkPlan </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/OptimizeShuffleWithLocalRead/ class=md-nav__link> <span class=md-ellipsis> OptimizeShuffleWithLocalRead </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/OptimizeSkewInRebalancePartitions/ class=md-nav__link> <span class=md-ellipsis> OptimizeSkewInRebalancePartitions </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/OptimizeSkewedJoin/ class=md-nav__link> <span class=md-ellipsis> OptimizeSkewedJoin </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanAdaptiveDynamicPruningFilters/ class=md-nav__link> <span class=md-ellipsis> PlanAdaptiveDynamicPruningFilters </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanAdaptiveSubqueries/ class=md-nav__link> <span class=md-ellipsis> PlanAdaptiveSubqueries </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanDynamicPruningFilters/ class=md-nav__link> <span class=md-ellipsis> PlanDynamicPruningFilters </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanSubqueries/ class=md-nav__link> <span class=md-ellipsis> PlanSubqueries </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/RemoveRedundantProjects/ class=md-nav__link> <span class=md-ellipsis> RemoveRedundantProjects </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/RemoveRedundantSorts/ class=md-nav__link> <span class=md-ellipsis> RemoveRedundantSorts </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReplaceHashWithSortAgg/ class=md-nav__link> <span class=md-ellipsis> ReplaceHashWithSortAgg </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseAdaptiveSubquery/ class=md-nav__link> <span class=md-ellipsis> ReuseAdaptiveSubquery </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseExchange/ class=md-nav__link> <span class=md-ellipsis> ReuseExchange </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseExchangeAndSubquery/ class=md-nav__link> <span class=md-ellipsis> ReuseExchangeAndSubquery </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseSubquery/ class=md-nav__link> <span class=md-ellipsis> ReuseSubquery </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ValidateSparkPlan/ class=md-nav__link> <span class=md-ellipsis> ValidateSparkPlan </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../QueryExecution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> QueryExecution &mdash; Structured Query Execution Pipeline </span> </span> </a> </li> <li class=md-nav__item> <a href=../QueryPlanningTracker/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> QueryPlanningTracker </span> </span> </a> </li> <li class=md-nav__item> <a href=../SparkOptimizer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkOptimizer &mdash; Logical Query Plan Optimizer </span> </span> </a> </li> <li class=md-nav__item> <a href=../SparkPlanner/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkPlanner &mdash; Spark Query Planner </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Internals </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Internals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../overview/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Spark SQL </span> </span> </a> </li> <li class=md-nav__item> <a href=../DataSource/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSource &mdash; Pluggable Data Provider Framework </span> </span> </a> </li> <li class=md-nav__item> <a href=../developer-api/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Developer API </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExecutionListenerBus/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExecutionListenerBus </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExecutionListenerManager/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExecutionListenerManager </span> </span> </a> </li> <li class=md-nav__item> <a href=../SharedState/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SharedState &mdash; State Shared Across SparkSessions </span> </span> </a> </li> <li class=md-nav__item> <a href=../SQLConf/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLConf </span> </span> </a> </li> <li class=md-nav__item> <a href=../SQLConfHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLConfHelper </span> </span> </a> </li> <li class=md-nav__item> <a href=../StaticSQLConf/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> StaticSQLConf &mdash; Static Configuration Properties </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_10> <label class=md-nav__link for=__nav_4_10 id=__nav_4_10_label tabindex=0> <span class=md-ellipsis> SparkSession Registries </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_10_label aria-expanded=false> <label class=md-nav__title for=__nav_4_10> <span class="md-nav__icon md-icon"></span> SparkSession Registries </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_10_1> <label class=md-nav__link for=__nav_4_10_1 id=__nav_4_10_1_label tabindex=0> <span class=md-ellipsis> Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_10_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_10_1> <span class="md-nav__icon md-icon"></span> Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Catalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Catalog &mdash; Metastore Management Interface </span> </span> </a> </li> <li class=md-nav__item> <a href=../CatalogImpl/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogImpl </span> </span> </a> </li> <li class=md-nav__item> <a href=../CatalogStatistics/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogStatistics </span> </span> </a> </li> <li class=md-nav__item> <a href=../CatalogUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogUtils </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ExperimentalMethods/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExperimentalMethods </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_10_3> <label class=md-nav__link for=__nav_4_10_3 id=__nav_4_10_3_label tabindex=0> <span class=md-ellipsis> ExternalCatalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_10_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_10_3> <span class="md-nav__icon md-icon"></span> ExternalCatalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ExternalCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExternalCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=../InMemoryCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InMemoryCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExternalCatalogWithListener/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExternalCatalogWithListener </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_10_4> <label class=md-nav__link for=__nav_4_10_4 id=__nav_4_10_4_label tabindex=0> <span class=md-ellipsis> FunctionRegistry </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_10_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_10_4> <span class="md-nav__icon md-icon"></span> FunctionRegistry </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../FunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FunctionRegistry </span> </span> </a> </li> <li class=md-nav__item> <a href=../FunctionRegistryBase/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FunctionRegistryBase </span> </span> </a> </li> <li class=md-nav__item> <a href=../SimpleFunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleFunctionRegistry </span> </span> </a> </li> <li class=md-nav__item> <a href=../SimpleFunctionRegistryBase/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleFunctionRegistryBase </span> </span> </a> </li> <li class=md-nav__item> <a href=../SimpleTableFunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleTableFunctionRegistry </span> </span> </a> </li> <li class=md-nav__item> <a href=../TableFunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableFunctionRegistry </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../GlobalTempViewManager/ class=md-nav__link> <span class=md-ellipsis> GlobalTempViewManager </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_10_6> <label class=md-nav__link for=__nav_4_10_6 id=__nav_4_10_6_label tabindex=0> <span class=md-ellipsis> SessionCatalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_10_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_10_6> <span class="md-nav__icon md-icon"></span> SessionCatalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../SessionCatalog/ class=md-nav__link> <span class=md-ellipsis> SessionCatalog </span> </a> </li> <li class=md-nav__item> <a href=../CatalogStorageFormat/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogStorageFormat </span> </span> </a> </li> <li class=md-nav__item> <a href=../CatalogTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogTable </span> </span> </a> </li> <li class=md-nav__item> <a href=../CatalogTablePartition/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogTablePartition </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../V2SessionCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V2SessionCatalog </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_10_8> <label class=md-nav__link for=__nav_4_10_8 id=__nav_4_10_8_label tabindex=0> <span class=md-ellipsis> SessionState </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_10_8_label aria-expanded=false> <label class=md-nav__title for=__nav_4_10_8> <span class="md-nav__icon md-icon"></span> SessionState </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../SessionState/ class=md-nav__link> <span class=md-ellipsis> SessionState </span> </a> </li> <li class=md-nav__item> <a href=../BaseSessionStateBuilder/ class=md-nav__link> <span class=md-ellipsis> BaseSessionStateBuilder </span> </a> </li> <li class=md-nav__item> <a href=../SessionStateBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SessionStateBuilder </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_10_9> <label class=md-nav__link for=__nav_4_10_9 id=__nav_4_10_9_label tabindex=0> <span class=md-ellipsis> CacheManager </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_10_9_label aria-expanded=false> <label class=md-nav__title for=__nav_4_10_9> <span class="md-nav__icon md-icon"></span> CacheManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CacheManager/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CacheManager </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../RuntimeConfig/ class=md-nav__link> <span class=md-ellipsis> RuntimeConfig </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_11> <label class=md-nav__link for=__nav_4_11 id=__nav_4_11_label tabindex=0> <span class=md-ellipsis> Encoder </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_11_label aria-expanded=false> <label class=md-nav__title for=__nav_4_11> <span class="md-nav__icon md-icon"></span> Encoder </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Encoder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Encoder </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExpressionEncoder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExpressionEncoder </span> </span> </a> </li> <li class=md-nav__item> <a href=../RowEncoder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RowEncoder </span> </span> </a> </li> <li class=md-nav__item> <a href=../ScalaReflection/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ScalaReflection </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../SQLExecution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLExecution </span> </span> </a> </li> <li class=md-nav__item> <a href=../SQLMetric/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLMetric </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_14> <div class="md-nav__link md-nav__container"> <a href=../tungsten/ class="md-nav__link "> <span class=md-ellipsis> Tungsten Execution Backend </span> </a> <label class="md-nav__link " for=__nav_4_14 id=__nav_4_14_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_14_label aria-expanded=false> <label class=md-nav__title for=__nav_4_14> <span class="md-nav__icon md-icon"></span> Tungsten Execution Backend </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CatalystSerde/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalystSerde Utility </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExternalAppendOnlyUnsafeRowArray/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExternalAppendOnlyUnsafeRowArray </span> </span> </a> </li> <li class=md-nav__item> <a href=../HashMapGenerator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HashMapGenerator </span> </span> </a> </li> <li class=md-nav__item> <a href=../InternalRow/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InternalRow </span> </span> </a> </li> <li class=md-nav__item> <a href=../UnsafeHashedRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnsafeHashedRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../UnsafeRow/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnsafeRow </span> </span> </a> </li> <li class=md-nav__item> <a href=../tungsten/UnsafeRowSerializerInstance/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnsafeRowSerializerInstance </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_15> <label class=md-nav__link for=__nav_4_15 id=__nav_4_15_label tabindex=0> <span class=md-ellipsis> RDDs </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_15_label aria-expanded=false> <label class=md-nav__title for=__nav_4_15> <span class="md-nav__icon md-icon"></span> RDDs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../DataSourceRDD/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSourceRDD </span> </span> </a> </li> <li class=md-nav__item> <a href=../DataSourceRDDPartition/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSourceRDDPartition </span> </span> </a> </li> <li class=md-nav__item> <a href=../rdds/FileScanRDD/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileScanRDD </span> </span> </a> </li> <li class=md-nav__item> <a href=../ShuffledRowRDD/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ShuffledRowRDD </span> </span> </a> </li> <li class=md-nav__item> <a href=../SQLExecutionRDD/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLExecutionRDD </span> </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../sql/ class="md-nav__link "> <span class=md-ellipsis> SQL </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> SQL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../sql/AbstractSqlParser/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AbstractSqlParser </span> </span> </a> </li> <li class=md-nav__item> <a href=../sql/AstBuilder/ class=md-nav__link> <span class=md-ellipsis> AstBuilder </span> </a> </li> <li class=md-nav__item> <a href=../sql/CatalystSqlParser/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalystSqlParser </span> </span> </a> </li> <li class=md-nav__item> <a href=../sql/ParserInterface/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParserInterface </span> </span> </a> </li> <li class=md-nav__item> <a href=../sql/SparkSqlParser/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkSqlParser &mdash; Default SQL Parser </span> </span> </a> </li> <li class=md-nav__item> <a href=../sql/SparkSqlAstBuilder/ class=md-nav__link> <span class=md-ellipsis> SparkSqlAstBuilder </span> </a> </li> <li class=md-nav__item> <a href=../sql/VariableSubstitution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> VariableSubstitution </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <div class="md-nav__link md-nav__container"> <a href=../connectors/ class="md-nav__link "> <span class=md-ellipsis> Connectors </span> </a> <label class="md-nav__link " for=__nav_6 id=__nav_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Connectors </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_2> <div class="md-nav__link md-nav__container"> <a href=../avro/ class="md-nav__link "> <span class=md-ellipsis> Avro </span> </a> <label class="md-nav__link " for=__nav_6_2 id=__nav_6_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_6_2> <span class="md-nav__icon md-icon"></span> Avro </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../avro/AvroOptions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AvroOptions </span> </span> </a> </li> <li class=md-nav__item> <a href=../avro/AvroFileFormat/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AvroFileFormat </span> </span> </a> </li> <li class=md-nav__item> <a href=../avro/CatalystDataToAvro/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalystDataToAvro Unary Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../avro/AvroDataToCatalyst/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AvroDataToCatalyst Unary Expression </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3> <div class="md-nav__link md-nav__container"> <a href=../files/ class="md-nav__link "> <span class=md-ellipsis> Files </span> </a> <label class="md-nav__link " for=__nav_6_3 id=__nav_6_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3> <span class="md-nav__icon md-icon"></span> Files </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../files/AggregatePushDownUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregatePushDownUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/BaseDynamicPartitionDataWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BaseDynamicPartitionDataWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/BasicWriteJobStatsTracker/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BasicWriteJobStatsTracker </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/BasicWriteTaskStats/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BasicWriteTaskStats </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/BasicWriteTaskStatsTracker/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BasicWriteTaskStatsTracker </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/CompressionCodecs/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CompressionCodecs </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/DynamicPartitionDataSingleWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DynamicPartitionDataSingleWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/DynamicPartitionDataConcurrentWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DynamicPartitionDataConcurrentWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileBatchWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileBatchWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileDataSourceV2/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileDataSourceV2 Table Providers </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileFormat/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileFormat </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileFormatDataWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileFormatDataWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileFormatWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileFormatWriter </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3_15> <label class=md-nav__link for=__nav_6_3_15 id=__nav_6_3_15_label tabindex=0> <span class=md-ellipsis> FileIndex </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_3_15_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3_15> <span class="md-nav__icon md-icon"></span> FileIndex </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../files/FileIndex/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileIndex </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/CatalogFileIndex/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalogFileIndex </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/InMemoryFileIndex/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InMemoryFileIndex </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/PartitioningAwareFileIndex/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PartitioningAwareFileIndex </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/PrunedInMemoryFileIndex/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PrunedInMemoryFileIndex </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../files/FilePartition/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FilePartition </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FilePartitionReaderFactory/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FilePartitionReaderFactory </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileScan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileScan </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileScanBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileScanBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileStatusCache/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileStatusCache </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileTable </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/FileWriterFactory/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileWriterFactory </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/HadoopFileLinesReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HadoopFileLinesReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/HadoopFsRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HadoopFsRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/PartitionedFile/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PartitionedFile </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/PartitionedFileUtil/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PartitionedFileUtil </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/RecordReaderIterator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RecordReaderIterator </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/SharedInMemoryCache/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SharedInMemoryCache </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/SchemaMergeUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SchemaMergeUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/SingleDirectoryDataWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SingleDirectoryDataWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/WriteJobStatsTracker/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WriteJobStatsTracker </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/WriteTaskStats/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WriteTaskStats </span> </span> </a> </li> <li class=md-nav__item> <a href=../files/WriteTaskStatsTracker/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WriteTaskStatsTracker </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_4> <div class="md-nav__link md-nav__container"> <a href=../hive/ class="md-nav__link "> <span class=md-ellipsis> Hive </span> </a> <label class="md-nav__link " for=__nav_6_4 id=__nav_6_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_4_label aria-expanded=false> <label class=md-nav__title for=__nav_6_4> <span class="md-nav__icon md-icon"></span> Hive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../hive/configuration-properties/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Configuration Properties </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/spark-sql-hive-metastore/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Hive Metastore </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/DataSinks/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSinks </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveClient/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveClient </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveClientImpl/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveClientImpl </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveFileFormat/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveFileFormat </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/IsolatedClientLoader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> IsolatedClientLoader Utility </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveTableRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveTableRelation Leaf Logical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/CreateHiveTableAsSelectCommand/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CreateHiveTableAsSelectCommand Logical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/SaveAsHiveFile/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SaveAsHiveFile </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/InsertIntoHiveDirCommand/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InsertIntoHiveDirCommand Logical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/InsertIntoHiveTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InsertIntoHiveTable Logical Command </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveTableScans/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveTableScans Execution Planning Strategy </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveTableScanExec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveTableScanExec Leaf Physical Operator </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/TableReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HadoopTableReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HadoopTableReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveSessionStateBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveSessionStateBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveExternalCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveExternalCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveSessionCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveSessionCatalog -- Hive-Specific Catalog of Relational Entities </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveMetastoreCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveMetastoreCatalog &mdash; Legacy SessionCatalog for Converting Hive Metastore Relations to Data Source Relations </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/RelationConversions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RelationConversions PostHoc Logical Evaluation Rule </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/ResolveHiveSerdeTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ResolveHiveSerdeTable Logical Resolution Rule </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/DetermineTableStats/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DetermineTableStats Logical PostHoc Resolution Rule -- Computing Total Size Table Statistic for HiveTableRelations </span> </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveAnalysis/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> HiveAnalysis PostHoc Logical Resolution Rule </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_5> <div class="md-nav__link md-nav__container"> <a href=../jdbc/ class="md-nav__link "> <span class=md-ellipsis> JDBC </span> </a> <label class="md-nav__link " for=__nav_6_5 id=__nav_6_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_5_label aria-expanded=false> <label class=md-nav__title for=__nav_6_5> <span class="md-nav__icon md-icon"></span> JDBC </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../jdbc/AggregatedDialect/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregatedDialect </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JDBCOptions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JDBCOptions </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JDBCRDD/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JDBCRDD </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JDBCRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JDBCRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JDBCScan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JDBCScan </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JDBCScanBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JDBCScanBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JDBCTableCatalog/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JDBCTableCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JdbcDialect/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JdbcDialect </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JdbcDialects/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JdbcDialects </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JdbcRelationProvider/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JdbcRelationProvider </span> </span> </a> </li> <li class=md-nav__item> <a href=../jdbc/JdbcUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JdbcUtils </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_6> <div class="md-nav__link md-nav__container"> <a href=../kafka/ class="md-nav__link "> <span class=md-ellipsis> Kafka </span> </a> <label class="md-nav__link " for=__nav_6_6 id=__nav_6_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6_6> <span class="md-nav__icon md-icon"></span> Kafka </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../kafka/configuration-properties/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Configuration Properties </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaBatch/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaBatch </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaBatchWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaBatchWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaBatchWriterFactory/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaBatchWriterFactory </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaDataConsumer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaDataConsumer </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaDataWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaDataWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaOffsetRangeLimit/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaOffsetRangeLimit </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaOffsetReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaOffsetReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaScan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaScan </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaSourceProvider/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaSourceProvider </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaSourceRDD/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaSourceRDD </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaSourceRDDPartition/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaSourceRDDPartition </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaTable </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaWriter Utility </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaWriteTask/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaWriteTask </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_6_19> <label class=md-nav__link for=__nav_6_6_19 id=__nav_6_6_19_label tabindex=0> <span class=md-ellipsis> Misc </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_6_6_19_label aria-expanded=false> <label class=md-nav__title for=__nav_6_6_19> <span class="md-nav__icon md-icon"></span> Misc </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../kafka/ConsumerStrategy/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ConsumerStrategy &mdash; Kafka Consumer Providers </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/InternalKafkaConsumer/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InternalKafkaConsumer </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/InternalKafkaProducerPool/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InternalKafkaProducerPool </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/JsonUtils/ class=md-nav__link> <span class=md-ellipsis> JsonUtils </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaRowWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaRowWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaRecordToRowConverter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KafkaRecordToRowConverter </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../kafka/options/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Options </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_7> <div class="md-nav__link md-nav__container"> <a href=../noop/ class="md-nav__link "> <span class=md-ellipsis> Noop </span> </a> <label class="md-nav__link " for=__nav_6_7 id=__nav_6_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_7_label aria-expanded=false> <label class=md-nav__title for=__nav_6_7> <span class="md-nav__icon md-icon"></span> Noop </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../noop/NoopDataSource/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> NoopDataSource </span> </span> </a> </li> <li class=md-nav__item> <a href=../noop/NoopTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> NoopTable </span> </span> </a> </li> <li class=md-nav__item> <a href=../noop/NoopWriteBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> NoopWriteBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../noop/NoopBatchWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> NoopBatchWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../noop/NoopStreamingWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> NoopStreamingWrite </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_8> <div class="md-nav__link md-nav__container"> <a href=../parquet/ class="md-nav__link "> <span class=md-ellipsis> Parquet </span> </a> <label class="md-nav__link " for=__nav_6_8 id=__nav_6_8_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_8_label aria-expanded=false> <label class=md-nav__title for=__nav_6_8> <span class="md-nav__icon md-icon"></span> Parquet </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../parquet/ParquetDataSourceV2/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetDataSourceV2 </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetFileFormat/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetFileFormat </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetFilters/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetFilters </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetOptions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetOptions </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetPartitionReaderFactory/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetPartitionReaderFactory </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetReadSupport/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetReadSupport </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetScan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetScan </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetScanBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetScanBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetTable </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/ParquetWriteSupport/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ParquetWriteSupport </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/SparkToParquetSchemaConverter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkToParquetSchemaConverter </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/SpecificParquetRecordReaderBase/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SpecificParquetRecordReaderBase &mdash; Hadoop RecordReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/VectorizedColumnReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> VectorizedColumnReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../parquet/VectorizedParquetRecordReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> VectorizedParquetRecordReader </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../connectors/DataWritingSparkTask/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataWritingSparkTask Utility </span> </span> </a> </li> <li class=md-nav__item> <a href=../connectors/DataSourceV2Utils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSourceV2Utils Utility </span> </span> </a> </li> <li class=md-nav__item> <a href=../connectors/OutputWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> OutputWriter </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> High-Level APIs </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> High-Level APIs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Column/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Column </span> </span> </a> </li> <li class=md-nav__item> <a href=../ColumnarRule/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ColumnarRule </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7_3> <div class="md-nav__link md-nav__container"> <a href=../connector/ class="md-nav__link "> <span class=md-ellipsis> Connector API </span> </a> <label class="md-nav__link " for=__nav_7_3 id=__nav_7_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_7_3_label aria-expanded=false> <label class=md-nav__title for=__nav_7_3> <span class="md-nav__icon md-icon"></span> Connector API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../connector/ApplyTransform/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ApplyTransform </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/Batch/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Batch </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/BatchWrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BatchWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/CustomMetric/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CustomMetric </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/DataSourceV2Implicits/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSourceV2Implicits </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/DataWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/DataWriterFactory/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataWriterFactory </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/Expression/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Expression </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/InputPartition/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InputPartition </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/LocalScan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> LocalScan </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/OptionsHelper/ class=md-nav__link> <span class=md-ellipsis> OptionsHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/PartitionReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PartitionReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/PartitionReaderFactory/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PartitionReaderFactory </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/PartitionSpecsHelper/ class=md-nav__link> <span class=md-ellipsis> PartitionSpecsHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/Partitioning/ class=md-nav__link> <span class=md-ellipsis> Partitioning </span> </a> </li> <li class=md-nav__item> <a href=../connector/Predicate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Predicate </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/RewritableTransform/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RewritableTransform </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/RowLevelOperation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RowLevelOperation </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/Scan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Scan </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/ScanBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ScanBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SessionConfigSupport/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SessionConfigSupport </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SimpleTableProvider/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SimpleTableProvider </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/StagedTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> StagedTable </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsAtomicPartitionManagement/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsAtomicPartitionManagement </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsDelete/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsDelete </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsDeleteV2/ class=md-nav__link> <span class=md-ellipsis> SupportsDeleteV2 </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsDelta/ class=md-nav__link> <span class=md-ellipsis> SupportsDelta </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsDynamicOverwrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsDynamicOverwrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsMetadata/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsMetadata </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsMetadataColumns/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsMetadataColumns </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsOverwrite/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsOverwrite </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPartitionManagement/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsPartitionManagement </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPushDownAggregates/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsPushDownAggregates </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPushDownFilters/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsPushDownFilters </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPushDownRequiredColumns/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsPushDownRequiredColumns </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPushDownV2Filters/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsPushDownV2Filters </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsRead/ class=md-nav__link> <span class=md-ellipsis> SupportsRead </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsReportOrdering/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsReportOrdering </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsReportPartitioning/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsReportPartitioning </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsReportStatistics/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsReportStatistics </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsRowLevelOperations/ class=md-nav__link> <span class=md-ellipsis> SupportsRowLevelOperations </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsRuntimeFiltering/ class=md-nav__link> <span class=md-ellipsis> SupportsRuntimeFiltering </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsRuntimeV2Filtering/ class=md-nav__link> <span class=md-ellipsis> SupportsRuntimeV2Filtering </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsStreamingUpdate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsStreamingUpdate </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsTruncate/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SupportsTruncate </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsWrite/ class=md-nav__link> <span class=md-ellipsis> SupportsWrite </span> </a> </li> <li class=md-nav__item> <a href=../connector/Table/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Table </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/TableCapability/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableCapability </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/TableHelper/ class=md-nav__link> <span class=md-ellipsis> TableHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/TableProvider/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableProvider </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/Transform/ class=md-nav__link> <span class=md-ellipsis> Transform </span> </a> </li> <li class=md-nav__item> <a href=../connector/TransformHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TransformHelper </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/TruncatableTable/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TruncatableTable </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/V1Scan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V1Scan </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/V1Table/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V1Table </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/V1WriteBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> V1WriteBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/Write/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Write </span> </span> </a> </li> <li class=md-nav__item> <a href=../connector/WriteBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WriteBuilder </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7_4> <div class="md-nav__link md-nav__container"> <a href=../types/ class="md-nav__link "> <span class=md-ellipsis> Data Types </span> </a> <label class="md-nav__link " for=__nav_7_4 id=__nav_7_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_7_4_label aria-expanded=false> <label class=md-nav__title for=__nav_7_4> <span class="md-nav__icon md-icon"></span> Data Types </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../types/AbstractDataType/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AbstractDataType </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/ArrayType/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ArrayType </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/AtomicType/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AtomicType </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/CalendarInterval/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CalendarInterval </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/DataType/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataType </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/Metadata/ class=md-nav__link> <span class=md-ellipsis> Metadata </span> </a> </li> <li class=md-nav__item> <a href=../types/MetadataBuilder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> MetadataBuilder </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/StructField/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> StructField </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/StructType/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> StructType </span> </span> </a> </li> <li class=md-nav__item> <a href=../types/UserDefinedType/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UserDefinedType </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Dataset/ class=md-nav__link> <span class=md-ellipsis> Dataset </span> </a> </li> <li class=md-nav__item> <a href=../DataFrame/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataFrame &mdash; Dataset of Rows with RowEncoder </span> </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameReader/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataFrameReader </span> </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataFrameWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameWriterV2/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataFrameWriterV2 </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7_10> <label class=md-nav__link for=__nav_7_10 id=__nav_7_10_label tabindex=0> <span class=md-ellipsis> DataSource V1 API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_7_10_label aria-expanded=false> <label class=md-nav__title for=__nav_7_10> <span class="md-nav__icon md-icon"></span> DataSource V1 API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../DataSourceRegister/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataSourceRegister </span> </span> </a> </li> <li class=md-nav__item> <a href=../CreatableRelationProvider/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CreatableRelationProvider </span> </span> </a> </li> <li class=md-nav__item> <a href=../RelationProvider/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RelationProvider &mdash; Relations with Pre-Defined Schema </span> </span> </a> </li> <li class=md-nav__item> <a href=../SchemaRelationProvider/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SchemaRelationProvider &mdash; Relation Providers With Mandatory User-Defined Schema </span> </span> </a> </li> <li class=md-nav__item> <a href=../BaseRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BaseRelation &mdash; Collection of Tuples with Schema </span> </span> </a> </li> <li class=md-nav__item> <a href=../FileRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FileRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../InsertableRelation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> InsertableRelation </span> </span> </a> </li> <li class=md-nav__item> <a href=../PrunedFilteredScan/ class=md-nav__link> <span class=md-ellipsis> PrunedFilteredScan </span> </a> </li> <li class=md-nav__item> <a href=../PrunedScan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PrunedScan </span> </span> </a> </li> <li class=md-nav__item> <a href=../TableScan/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TableScan &mdash; Relations with Column Pruning </span> </span> </a> </li> <li class=md-nav__item> <a href=../Filter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Data Source Filter Predicate </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Encoders/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Encoders Utility </span> </span> </a> </li> <li class=md-nav__item> <a href=../KeyValueGroupedDataset/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KeyValueGroupedDataset </span> </span> </a> </li> <li class=md-nav__item> <a href=../Observation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Observation </span> </span> </a> </li> <li class=md-nav__item> <a href=../QueryExecutionListener/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> QueryExecutionListener </span> </span> </a> </li> <li class=md-nav__item> <a href=../RelationalGroupedDataset/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RelationalGroupedDataset </span> </span> </a> </li> <li class=md-nav__item> <a href=../SparkSession/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkSession &mdash; The Entry Point to Spark SQL </span> </span> </a> </li> <li class=md-nav__item> <a href=../SparkSession-Builder/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkSession.Builder </span> </span> </a> </li> <li class=md-nav__item> <a href=../SparkSessionExtensions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkSessionExtensions </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7_19> <div class="md-nav__link md-nav__container"> <a href=../standard-functions/ class="md-nav__link "> <span class=md-ellipsis> Standard Functions <br> <small>org.apache.spark.sql.functions</small> </span> </a> <label class="md-nav__link " for=__nav_7_19 id=__nav_7_19_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_7_19_label aria-expanded=false> <label class=md-nav__title for=__nav_7_19> <span class="md-nav__icon md-icon"></span> Standard Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../standard-functions/aggregate/ class=md-nav__link> <span class=md-ellipsis> Aggregate </span> </a> </li> <li class=md-nav__item> <a href=../standard-functions/collection-functions/ class=md-nav__link> <span class=md-ellipsis> Collection </span> </a> </li> <li class=md-nav__item> <a href=../standard-functions/datetime/ class=md-nav__link> <span class=md-ellipsis> Date time </span> </a> </li> <li class=md-nav__item> <a href=../standard-functions/regular-functions/ class=md-nav__link> <span class=md-ellipsis> Non-aggregate (Normal) </span> </a> </li> <li class=md-nav__item> <a href=../standard-functions/windows-functions/ class=md-nav__link> <span class=md-ellipsis> Window </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../TypedColumn/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> TypedColumn </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7_21> <div class="md-nav__link md-nav__container"> <a href=../window-functions/ class="md-nav__link "> <span class=md-ellipsis> Window Functions </span> </a> <label class="md-nav__link " for=__nav_7_21 id=__nav_7_21_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_7_21_label aria-expanded=false> <label class=md-nav__title for=__nav_7_21> <span class="md-nav__icon md-icon"></span> Window Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../window-functions/AggregateProcessor/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregateProcessor </span> </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/RangeFrame/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> RangeFrame </span> </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/Window/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Window </span> </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/WindowFunctionFrame/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WindowFunctionFrame </span> </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/WindowSpec/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WindowSpec </span> </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8> <div class="md-nav__link md-nav__container"> <a href=../ui/ class="md-nav__link "> <span class=md-ellipsis> Web UI </span> </a> <label class="md-nav__link " for=__nav_8 id=__nav_8_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Web UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ui/AllExecutionsPage/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AllExecutionsPage </span> </span> </a> </li> <li class=md-nav__item> <a href=../ui/ExecutionPage/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExecutionPage </span> </span> </a> </li> <li class=md-nav__item> <a href=../ui/SQLAppStatusListener/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLAppStatusListener </span> </span> </a> </li> <li class=md-nav__item> <a href=../ui/SQLAppStatusStore/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLAppStatusStore </span> </span> </a> </li> <li class=md-nav__item> <a href=../ui/SQLTab/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SQLTab </span> </span> </a> </li> <li class=md-nav__item> <a href=../ui/SparkListenerSQLExecutionEnd/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SparkListenerSQLExecutionEnd </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_9> <div class="md-nav__link md-nav__container"> <a href=../demo/ class="md-nav__link "> <span class=md-ellipsis> Demo </span> </a> <label class="md-nav__link " for=__nav_9 id=__nav_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_9_label aria-expanded=false> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> Demo </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../demo/adaptive-query-execution/ class=md-nav__link> <span class=md-ellipsis> Adaptive Query Execution </span> </a> </li> <li class=md-nav__item> <a href=../demo/connecting-spark-sql-to-hive-metastore/ class=md-nav__link> <span class=md-ellipsis> Connecting Spark SQL to Hive Metastore </span> </a> </li> <li class=md-nav__item> <a href=../demo/demo-multi-dimensional-aggregations/ class=md-nav__link> <span class=md-ellipsis> Mult-Dimensional Aggregations </span> </a> </li> <li class=md-nav__item> <a href=../demo/developing-catalogplugin/ class=md-nav__link> <span class=md-ellipsis> Developing CatalogPlugin </span> </a> </li> <li class=md-nav__item> <a href=../demo/dynamic-partition-pruning/ class=md-nav__link> <span class=md-ellipsis> Dynamic Partition Pruning </span> </a> </li> <li class=md-nav__item> <a href=../demo/hive-partitioned-parquet-table-partition-pruning/ class=md-nav__link> <span class=md-ellipsis> Hive Partitioned Parquet Table and Partition Pruning </span> </a> </li> <li class=md-nav__item> <a href=../demo/objecthashaggregateexec-sort-based-fallback-tasks/ class=md-nav__link> <span class=md-ellipsis> ObjectHashAggregateExec and Sort-Based Fallback Tasks </span> </a> </li> <li class=md-nav__item> <a href=../demo/spilling/ class=md-nav__link> <span class=md-ellipsis> Spilling </span> </a> </li> <li class=md-nav__item> <a href=../demo/using-jdbc-data-source-to-access-postgresql/ class=md-nav__link> <span class=md-ellipsis> Using JDBC Data Source to Access PostgreSQL </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10> <label class=md-nav__link for=__nav_10 id=__nav_10_label tabindex=0> <span class=md-ellipsis> Misc </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_10_label aria-expanded=false> <label class=md-nav__title for=__nav_10> <span class="md-nav__icon md-icon"></span> Misc </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../AggregatingAccumulator/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> AggregatingAccumulator </span> </span> </a> </li> <li class=md-nav__item> <a href=../DistinctKeyVisitor/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DistinctKeyVisitor </span> </span> </a> </li> <li class=md-nav__item> <a href=../FilterEvaluatorFactory/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> FilterEvaluatorFactory </span> </span> </a> </li> <li class=md-nav__item> <a href=../JoinSelectionHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> JoinSelectionHelper </span> </span> </a> </li> <li class=md-nav__item> <a href=../PushDownUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PushDownUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../UnsafeExternalRowSorter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> UnsafeExternalRowSorter </span> </span> </a> </li> <li class=md-nav__item> <a href=../BindReferences/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> BindReferences </span> </span> </a> </li> <li class=md-nav__item> <a href=../IntervalUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> IntervalUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExplainUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExplainUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../SerializerBuildHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SerializerBuildHelper </span> </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-dataset-rdd/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Datasets, DataFrames and RDDs </span> </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-dataset-vs-sql/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Dataset API and SQL </span> </span> </a> </li> <li class=md-nav__item> <a href=../connectors/DDLUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DDLUtils </span> </span> </a> </li> <li class=md-nav__item> <a href=../implicits/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> implicits Object -- Implicits Conversions </span> </span> </a> </li> <li class=md-nav__item> <a href=../Row/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Row </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10_16> <label class=md-nav__link for=__nav_10_16 id=__nav_10_16_label tabindex=0> <span class=md-ellipsis> Data Source API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_10_16_label aria-expanded=false> <label class=md-nav__title for=__nav_10_16> <span class="md-nav__icon md-icon"></span> Data Source API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CreateTableWriter/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CreateTableWriter </span> </span> </a> </li> <li class=md-nav__item> <a href=../WriteConfigMethods/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> WriteConfigMethods </span> </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10_17> <label class=md-nav__link for=__nav_10_17 id=__nav_10_17_label tabindex=0> <span class=md-ellipsis> Dataset API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_10_17_label aria-expanded=false> <label class=md-nav__title for=__nav_10_17> <span class="md-nav__icon md-icon"></span> Dataset API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-dataset-operators/ class=md-nav__link> <span class=md-ellipsis> Operators </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-Dataset-typed-transformations/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Dataset API &mdash; Typed Transformations </span> </span> </a> </li> <li class=md-nav__item> <a href=../Dataset-untyped-transformations/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Dataset API &mdash; Untyped Transformations </span> </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-Dataset-basic-actions/ class=md-nav__link> <span class=md-ellipsis> Basic Actions </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-Dataset-actions/ class=md-nav__link> <span class=md-ellipsis> Actions </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-DataFrameNaFunctions/ class=md-nav__link> <span class=md-ellipsis> DataFrameNaFunctions </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameStatFunctions/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> DataFrameStatFunctions </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-column-operators/ class=md-nav__link> <span class=md-ellipsis> Column Operators </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10_19> <label class=md-nav__link for=__nav_10_19 id=__nav_10_19_label tabindex=0> <span class=md-ellipsis> Caching and Persistence </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_10_19_label aria-expanded=false> <label class=md-nav__title for=__nav_10_19> <span class="md-nav__icon md-icon"></span> Caching and Persistence </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../caching-and-persistence/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Caching and Persistence </span> </span> </a> </li> <li class=md-nav__item> <a href=../caching-webui-storage/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> User-Friendly Names of Cached Queries in web UI </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../checkpointing/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Checkpointing </span> </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10_21> <label class=md-nav__link for=__nav_10_21 id=__nav_10_21_label tabindex=0> <span class=md-ellipsis> Performance Tuning and Debugging </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_10_21_label aria-expanded=false> <label class=md-nav__title for=__nav_10_21> <span class="md-nav__icon md-icon"></span> Performance Tuning and Debugging </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../debugging-query-execution/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Debugging Query Execution </span> </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-performance-tuning/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Spark SQL's Performance Tuning Tips and Tricks (aka Case Studies) </span> </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-performance-tuning-groupBy-aggregation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> Case Study: Number of Partitions for groupBy Aggregation </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../CheckAnalysis/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CheckAnalysis &mdash; Analysis Validation </span> </span> </a> </li> <li class=md-nav__item> <a href=../CatalystTypeConverters/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> CatalystTypeConverters Helper Object </span> </span> </a> </li> <li class=md-nav__item> <a href=../SubExprUtils/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> SubExprUtils Utility </span> </span> </a> </li> <li class=md-nav__item> <a href=../PredicateHelper/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> PredicateHelper </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExtractEquiJoinKeys/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExtractEquiJoinKeys Scala Extractor </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExtractSingleColumnNullAwareAntiJoin/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExtractSingleColumnNullAwareAntiJoin Scala Extractor </span> </span> </a> </li> <li class=md-nav__item> <a href=../ExtractJoinWithBuckets/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> ExtractJoinWithBuckets Scala Extractor </span> </span> </a> </li> <li class=md-nav__item> <a href=../PhysicalOperation/ class=md-nav__link> <span class=md-ellipsis> PhysicalOperation </span> </a> </li> <li class=md-nav__item> <a href=../KnownSizeEstimation/ class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> KnownSizeEstimation </span> </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#spark.sql.adaptive class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.adaptive </span> </span> </a> <nav class=md-nav aria-label=spark.sql.adaptive> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> advisoryPartitionSizeInBytes </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.autoBroadcastJoinThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> autoBroadcastJoinThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> coalescePartitions.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.minPartitionSize class=md-nav__link> <span class=md-ellipsis> coalescePartitions.minPartitionSize </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.minPartitionSize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> coalescePartitions.minPartitionSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.initialPartitionNum class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> coalescePartitions.initialPartitionNum </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.coalescePartitions.parallelismFirst class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> coalescePartitions.parallelismFirst </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.customCostEvaluatorClass class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> customCostEvaluatorClass </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.fetchShuffleBlocksInBatch class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> fetchShuffleBlocksInBatch </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.forceApply class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> forceApply </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.forceOptimizeSkewedJoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> forceOptimizeSkewedJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.localShuffleReader.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> localShuffleReader.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.logLevel class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> logLevel </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> maxShuffledHashJoinLocalMapThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> nonEmptyPartitionRatioForBroadcastJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.optimizer.excludedRules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> optimizer.excludedRules </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> optimizeSkewsInRebalancePartitions.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.skewJoin.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> skewJoin.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.skewJoin.skewedPartitionFactor class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> skewJoin.skewedPartitionFactor </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> skewJoin.skewedPartitionThresholdInBytes </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.allowNamedFunctionArguments class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> allowNamedFunctionArguments </span> </span> </a> </li> <li class=md-nav__item> <a href=#autobroadcastjointhreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> autoBroadcastJoinThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#cacheserializer class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> cache.serializer </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.codegen </span> </span> </a> <nav class=md-nav aria-label=spark.sql.codegen> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.fastHashMap.capacityBit class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.fastHashMap.capacityBit </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.twolevel.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.map.twolevel.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.vectorized.enable class=md-nav__link> <span class=md-ellipsis> aggregate.map.vectorized.enable </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.twolevel.partialOnly class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.map.twolevel.partialOnly </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.hugeMethodLimit class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> hugeMethodLimit </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.fallback class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> fallback </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.join.fullOuterShuffledHashJoin.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> join.fullOuterShuffledHashJoin.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.methodSplitThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> methodSplitThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.wholeStage class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> wholeStage </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#columnvectoroffheapenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> columnVector.offheap.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#defaultcolumnenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> defaultColumn.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#exchangereuse class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> exchange.reuse </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.execution </span> </span> </a> <nav class=md-nav aria-label=spark.sql.execution> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.execution.arrow.pyspark.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> arrow.pyspark.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.arrow.pyspark.fallback.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> arrow.pyspark.fallback.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.arrow.pyspark.selfDestruct.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> arrow.pyspark.selfDestruct.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.pandas.convertToArrowArraySafely class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> pandas.convertToArrowArraySafely </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.pandas.udf.buffer.size class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> pandas.udf.buffer.size </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.rangeExchange.sampleSizePerPartition class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> rangeExchange.sampleSizePerPartition </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.removeRedundantSorts class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> removeRedundantSorts </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.replaceHashWithSortAgg class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> replaceHashWithSortAgg </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.reuseSubquery class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> reuseSubquery </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.sortBeforeRepartition class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> sortBeforeRepartition </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.execution.usePartitionEvaluator class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> usePartitionEvaluator </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sparksqlhive class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.hive </span> </span> </a> <nav class=md-nav aria-label=spark.sql.hive> <ul class=md-nav__list> <li class=md-nav__item> <a href=#filesourcepartitionfilecachesize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> filesourcePartitionFileCacheSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#managefilesourcepartitions class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> manageFilesourcePartitions </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#inmemorycolumnarstoragepartitionpruning class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> inMemoryColumnarStorage.partitionPruning </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.optimizer </span> </span> </a> <nav class=md-nav aria-label=spark.sql.optimizer> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.optimizer.canChangeCachedPlanOutputPartitioning class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> canChangeCachedPlanOutputPartitioning </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.decorrelateInnerQuery.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> decorrelateInnerQuery.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.fallbackFilterRatio </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.pruningSideExtraFilterRatio </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.useStats class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.useStats </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> dynamicPartitionPruning.reuseBroadcastOnly </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.enableCsvExpressionOptimization class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> enableCsvExpressionOptimization </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.excludedRules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> excludedRules </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.expressionProjectionCandidateLimit class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> expressionProjectionCandidateLimit </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.expression.nestedPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> expression.nestedPruning.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.inSetConversionThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> inSetConversionThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.inSetSwitchThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> inSetSwitchThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.maxIterations class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> maxIterations </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.nestedSchemaPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> nestedSchemaPruning.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.nestedPredicatePushdown.supportedFileSources class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> nestedPredicatePushdown.supportedFileSources </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.optimizeOneRowRelationSubquery class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> optimizeOneRowRelationSubquery </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.planChangeLog.batches class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> planChangeLog.batches </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.planChangeLog.level class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> planChangeLog.level </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.planChangeLog.rules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> planChangeLog.rules </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.propagateDistinctKeys.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> propagateDistinctKeys.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.replaceExceptWithFilter class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> replaceExceptWithFilter </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.creationSideThreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.creationSideThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.expectedNumItems class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.expectedNumItems </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.bloomFilter.maxNumBits class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtime.bloomFilter.maxNumBits </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtime.rowLevelOperationGroupFilter.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> runtime.rowLevelOperationGroupFilter.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtimeFilter.number.threshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtimeFilter.number.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.runtimeFilter.semiJoinReduction.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> runtimeFilter.semiJoinReduction.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.optimizer.serializer.nestedSchemaPruning.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> serializer.nestedSchemaPruning.enabled </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql </span> </span> </a> <nav class=md-nav aria-label=spark.sql> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.retainGroupColumns class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> retainGroupColumns </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.files class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.files </span> </span> </a> <nav class=md-nav aria-label=spark.sql.files> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.files.maxPartitionBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> maxPartitionBytes </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.maxPartitionNum class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> maxPartitionNum </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.maxRecordsPerFile class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> maxRecordsPerFile </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.minPartitionNum class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> minPartitionNum </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.files.openCostInBytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> openCostInBytes </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.parquet class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.parquet </span> </span> </a> <nav class=md-nav aria-label=spark.sql.parquet> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.parquet.aggregatePushdown class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregatePushdown </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.columnarReaderBatchSize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> columnarReaderBatchSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.enableNestedColumnVectorizedReader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> enableNestedColumnVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.filterPushdown class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> filterPushdown </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.filterPushdown.stringPredicate class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> filterPushdown.stringPredicate </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.mergeSchema class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> mergeSchema </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.parquet.output.committer.class class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> output.committer.class </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#spark.sql.sources class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.sources </span> </span> </a> <nav class=md-nav aria-label=spark.sql.sources> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.sources.bucketing.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> bucketing.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.sources.commitProtocolClass class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> commitProtocolClass </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.sources.outputCommitterClass class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> outputCommitterClass </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sparksqlobjecthashaggregatesortbasedfallbackthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.objectHashAggregate.sortBased.fallbackThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownonemptylocationinctas class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowNonEmptyLocationInCTAS </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowautogeneratedaliasforview class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowAutoGeneratedAliasForView </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sessionWindow.buffer.spill.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowstarwithsingletableidentifierincount class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowStarWithSingleTableIdentifierInCount </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sessionWindow.buffer.in.memory.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcenablenestedcolumnvectorizedreader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.orc.enableNestedColumnVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzermaxiterations class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.analyzer.maxIterations </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzerfailambiguousselfjoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.analyzer.failAmbiguousSelfJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlansienabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.ansi.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcliprintheader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cli.print.header </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldebugmaxtostringfields class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.debug.maxToStringFields </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultcatalog class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.defaultCatalog </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.histogram.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessiontimezone class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.session.timeZone </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesignoredatalocality class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.ignoreDataLocality </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesvalidatepartitioncolumns class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.validatePartitionColumns </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesusev1sourcelist class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.sources.useV1SourceList </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstoreassignmentpolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.storeAssignmentPolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlthriftserverinterruptoncancel class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.thriftServer.interruptOnCancel </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlhivetablepropertylengththreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.hive.tablePropertyLengthThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcmergeschema class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.orc.mergeSchema </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbucketingautobucketedscanenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.bucketing.autoBucketedScan.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldatetimejava8apienabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.datetime.java8API.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyintervalenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.interval.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbinaryfilemaxlength class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.binaryFile.maxLength </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmapkeydeduppolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.mapKeyDedupPolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxconcurrentoutputfilewriters class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maxConcurrentOutputFileWriters </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxmetadatastringlength class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maxMetadataStringLength </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmavenadditionalremoterepositories class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maven.additionalRemoteRepositories </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxplanstringlength class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.maxPlanStringLength </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladdpartitioninbatchsize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.addPartitionInBatch.size </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlscripttransformationexittimeoutinseconds class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.scriptTransformation.exitTimeoutInSeconds </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlavrocompressioncodec class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.avro.compression.codec </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbroadcasttimeout class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.broadcastTimeout </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbucketingcoalescebucketsinjoinenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.bucketing.coalesceBucketsInJoin.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcasesensitive class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.caseSensitive </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcatalogspark_catalog class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.catalog.spark_catalog </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbojoinreorderenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.joinReorder.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboplanstatsenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.planStats.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbostarschemadetection class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.cbo.starSchemaDetection </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegen class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.codegen </span> </span> </a> <nav class=md-nav aria-label=spark.sql.codegen> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.map.vectorized.enable class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.map.vectorized.enable </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.sortAggregate.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> aggregate.sortAggregate.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.aggregate.splitAggregateFunc.enabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> aggregate.splitAggregateFunc.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.comments class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> comments </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.factoryMode class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> factoryMode </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.useIdInClassName class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> useIdInClassName </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.maxFields class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> maxFields </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.codegen.splitConsumeFuncByOperator class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> splitConsumeFuncByOperator </span> </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sparksqlcolumnnameofcorruptrecord class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.columnNameOfCorruptRecord </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlconstraintpropagationenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.constraintPropagation.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcsvfilterpushdownenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.csv.filterPushdown.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultsizeinbytes class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.defaultSizeInBytes </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldialect class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.dialect </span> </span> </a> </li> <li class=md-nav__item> <a href=#executionuseobjecthashaggregateexec class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> execution.useObjectHashAggregateExec </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignorecorruptfiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.files.ignoreCorruptFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignoremissingfiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.files.ignoreMissingFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragecompressed class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryColumnarStorage.compressed </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragebatchsize class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryColumnarStorage.batchSize </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorytablescanstatisticsenable class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryTableScanStatistics.enable </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstorageenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.inMemoryColumnarStorage.enableVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljoinprefersortmergejoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.join.preferSortMergeJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljsongeneratorignorenullfields class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.jsonGenerator.ignoreNullFields </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlleafnodedefaultparallelism class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.leafNodeDefaultParallelism </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydolooseupcast class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.doLooseUpcast </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycteprecedencepolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.ctePrecedencePolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytimeparserpolicy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.timeParserPolicy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfollowthreevaluedlogicinarrayexists class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.followThreeValuedLogicInArrayExists </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfromdaytimestringenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.fromDayTimeString.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacynotreserveproperties class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.notReserveProperties </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyaddsinglefileinaddfile class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.addSingleFileInAddFile </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyexponentliteralasdecimalenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.exponentLiteralAsDecimal.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownegativescaleofdecimal class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowNegativeScaleOfDecimal </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacybucketedtablescanoutputordering class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.bucketedTableScan.outputOrdering </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyjsonallowemptystringenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.json.allowEmptyString.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycreateemptycollectionusingstringtype class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.createEmptyCollectionUsingStringType </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowuntypedscalaudf class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowUntypedScalaUDF </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydatasetnamenonstructgroupingkeyasvalue class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacysetcommandrejectssparkcoreconfs class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.setCommandRejectsSparkCoreConfs </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytypecoerciondatetimetostringenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.typeCoercion.datetimeToString.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowhashonmaptype class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.allowHashOnMapType </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.parquet.datetimeRebaseModeInWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.parquet.datetimeRebaseModeInRead </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.avro.datetimeRebaseModeInWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.avro.datetimeRebaseModeInRead </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyrddapplyconf class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.rdd.applyConf </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyreplacedatabrickssparkavroenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.legacy.replaceDatabricksSparkAvro.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllimitscaleupfactor class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.limit.scaleUpFactor </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqloptimizenullawareantijoin class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.optimizeNullAwareAntiJoin </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcimpl class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.orc.impl </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangeloglevel class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.planChangeLog.level </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogbatches class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.planChangeLog.batches </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogrules class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.planChangeLog.rules </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpysparkjvmstacktraceenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.pyspark.jvmStacktrace.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetbinaryasstring class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.binaryAsString </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetcompressioncodec class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.compression.codec </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.enableVectorizedReader </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndate class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.date </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndecimal class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.decimal </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96rebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.int96RebaseModeInWrite </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetpushdowninfilterthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.pushdown.inFilterThreshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdownstringstartswith class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.string.startsWith </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowntimestamp class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.filterPushdown.timestamp </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96astimestamp class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.int96AsTimestamp </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96timestampconversion class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.int96TimestampConversion </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetoutputtimestamptype class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.outputTimestampType </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrecordlevelfilterenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.recordLevelFilter.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrespectsummaryfiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parquet.respectSummaryFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparserquotedregexcolumnnames class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.parser.quotedRegexColumnNames </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpivotmaxvalues class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.pivotMaxValues </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionoptionsregex class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.redaction.options.regex </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionstringregex class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.redaction.string.regex </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.runSQLOnFiles class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> spark.sql.runSQLOnFiles </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlselfjoinautoresolveambiguity class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.selfJoinAutoResolveAmbiguity </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsortenableradixsort class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sort.enableRadixSort </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesdefault class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.sources.default </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsfallbacktohdfs class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.fallBackToHdfs </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramnumbins class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.histogram.numBins </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsparallelfilelistinginstatscomputationenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statisticsparallelFileListingInStatsComputation.enabled* </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsndvmaxerror class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.ndv.maxError </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticspercentileaccuracy class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.percentile.accuracy </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticssizeautoupdateenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.statistics.size.autoUpdate.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsubexpressioneliminationenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.subexpressionElimination.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#spark.sql.subexpressionElimination.skipForShortcutExpr class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span><span> spark.sql.subexpressionElimination.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlshufflepartitions class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.shuffle.partitions </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesfilecompressionfactor class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.fileCompressionFactor </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcespartitionoverwritemode class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.sources.partitionOverwriteMode </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqltruncatetableignorepermissionaclenabled class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.truncateTable.ignorePermissionAcl.enabled </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqluiretainedexecutions class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.ui.retainedExecutions </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlvariablesubstitute class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.variable.substitute </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.windowExec.buffer.in.memory.threshold </span> </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> <span class=md-typeset> <span> spark.sql.windowExec.buffer.spill.threshold </span> </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=.. class=md-path__link> <span class=md-ellipsis> Spark SQL </span> </a> </li> <li class=md-path__item> <a href=../features/ class=md-path__link> <span class=md-ellipsis> Features </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=configuration-properties>Configuration Properties<a class=headerlink href=#configuration-properties title="Permanent link">&para;</a></h1> <p><strong>Configuration properties</strong> (aka <strong>settings</strong>) allow you to fine-tune a Spark SQL application.</p> <p>Configuration properties are configured in a <a href=../SparkSession/ >SparkSession</a> while creating a new instance using <a href=../SparkSession-Builder/#config>config</a> method (e.g. <a href=../StaticSQLConf/#spark.sql.warehouse.dir>spark.sql.warehouse.dir</a>).</p> <div class=highlight><pre><span></span><code><span class=k>import</span><span class=w> </span><span class=nn>org</span><span class=p>.</span><span class=nn>apache</span><span class=p>.</span><span class=nn>spark</span><span class=p>.</span><span class=nn>sql</span><span class=p>.</span><span class=nc>SparkSession</span>
<span class=kd>val</span><span class=w> </span><span class=n>spark</span><span class=p>:</span><span class=w> </span><span class=nc>SparkSession</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=nc>SparkSession</span><span class=p>.</span><span class=n>builder</span>
<span class=w>  </span><span class=p>.</span><span class=n>master</span><span class=p>(</span><span class=s>&quot;local[*]&quot;</span><span class=p>)</span>
<span class=w>  </span><span class=p>.</span><span class=n>appName</span><span class=p>(</span><span class=s>&quot;My Spark Application&quot;</span><span class=p>)</span>
<span class=w>  </span><span class=p>.</span><span class=n>config</span><span class=p>(</span><span class=s>&quot;spark.sql.warehouse.dir&quot;</span><span class=p>,</span><span class=w> </span><span class=s>&quot;c:/Temp&quot;</span><span class=p>)</span><span class=w> </span><span class=c1>// (1)!</span>
<span class=w>  </span><span class=p>.</span><span class=n>getOrCreate</span>
</code></pre></div> <ol> <li>Sets <a href=#spark.sql.warehouse.dir>spark.sql.warehouse.dir</a></li> </ol> <p>You can also set a property using SQL <code>SET</code> command.</p> <div class=highlight><pre><span></span><code>assert(spark.conf.getOption(&quot;spark.sql.hive.metastore.version&quot;).isEmpty)

scala&gt; spark.sql(&quot;SET spark.sql.hive.metastore.version=2.3.2&quot;).show(truncate = false)
+--------------------------------+-----+
|key                             |value|
+--------------------------------+-----+
|spark.sql.hive.metastore.version|2.3.2|
+--------------------------------+-----+

assert(spark.conf.get(&quot;spark.sql.hive.metastore.version&quot;) == &quot;2.3.2&quot;)
</code></pre></div> <h2 id=spark.sql.adaptive>spark.sql.adaptive<a class=headerlink href=#spark.sql.adaptive title="Permanent link">&para;</a></h2> <h3 id=spark.sql.adaptive.advisoryPartitionSizeInBytes>advisoryPartitionSizeInBytes<a class=headerlink href=#spark.sql.adaptive.advisoryPartitionSizeInBytes title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.advisoryPartitionSizeInBytes</strong></p> <p>The advisory size in bytes of the shuffle partition during adaptive optimization (when <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is enabled). It takes effect when Spark coalesces small shuffle partitions or splits skewed shuffle partition.</p> <p>Default: <code>64MB</code></p> <p>Fallback Property: <code>spark.sql.adaptive.shuffle.targetPostShuffleInputSize</code></p> <p>Use <a href=../SQLConf/#ADVISORY_PARTITION_SIZE_IN_BYTES>SQLConf.ADVISORY_PARTITION_SIZE_IN_BYTES</a> to reference the name.</p> <h3 id=spark.sql.adaptive.autoBroadcastJoinThreshold>autoBroadcastJoinThreshold<a class=headerlink href=#spark.sql.adaptive.autoBroadcastJoinThreshold title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.autoBroadcastJoinThreshold</strong></p> <p>The maximum size (in bytes) of a table to be broadcast when performing a join. <code>-1</code> turns broadcasting off. The default value is same as <a href=#spark.sql.autoBroadcastJoinThreshold>spark.sql.autoBroadcastJoinThreshold</a>.</p> <p>Used only in <a href=../adaptive-query-execution/ >Adaptive Query Execution</a></p> <p>Default: (undefined)</p> <p>Available as <a href=../SQLConf/#ADAPTIVE_AUTO_BROADCASTJOIN_THRESHOLD>SQLConf.ADAPTIVE_AUTO_BROADCASTJOIN_THRESHOLD</a> value.</p> <h3 id=spark.sql.adaptive.coalescePartitions.enabled>coalescePartitions.enabled<a class=headerlink href=#spark.sql.adaptive.coalescePartitions.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.coalescePartitions.enabled</strong></p> <p>Controls coalescing shuffle partitions</p> <p>When <code>true</code> and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is enabled, Spark will coalesce contiguous shuffle partitions according to the target size (specified by <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a>), to avoid too many small tasks.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#coalesceShufflePartitionsEnabled>SQLConf.coalesceShufflePartitionsEnabled</a> method to access the current value.</p> <h3 id=spark.sql.adaptive.coalescePartitions.minPartitionSize>coalescePartitions.minPartitionSize<a class=headerlink href=#spark.sql.adaptive.coalescePartitions.minPartitionSize title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.coalescePartitions.minPartitionSize</strong></p> <p>The minimum size (in bytes unless specified) of shuffle partitions after coalescing. This is useful when the adaptively calculated target size is too small during partition coalescing</p> <p>Default: <code>1MB</code></p> <p>Use <a href=../SQLConf/#coalesceShufflePartitionsEnabled>SQLConf.coalesceShufflePartitionsEnabled</a> method to access the current value.</p> <h3 id=spark.sql.adaptive.coalescePartitions.minPartitionSize><span id=COALESCE_PARTITIONS_MIN_PARTITION_SIZE><span id=COALESCE_PARTITIONS_MIN_PARTITION_NUM> coalescePartitions.minPartitionSize<a class=headerlink href=#spark.sql.adaptive.coalescePartitions.minPartitionSize title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.coalescePartitions.minPartitionSize</strong></p> <p>The minimum size (in bytes) of shuffle partitions after coalescing.</p> <p>Useful when the adaptively calculated target size is too small during partition coalescing.</p> <p>Default: <code>(undefined)</code></p> <p>Must be positive</p> <p>Used when:</p> <ul> <li><a href=../physical-optimizations/CoalesceShufflePartitions/ >CoalesceShufflePartitions</a> adaptive physical optimization is executed</li> </ul> <h3 id=spark.sql.adaptive.coalescePartitions.initialPartitionNum>coalescePartitions.initialPartitionNum<a class=headerlink href=#spark.sql.adaptive.coalescePartitions.initialPartitionNum title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.coalescePartitions.initialPartitionNum</strong></p> <p>The initial number of shuffle partitions before coalescing.</p> <p>By default it equals to <a href=#spark.sql.shuffle.partitions>spark.sql.shuffle.partitions</a>. If not set, the default value is the default parallelism of the Spark cluster. This configuration only has an effect when <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> and <a href=#spark.sql.adaptive.coalescePartitions.enabled>spark.sql.adaptive.coalescePartitions.enabled</a> are both enabled.</p> <p>Default: <code>(undefined)</code></p> <h3 id=spark.sql.adaptive.coalescePartitions.parallelismFirst>coalescePartitions.parallelismFirst<a class=headerlink href=#spark.sql.adaptive.coalescePartitions.parallelismFirst title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.coalescePartitions.parallelismFirst</strong></p> <p>When <code>true</code>, Spark does not respect the target size specified by <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a> when coalescing contiguous shuffle partitions, but adaptively calculate the target size according to the default parallelism of the Spark cluster. The calculated size is usually smaller than the configured target size. This is to maximize the parallelism and avoid performance regression when enabling adaptive query execution. It's recommended to set this config to <code>false</code> and respect the configured target size.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#coalesceShufflePartitionsEnabled>SQLConf.coalesceShufflePartitionsEnabled</a> method to access the current value.</p> <h3 id=spark.sql.adaptive.customCostEvaluatorClass>customCostEvaluatorClass<a class=headerlink href=#spark.sql.adaptive.customCostEvaluatorClass title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.customCostEvaluatorClass</strong></p> <p>The fully-qualified class name of the <a href=../adaptive-query-execution/CostEvaluator/ >CostEvaluator</a> in <a href=../adaptive-query-execution/ >Adaptive Query Execution</a></p> <p>Default: <a href=../adaptive-query-execution/SimpleCostEvaluator/ >SimpleCostEvaluator</a></p> <p>Use <a href=../SQLConf/#ADAPTIVE_CUSTOM_COST_EVALUATOR_CLASS>SQLConf.ADAPTIVE_CUSTOM_COST_EVALUATOR_CLASS</a> method to access the property (in a type-safe way).</p> <p>Used when:</p> <ul> <li><code>AdaptiveSparkPlanExec</code> physical operator is requested for the <a href=../physical-operators/AdaptiveSparkPlanExec/#costEvaluator>AQE cost evaluator</a></li> </ul> <h3 id=spark.sql.adaptive.enabled>enabled<a class=headerlink href=#spark.sql.adaptive.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.enabled</strong></p> <p>Enables <a href=../adaptive-query-execution/ >Adaptive Query Execution</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#adaptiveExecutionEnabled>SQLConf.adaptiveExecutionEnabled</a> method to access the current value.</p> <h3 id=spark.sql.adaptive.fetchShuffleBlocksInBatch>fetchShuffleBlocksInBatch<a class=headerlink href=#spark.sql.adaptive.fetchShuffleBlocksInBatch title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.fetchShuffleBlocksInBatch</strong></p> <p><strong>(internal)</strong> Whether to fetch the contiguous shuffle blocks in batch. Instead of fetching blocks one by one, fetching contiguous shuffle blocks for the same map task in batch can reduce IO and improve performance. Note, multiple contiguous blocks exist in single "fetch request only happen when <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> and <a href=#spark.sql.adaptive.coalescePartitions.enabled>spark.sql.adaptive.coalescePartitions.enabled</a> are both enabled. This feature also depends on a relocatable serializer, the concatenation support codec in use and the new version shuffle fetch protocol.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#fetchShuffleBlocksInBatch>SQLConf.fetchShuffleBlocksInBatch</a> method to access the current value.</p> <h3 id=spark.sql.adaptive.forceApply>forceApply<a class=headerlink href=#spark.sql.adaptive.forceApply title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.forceApply</strong></p> <p><strong>(internal)</strong> When <code>true</code> (together with <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> enabled), Spark will <a href=../physical-optimizations/InsertAdaptiveSparkPlan/#shouldApplyAQE>force apply adaptive query execution for all supported queries</a>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#ADAPTIVE_EXECUTION_FORCE_APPLY>SQLConf.ADAPTIVE_EXECUTION_FORCE_APPLY</a> method to access the property (in a type-safe way).</p> <h3 id=spark.sql.adaptive.forceOptimizeSkewedJoin>forceOptimizeSkewedJoin<a class=headerlink href=#spark.sql.adaptive.forceOptimizeSkewedJoin title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.forceOptimizeSkewedJoin</strong></p> <p>Enables <a href=../physical-optimizations/OptimizeSkewedJoin/ >OptimizeSkewedJoin</a> physical optimization to be executed even if it introduces extra shuffle</p> <p>Default: <code>false</code></p> <p>Requires <a href=#spark.sql.adaptive.skewJoin.enabled>spark.sql.adaptive.skewJoin.enabled</a> to be enabled</p> <p>Use <a href=../SQLConf/#ADAPTIVE_FORCE_OPTIMIZE_SKEWED_JOIN>SQLConf.ADAPTIVE_FORCE_OPTIMIZE_SKEWED_JOIN</a> to access the property (in a type-safe way).</p> <p>Used when:</p> <ul> <li><code>AdaptiveSparkPlanExec</code> physical operator is requested for the <a href=../physical-operators/AdaptiveSparkPlanExec/#costEvaluator>AQE cost evaluator</a> (and creates a <a href=../physical-operators/AdaptiveSparkPlanExec/#costEvaluator>SimpleCostEvaluator</a>)</li> <li><a href=../physical-optimizations/OptimizeSkewedJoin/ >OptimizeSkewedJoin</a> physical optimization is executed</li> </ul> <h3 id=spark.sql.adaptive.localShuffleReader.enabled>localShuffleReader.enabled<a class=headerlink href=#spark.sql.adaptive.localShuffleReader.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.localShuffleReader.enabled</strong></p> <p>When <code>true</code> (and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is <code>true</code>), Spark SQL tries to use local shuffle reader to read the shuffle data when the shuffle partitioning is not needed, for example, after converting sort-merge join to broadcast-hash join.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#LOCAL_SHUFFLE_READER_ENABLED>SQLConf.LOCAL_SHUFFLE_READER_ENABLED</a> to access the property (in a type-safe way)</p> <h3 id=spark.sql.adaptive.logLevel>logLevel<a class=headerlink href=#spark.sql.adaptive.logLevel title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.logLevel</strong></p> <p><strong>(internal)</strong> Log level for adaptive execution logging of plan changes. The value can be <code>TRACE</code>, <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code> or <code>ERROR</code>.</p> <p>Default: <code>DEBUG</code></p> <p>Use <a href=../SQLConf/#adaptiveExecutionLogLevel>SQLConf.adaptiveExecutionLogLevel</a> for the current value</p> <h3 id=spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold>maxShuffledHashJoinLocalMapThreshold<a class=headerlink href=#spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold</strong></p> <p>The maximum size (in bytes) per partition that can be allowed to build local hash map. If this value is not smaller than <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a> and all the partition size are not larger than this config, join selection prefer to use shuffled hash join instead of sort merge join regardless of the value of <a href=#spark.sql.join.preferSortMergeJoin>spark.sql.join.preferSortMergeJoin</a>.</p> <p>Default: <code>0</code></p> <p>Available as <a href=../SQLConf/#ADAPTIVE_MAX_SHUFFLE_HASH_JOIN_LOCAL_MAP_THRESHOLD>SQLConf.ADAPTIVE_MAX_SHUFFLE_HASH_JOIN_LOCAL_MAP_THRESHOLD</a></p> <h3 id=spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin>nonEmptyPartitionRatioForBroadcastJoin<a class=headerlink href=#spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin</strong></p> <p><strong>(internal)</strong> A relation with a non-empty partition ratio (the number of non-empty partitions to all partitions) lower than this config will not be considered as the build side of a broadcast-hash join in <a href=../adaptive-query-execution/ >Adaptive Query Execution</a> regardless of the size.</p> <p>Effective with <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> <code>true</code></p> <p>Default: <code>0.2</code></p> <p>Use <a href=../SQLConf/#nonEmptyPartitionRatioForBroadcastJoin>SQLConf.nonEmptyPartitionRatioForBroadcastJoin</a> method to access the current value.</p> <h3 id=spark.sql.adaptive.optimizer.excludedRules><span id=ADAPTIVE_OPTIMIZER_EXCLUDED_RULES> optimizer.excludedRules<a class=headerlink href=#spark.sql.adaptive.optimizer.excludedRules title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.optimizer.excludedRules</strong></p> <p>A comma-separated list of rules (names) to be disabled (<em>excluded</em>) in the <a href=../adaptive-query-execution/AQEOptimizer/ >AQE Logical Optimizer</a></p> <p>Default: undefined</p> <p>Use <a href=../SQLConf/#ADAPTIVE_OPTIMIZER_EXCLUDED_RULES>SQLConf.ADAPTIVE_OPTIMIZER_EXCLUDED_RULES</a> to reference the property.</p> <p>Used when:</p> <ul> <li><code>AQEOptimizer</code> is requested for the <a href=../adaptive-query-execution/AQEOptimizer/#batches>batches</a></li> </ul> <h3 id=spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled>optimizeSkewsInRebalancePartitions.enabled<a class=headerlink href=#spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled title="Permanent link">&para;</a></h3> <p>When <code>true</code> and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is <code>true</code>, Spark SQL will optimize the skewed shuffle partitions in RebalancePartitions and split them to smaller ones according to the target size (specified by <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a>), to avoid data skew</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#ADAPTIVE_OPTIMIZE_SKEWS_IN_REBALANCE_PARTITIONS_ENABLED>SQLConf.ADAPTIVE_OPTIMIZE_SKEWS_IN_REBALANCE_PARTITIONS_ENABLED</a> method to access the property (in a type-safe way)</p> <h3 id=spark.sql.adaptive.skewJoin.enabled>skewJoin.enabled<a class=headerlink href=#spark.sql.adaptive.skewJoin.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.skewJoin.enabled</strong></p> <p>When <code>true</code> and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is enabled, Spark dynamically handles skew in sort-merge join by splitting (and replicating if needed) skewed partitions.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#SKEW_JOIN_ENABLED>SQLConf.SKEW_JOIN_ENABLED</a> to reference the property.</p> <h3 id=spark.sql.adaptive.skewJoin.skewedPartitionFactor>skewJoin.skewedPartitionFactor<a class=headerlink href=#spark.sql.adaptive.skewJoin.skewedPartitionFactor title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.skewJoin.skewedPartitionFactor</strong></p> <p>A partition is considered skewed if its size is larger than this factor multiplying the median partition size and also larger than <a href=#spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes>spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes</a>.</p> <p>Default: <code>5</code></p> <h3 id=spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes>skewJoin.skewedPartitionThresholdInBytes<a class=headerlink href=#spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes title="Permanent link">&para;</a></h3> <p><strong>spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes</strong></p> <p>A partition is considered skewed if its size in bytes is larger than this threshold and also larger than <a href=#spark.sql.adaptive.skewJoin.skewedPartitionFactor>spark.sql.adaptive.skewJoin.skewedPartitionFactor</a> multiplying the median partition size. Ideally this config should be set larger than <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a>.</p> <p>Default: <code>256MB</code></p> <h2 id=spark.sql.allowNamedFunctionArguments><span id=ALLOW_NAMED_FUNCTION_ARGUMENTS> allowNamedFunctionArguments<a class=headerlink href=#spark.sql.allowNamedFunctionArguments title="Permanent link">&para;</a></h2> <p><strong>spark.sql.allowNamedFunctionArguments</strong></p> <p>Controls support for named parameters in function calls in SQL statements</p> <p>Default: <code>true</code></p> <p>Used when:</p> <ul> <li><code>AstBuilder</code> is requested to <a href=#visitTableValuedFunction>parse table-valued function</a> (and <a href=../sql/AstBuilder/#extractFunctionTableNamedArgument>extractFunctionTableNamedArgument</a> and <a href=../sql/AstBuilder/#extractNamedArgument>extractNamedArgument</a>)</li> </ul> <h2 id=autobroadcastjointhreshold><span id=spark.sql.autoBroadcastJoinThreshold><span id=AUTO_BROADCASTJOIN_THRESHOLD> autoBroadcastJoinThreshold<a class=headerlink href=#autobroadcastjointhreshold title="Permanent link">&para;</a></h2> <p><strong>spark.sql.autoBroadcastJoinThreshold</strong></p> <p>Maximum size (in bytes) for a table that can be broadcast (to all worker nodes) in a join</p> <p>Default: <code>10M</code></p> <p><code>-1</code> (or any negative value) disables broadcasting</p> <p>Use <a href=../SQLConf/#autoBroadcastJoinThreshold>SQLConf.autoBroadcastJoinThreshold</a> method to access the current value.</p> <h2 id=cacheserializer><span id=spark.sql.cache.serializer><span id=SPARK_CACHE_SERIALIZER> cache.serializer<a class=headerlink href=#cacheserializer title="Permanent link">&para;</a></h2> <p><strong>spark.sql.cache.serializer</strong></p> <p>The name of <a href=../cache-serialization/CachedBatchSerializer/ >CachedBatchSerializer</a> implementation to translate SQL data into a format that can more efficiently be cached.</p> <p>Default: <a href=../cache-serialization/DefaultCachedBatchSerializer/ >org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer</a></p> <p><code>spark.sql.cache.serializer</code> is a <a href=../StaticSQLConf/#SPARK_CACHE_SERIALIZER>StaticSQLConf</a></p> <p>Use <a href=../StaticSQLConf/#SPARK_CACHE_SERIALIZER>SQLConf.SPARK_CACHE_SERIALIZER</a> for the name</p> <p>Used when:</p> <ul> <li><code>InMemoryRelation</code> is requested for the <a href=../logical-operators/InMemoryRelation/#getSerializer>CachedBatchSerializer</a></li> </ul> <h2 id=spark.sql.codegen>spark.sql.codegen<a class=headerlink href=#spark.sql.codegen title="Permanent link">&para;</a></h2> <h3 id=spark.sql.codegen.aggregate.fastHashMap.capacityBit>aggregate.fastHashMap.capacityBit<a class=headerlink href=#spark.sql.codegen.aggregate.fastHashMap.capacityBit title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.aggregate.fastHashMap.capacityBit</strong></p> <p><strong>(internal)</strong> Capacity for the max number of rows to be held in memory by the fast hash aggregate product operator. The bit is not for actual value, but the actual <code>numBuckets</code> is determined by <code>loadFactor</code> (e.g., the default bit value <code>16</code>, the actual numBuckets is <code>((1 &lt;&lt; 16) / 0.5</code>).</p> <p>Default: <code>16</code></p> <p>Must be in the range of <code>[10, 30]</code> (inclusive)</p> <p>Use <a href=../SQLConf/#fastHashAggregateRowMaxCapacityBit>SQLConf.fastHashAggregateRowMaxCapacityBit</a> for the current value</p> <p>Used when:</p> <ul> <li><code>HashAggregateExec</code> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#doProduceWithKeys>doProduceWithKeys</a></li> </ul> <h3 id=spark.sql.codegen.aggregate.map.twolevel.enabled>aggregate.map.twolevel.enabled<a class=headerlink href=#spark.sql.codegen.aggregate.map.twolevel.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.aggregate.map.twolevel.enabled</strong></p> <p><strong>(internal)</strong> Enable two-level aggregate hash map. When enabled, records will first be inserted/looked-up at a 1<sup>st</sup>-level, small, fast map, and then fallback to a 2<sup>nd</sup>-level, larger, slower map when 1<sup>st</sup> level is full or keys cannot be found. When disabled, records go directly to the 2<sup>nd</sup> level.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#enableTwoLevelAggMap>SQLConf.enableTwoLevelAggMap</a> for the current value</p> <p>Used when:</p> <ul> <li><code>HashAggregateExec</code> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#doProduceWithKeys>doProduceWithKeys</a></li> </ul> <h3 id=spark.sql.codegen.aggregate.map.vectorized.enable>aggregate.map.vectorized.enable<a class=headerlink href=#spark.sql.codegen.aggregate.map.vectorized.enable title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.aggregate.map.vectorized.enable</strong></p> <p><strong>(internal)</strong> Enables vectorized aggregate hash map. For testing/benchmarking only.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#enableVectorizedHashMap>SQLConf.enableVectorizedHashMap</a> for the current value</p> <p>Used when:</p> <ul> <li><code>HashAggregateExec</code> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#enableTwoLevelHashMap>enableTwoLevelHashMap</a>, <a href=../physical-operators/HashAggregateExec/#doProduceWithKeys>doProduceWithKeys</a></li> </ul> <h3 id=spark.sql.codegen.aggregate.map.twolevel.partialOnly>aggregate.map.twolevel.partialOnly<a class=headerlink href=#spark.sql.codegen.aggregate.map.twolevel.partialOnly title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.aggregate.map.twolevel.partialOnly</strong></p> <p><strong>(internal)</strong> Enables two-level aggregate hash map for partial aggregate only, because final aggregate might get more distinct keys compared to partial aggregate. "Overhead of looking up 1<sup>st</sup>-level map might dominate when having a lot of distinct keys.</p> <p>Default: <code>true</code></p> <p>Used when:</p> <ul> <li><a href=../physical-operators/HashAggregateExec/ >HashAggregateExec</a> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#checkIfFastHashMapSupported>checkIfFastHashMapSupported</a></li> </ul> <h3 id=spark.sql.codegen.hugeMethodLimit>hugeMethodLimit<a class=headerlink href=#spark.sql.codegen.hugeMethodLimit title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.hugeMethodLimit</strong></p> <p><strong>(internal)</strong> The maximum bytecode size of a single compiled Java function generated by whole-stage codegen. When the compiled code has a function that exceeds this threshold, the whole-stage codegen is deactivated for this subtree of the query plan.</p> <p>Default: <code>65535</code></p> <p>The default value <code>65535</code> is the largest bytecode size possible for a valid Java method. When running on HotSpot, it may be preferable to set the value to <code>8000</code> (which is the value of <code>HugeMethodLimit</code> in the OpenJDK JVM settings)</p> <p>Use <a href=../SQLConf/#hugeMethodLimit>SQLConf.hugeMethodLimit</a> method to access the current value.</p> <p>Used when:</p> <ul> <li><code>WholeStageCodegenExec</code> physical operator is <a href=../physical-operators/WholeStageCodegenExec/#doExecute>executed</a></li> </ul> <h3 id=spark.sql.codegen.fallback>fallback<a class=headerlink href=#spark.sql.codegen.fallback title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.fallback</strong></p> <p><strong>(internal)</strong> Whether the whole-stage codegen could be temporary disabled for the part of a query that has failed to compile generated code (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageFallback>SQLConf.wholeStageFallback</a> method to access the current value.</p> <p>Used when:</p> <ul> <li><code>WholeStageCodegenExec</code> physical operator is <a href=../physical-operators/WholeStageCodegenExec/#doExecute>executed</a></li> </ul> <h3 id=spark.sql.codegen.join.fullOuterShuffledHashJoin.enabled>join.fullOuterShuffledHashJoin.enabled<a class=headerlink href=#spark.sql.codegen.join.fullOuterShuffledHashJoin.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.join.fullOuterShuffledHashJoin.enabled</strong></p> <p><strong>(internal)</strong> Enables <a href=../whole-stage-code-generation/ >Whole-Stage Code Generation</a> for FULL OUTER <a href=../physical-operators/ShuffledHashJoinExec/#supportCodegen>shuffled hash join</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#ENABLE_FULL_OUTER_SHUFFLED_HASH_JOIN_CODEGEN>SQLConf.ENABLE_FULL_OUTER_SHUFFLED_HASH_JOIN_CODEGEN</a> to access the property</p> <h3 id=spark.sql.codegen.methodSplitThreshold>methodSplitThreshold<a class=headerlink href=#spark.sql.codegen.methodSplitThreshold title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.methodSplitThreshold</strong></p> <p><strong>(internal)</strong> The threshold of source-code splitting in the codegen. When the number of characters in a single Java function (without comment) exceeds the threshold, the function will be automatically split to multiple smaller ones. We cannot know how many bytecode will be generated, so use the code length as metric. When running on HotSpot, a function's bytecode should not go beyond 8KB, otherwise it will not be JITted; it also should not be too small, otherwise there will be many function calls.</p> <p>Default: <code>1024</code></p> <p>Use <a href=../SQLConf/#methodSplitThreshold>SQLConf.methodSplitThreshold</a> for the current value</p> <h3 id=spark.sql.codegen.wholeStage>wholeStage<a class=headerlink href=#spark.sql.codegen.wholeStage title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.wholeStage</strong></p> <p><strong>(internal)</strong> Whether the whole stage (of multiple physical operators) will be compiled into a single Java method (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageEnabled>SQLConf.wholeStageEnabled</a> method to access the current value.</p> <h2 id=columnvectoroffheapenabled><span id=spark.sql.columnVector.offheap.enabled> columnVector.offheap.enabled<a class=headerlink href=#columnvectoroffheapenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.columnVector.offheap.enabled</strong></p> <p><strong>(internal)</strong> Enables <a href=../vectorized-decoding/OffHeapColumnVector/ >OffHeapColumnVector</a> (<code>true</code>) or <a href=../vectorized-decoding/OnHeapColumnVector/ >OnHeapColumnVector</a> (<code>false</code>) in <a href=../vectorized-query-execution/ColumnarBatch/ >ColumnarBatch</a></p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#offHeapColumnVectorEnabled>SQLConf.offHeapColumnVectorEnabled</a> for the current value</p> <p>Used when:</p> <ul> <li><code>RowToColumnarExec</code> physical operator is requested to <a href=../physical-operators/RowToColumnarExec/#doExecuteColumnar>doExecuteColumnar</a></li> <li><code>DefaultCachedBatchSerializer</code> is requested to <code>vectorTypes</code> and <code>convertCachedBatchToColumnarBatch</code></li> <li><code>ParquetFileFormat</code> is requested to <a href=../parquet/ParquetFileFormat/#vectorTypes>vectorTypes</a> and <a href=../parquet/ParquetFileFormat/#buildReaderWithPartitionValues>buildReaderWithPartitionValues</a></li> <li><code>ParquetPartitionReaderFactory</code> is <a href=../parquet/ParquetPartitionReaderFactory/#enableOffHeapColumnVector>created</a></li> </ul> <h2 id=defaultcolumnenabled><span id=spark.sql.defaultColumn.enabled> defaultColumn.enabled<a class=headerlink href=#defaultcolumnenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.defaultColumn.enabled</strong></p> <p><strong>(internal)</strong> When true, allows CREATE TABLE, REPLACE TABLE, and ALTER COLUMN statements to set or update default values for specific columns. Following INSERT, MERGE, and UPDATE statements may then omit these values and their values will be injected automatically instead.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#enableDefaultColumns>SQLConf.enableDefaultColumns</a> for the current value</p> <p>Used when:</p> <ul> <li><code>AstBuilder</code> is requested to <a href=../sql/AstBuilder/#visitCreateOrReplaceTableColType>visitCreateOrReplaceTableColType</a>, <a href=../sql/AstBuilder/#visitQualifiedColTypeWithPosition>visitQualifiedColTypeWithPosition</a>, <a href=../sql/AstBuilder/#visitAlterTableAlterColumn>visitAlterTableAlterColumn</a></li> <li><a href=../logical-analysis-rules/ResolveDefaultColumns/ >ResolveDefaultColumns</a> logical resolution rule is executed, <a href=../logical-analysis-rules/ResolveDefaultColumns/#constantFoldCurrentDefaultsToExistDefaults>constantFoldCurrentDefaultsToExistDefaults</a>, <a href=../logical-analysis-rules/ResolveDefaultColumns/#validateCatalogForDefaultValue>validateCatalogForDefaultValue</a>, <a href=../logical-analysis-rules/ResolveDefaultColumns/#validateTableProviderForDefaultValue>validateTableProviderForDefaultValue</a></li> </ul> <h2 id=exchangereuse><span id=spark.sql.exchange.reuse> exchange.reuse<a class=headerlink href=#exchangereuse title="Permanent link">&para;</a></h2> <p><strong>spark.sql.exchange.reuse</strong></p> <p><strong>(internal)</strong> When enabled (<code>true</code>), the <a href=../SparkPlanner/ >Spark planner</a> will find duplicated exchanges and subqueries and re-use them.</p> <p>When disabled (<code>false</code>), <a href=../physical-optimizations/ReuseExchange/ >ReuseExchange</a> and <a href=../physical-optimizations/ReuseSubquery/ >ReuseSubquery</a> physical optimizations (that the Spark planner uses for physical query plan optimization) do nothing.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#exchangeReuseEnabled>SQLConf.exchangeReuseEnabled</a> for the current value</p> <h2 id=spark.sql.execution>spark.sql.execution<a class=headerlink href=#spark.sql.execution title="Permanent link">&para;</a></h2> <h3 id=spark.sql.execution.arrow.pyspark.enabled>arrow.pyspark.enabled<a class=headerlink href=#spark.sql.execution.arrow.pyspark.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.arrow.pyspark.enabled</strong></p> <p>When true, make use of Apache Arrow for columnar data transfers in PySpark. This optimization applies to:</p> <ol> <li>pyspark.sql.DataFrame.toPandas</li> <li>pyspark.sql.SparkSession.createDataFrame when its input is a Pandas DataFrame</li> </ol> <p>The following data types are unsupported: BinaryType, MapType, <a href=../types/ArrayType/ >ArrayType</a> of TimestampType, and nested StructType.</p> <p>Default: <code>false</code></p> <h3 id=spark.sql.execution.arrow.pyspark.fallback.enabled>arrow.pyspark.fallback.enabled<a class=headerlink href=#spark.sql.execution.arrow.pyspark.fallback.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.arrow.pyspark.fallback.enabled</strong></p> <p>When true, optimizations enabled by <a href=#spark.sql.execution.arrow.pyspark.enabled>spark.sql.execution.arrow.pyspark.enabled</a> will fallback automatically to non-optimized implementations if an error occurs.</p> <p>Default: <code>true</code></p> <h3 id=spark.sql.execution.arrow.pyspark.selfDestruct.enabled>arrow.pyspark.selfDestruct.enabled<a class=headerlink href=#spark.sql.execution.arrow.pyspark.selfDestruct.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.arrow.pyspark.selfDestruct.enabled</strong></p> <p>(Experimental) When <code>true</code>, make use of Apache Arrow's self-destruct and split-blocks options for columnar data transfers in PySpark, when converting from Arrow to Pandas. This reduces memory usage at the cost of some CPU time. Applies to: <code>pyspark.sql.DataFrame.toPandas</code> when <a href=#spark.sql.execution.arrow.pyspark.enabled>spark.sql.execution.arrow.pyspark.enabled</a> is <code>true</code>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#arrowPySparkSelfDestructEnabled>SQLConf.arrowPySparkSelfDestructEnabled</a> for the current value</p> <h3 id=spark.sql.execution.pandas.convertToArrowArraySafely>pandas.convertToArrowArraySafely<a class=headerlink href=#spark.sql.execution.pandas.convertToArrowArraySafely title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.pandas.convertToArrowArraySafely</strong></p> <p><strong>(internal)</strong> When true, Arrow will perform safe type conversion when converting Pandas. Series to Arrow array during serialization. Arrow will raise errors when detecting unsafe type conversion like overflow. When false, disabling Arrow's type check and do type conversions anyway. This config only works for Arrow 0.11.0+.</p> <p>Default: <code>false</code></p> <h3 id=spark.sql.execution.pandas.udf.buffer.size>pandas.udf.buffer.size<a class=headerlink href=#spark.sql.execution.pandas.udf.buffer.size title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.pandas.udf.buffer.size</strong></p> <p>Same as <code>${BUFFER_SIZE.key}</code> but only applies to Pandas UDF executions. If it is not set, the fallback is <code>${BUFFER_SIZE.key}</code>. Note that Pandas execution requires more than 4 bytes. Lowering this value could make small Pandas UDF batch iterated and pipelined; however, it might degrade performance. See SPARK-27870.</p> <p>Default: <code>65536</code></p> <h3 id=spark.sql.execution.rangeExchange.sampleSizePerPartition>rangeExchange.sampleSizePerPartition<a class=headerlink href=#spark.sql.execution.rangeExchange.sampleSizePerPartition title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.rangeExchange.sampleSizePerPartition</strong></p> <p><strong>(internal)</strong> Number of points to sample per partition in order to determine the range boundaries for range partitioning, typically used in global sorting (without limit).</p> <p>Default: <code>100</code></p> <p>Use <a href=../SQLConf/#rangeExchangeSampleSizePerPartition>SQLConf.rangeExchangeSampleSizePerPartition</a> method to access the current value.</p> <h3 id=spark.sql.execution.removeRedundantSorts>removeRedundantSorts<a class=headerlink href=#spark.sql.execution.removeRedundantSorts title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.removeRedundantSorts</strong></p> <p><strong>(internal)</strong> Whether to remove redundant physical sort node</p> <p>Default: <code>true</code></p> <p>Used as <a href=../SQLConf/#REMOVE_REDUNDANT_SORTS_ENABLED>SQLConf.REMOVE_REDUNDANT_SORTS_ENABLED</a></p> <h3 id=spark.sql.execution.replaceHashWithSortAgg>replaceHashWithSortAgg<a class=headerlink href=#spark.sql.execution.replaceHashWithSortAgg title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.replaceHashWithSortAgg</strong></p> <p><strong>(internal)</strong> Enables replacing hash aggregate operators (i.e., <a href=../physical-operators/HashAggregateExec/ >HashAggregateExec</a> and <a href=../physical-operators/ObjectHashAggregateExec/ >ObjectHashAggregateExec</a>) with <a href=../physical-operators/SortAggregateExec/ >SortAggregateExec</a> based on children's ordering</p> <p>Default: <code>false</code></p> <p>Used when:</p> <ul> <li><a href=../physical-optimizations/ReplaceHashWithSortAgg/ >ReplaceHashWithSortAgg</a> physical optimization is executed</li> </ul> <h3 id=spark.sql.execution.reuseSubquery>reuseSubquery<a class=headerlink href=#spark.sql.execution.reuseSubquery title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.reuseSubquery</strong></p> <p><strong>(internal)</strong> When <code>true</code>, the planner will try to find duplicated subqueries and re-use them.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#subqueryReuseEnabled>SQLConf.subqueryReuseEnabled</a> for the current value</p> <h3 id=spark.sql.execution.sortBeforeRepartition>sortBeforeRepartition<a class=headerlink href=#spark.sql.execution.sortBeforeRepartition title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.sortBeforeRepartition</strong></p> <p><strong>(internal)</strong> When perform a repartition following a shuffle, the output row ordering would be nondeterministic. If some downstream stages fail and some tasks of the repartition stage retry, these tasks may generate different data, and that can lead to correctness issues. Turn on this config to insert a local sort before actually doing repartition to generate consistent repartition results. The performance of <code>repartition()</code> may go down since we insert extra local sort before it.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#sortBeforeRepartition>SQLConf.sortBeforeRepartition</a> method to access the current value.</p> <h3 id=spark.sql.execution.usePartitionEvaluator><span id=USE_PARTITION_EVALUATOR> usePartitionEvaluator<a class=headerlink href=#spark.sql.execution.usePartitionEvaluator title="Permanent link">&para;</a></h3> <p><strong>spark.sql.execution.usePartitionEvaluator</strong></p> <p><strong>(internal)</strong> Enables <code>PartitionEvaluator</code> (<a href=https://books.japila.pl/apache-spark-internals/PartitionEvaluator>Spark Core</a>) to <a href=../physical-operators/SparkPlan/#execute>execute physical operators</a> (using <code>RDD.mapPartitionsWithEvaluator</code> operator)</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#usePartitionEvaluator>SQLConf.usePartitionEvaluator</a> for the current value</p> <p>Used when:</p> <ul> <li><code>FilterExec</code> physical operator is <a href=../physical-operators/FilterExec/#doExecute>executed</a></li> <li><code>ProjectExec</code> physical operator is <a href=../physical-operators/ProjectExec/#doExecute>executed</a></li> <li><code>ColumnarToRowExec</code> physical operator is <a href=../physical-operators/ColumnarToRowExec/#doExecute>executed</a></li> <li><code>RowToColumnarExec</code> physical operator is <a href=../physical-operators/RowToColumnarExec/#doExecuteColumnar>executed</a></li> <li><code>WholeStageCodegenExec</code> physical operator is <a href=../physical-operators/WholeStageCodegenExec/#doExecute>executed</a></li> <li><code>SortMergeJoinExec</code> physical operator is <a href=../physical-operators/SortMergeJoinExec/#doExecute>executed</a></li> <li><code>MapInBatchExec</code> (<a href=https://books.japila.pl/pyspark-internals/sql/MapInBatchExec>PySpark</a>) physical operator is executed</li> <li><code>WindowGroupLimitExec</code> physical operator is executed</li> </ul> <h2 id=sparksqlhive><span id=spark.sql.hive> spark.sql.hive<a class=headerlink href=#sparksqlhive title="Permanent link">&para;</a></h2> <h3 id=filesourcepartitionfilecachesize><span id=spark.sql.hive.filesourcePartitionFileCacheSize> filesourcePartitionFileCacheSize<a class=headerlink href=#filesourcepartitionfilecachesize title="Permanent link">&para;</a></h3> <p><strong>spark.sql.hive.filesourcePartitionFileCacheSize</strong></p> <p>When greater than <code>0</code>, enables caching of partition file metadata in memory (using <a href=../files/SharedInMemoryCache/ >SharedInMemoryCache</a>). All tables share a cache that can use up to specified num bytes for file metadata.</p> <p>Requires <a href=#spark.sql.hive.manageFilesourcePartitions>spark.sql.hive.manageFilesourcePartitions</a> to be enabled</p> <p>Default: <code>250 * 1024 * 1024</code></p> <p>Use <a href=../SQLConf/#filesourcePartitionFileCacheSize>SQLConf.filesourcePartitionFileCacheSize</a> for the current value</p> <p>Used when:</p> <ul> <li><code>FileStatusCache</code> is requested to <a href=../files/FileStatusCache/#getOrCreate>look up the system-wide FileStatusCache</a></li> </ul> <h3 id=managefilesourcepartitions><span id=spark.sql.hive.manageFilesourcePartitions> manageFilesourcePartitions<a class=headerlink href=#managefilesourcepartitions title="Permanent link">&para;</a></h3> <p><strong>spark.sql.hive.manageFilesourcePartitions</strong></p> <p>Enables metastore partition management for file source tables.</p> <p>This includes both datasource and Hive tables. When partition management is enabled, datasource tables store partition in the Hive metastore, and use the metastore to prune partitions during query planning when <a href=#spark.sql.hive.metastorePartitionPruning>spark.sql.hive.metastorePartitionPruning</a> is enabled</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#manageFilesourcePartitions>SQLConf.manageFilesourcePartitions</a> for the current value</p> <p>Used when:</p> <ul> <li><code>HiveMetastoreCatalog</code> is requested to <a href=../hive/HiveMetastoreCatalog/#convertToLogicalRelation>convert a HiveTableRelation to a LogicalRelation over a HadoopFsRelation</a></li> <li><a href=../logical-operators/CreateDataSourceTableCommand/ >CreateDataSourceTableCommand</a>, <a href=../logical-operators/CreateDataSourceTableAsSelectCommand/ >CreateDataSourceTableAsSelectCommand</a> and <a href=../logical-operators/InsertIntoHadoopFsRelationCommand/ >InsertIntoHadoopFsRelationCommand</a> logical commands are executed</li> <li><code>DDLUtils</code> utility is used to <code>verifyPartitionProviderIsHive</code></li> <li><code>DataSource</code> is requested to <a href=../DataSource/#resolveRelation>resolve a BaseRelation</a> (for file-based data source tables and creates a <code>HadoopFsRelation</code>)</li> <li><code>FileStatusCache</code> is <a href=../files/FileStatusCache/#getOrCreate>created</a></li> <li><code>V2SessionCatalog</code> is requested to <a href=../V2SessionCatalog/#createTable>create a table</a> (<em>deprecated</em>)</li> </ul> <h2 id=inmemorycolumnarstoragepartitionpruning><span id=spark.sql.inMemoryColumnarStorage.partitionPruning> inMemoryColumnarStorage.partitionPruning<a class=headerlink href=#inmemorycolumnarstoragepartitionpruning title="Permanent link">&para;</a></h2> <p><strong>spark.sql.inMemoryColumnarStorage.partitionPruning</strong></p> <p><strong>(internal)</strong> Enables partition pruning for in-memory columnar tables</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#inMemoryPartitionPruning>SQLConf.inMemoryPartitionPruning</a> for the current value</p> <p>Used when:</p> <ul> <li><code>InMemoryTableScanExec</code> physical operator is requested to <a href=../physical-operators/InMemoryTableScanExec/#filteredCachedBatches>filter cached column batches</a></li> </ul> <h2 id=spark.sql.optimizer>spark.sql.optimizer<a class=headerlink href=#spark.sql.optimizer title="Permanent link">&para;</a></h2> <h3 id=spark.sql.optimizer.canChangeCachedPlanOutputPartitioning>canChangeCachedPlanOutputPartitioning<a class=headerlink href=#spark.sql.optimizer.canChangeCachedPlanOutputPartitioning title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.canChangeCachedPlanOutputPartitioning</strong></p> <p><strong>(internal)</strong> Whether to forcibly enable some optimization rules that can change the output partitioning of a cached query when executing it for caching. If it is set to true, queries may need an extra shuffle to read the cached data. This configuration is disabled by default. Currently, the optimization rules enabled by this configuration are <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> and <a href=#spark.sql.sources.bucketing.autoBucketedScan.enabled>spark.sql.sources.bucketing.autoBucketedScan.enabled</a>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#CAN_CHANGE_CACHED_PLAN_OUTPUT_PARTITIONING>SQLConf.CAN_CHANGE_CACHED_PLAN_OUTPUT_PARTITIONING</a> to access the property</p> <h3 id=spark.sql.optimizer.decorrelateInnerQuery.enabled>decorrelateInnerQuery.enabled<a class=headerlink href=#spark.sql.optimizer.decorrelateInnerQuery.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.decorrelateInnerQuery.enabled</strong></p> <p><strong>(internal)</strong> Decorrelates inner queries by eliminating correlated references and build domain joins</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#decorrelateInnerQueryEnabled>SQLConf.decorrelateInnerQueryEnabled</a> for the current value</p> <h3 id=spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio>dynamicPartitionPruning.fallbackFilterRatio<a class=headerlink href=#spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio</strong></p> <p><strong>(internal)</strong> When statistics are not available or configured not to be used, this config will be used as the fallback filter ratio for computing the data size of the partitioned table after dynamic partition pruning, in order to evaluate if it is worth adding an extra subquery as the pruning filter if broadcast reuse is not applicable.</p> <p>Default: <code>0.5</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningFallbackFilterRatio>SQLConf.dynamicPartitionPruningFallbackFilterRatio</a> method to access the current value.</p> <h3 id=spark.sql.optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio>dynamicPartitionPruning.pruningSideExtraFilterRatio<a class=headerlink href=#spark.sql.optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio</strong></p> <p><strong>(internal)</strong> When filtering side doesn't support broadcast by join type, and doing DPP means running an extra query that may have significant overhead. This config will be used as the extra filter ratio for computing the data size of the pruning side after DPP, in order to evaluate if it is worth adding an extra subquery as the pruning filter.</p> <p>Must be a double between <code>0.0</code> and <code>1.0</code></p> <p>Default: <code>0.04</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningPruningSideExtraFilterRatio>SQLConf.dynamicPartitionPruningPruningSideExtraFilterRatio</a> to access the current value.</p> <h3 id=spark.sql.optimizer.dynamicPartitionPruning.useStats>dynamicPartitionPruning.useStats<a class=headerlink href=#spark.sql.optimizer.dynamicPartitionPruning.useStats title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.useStats</strong></p> <p><strong>(internal)</strong> When true, distinct count statistics will be used for computing the data size of the partitioned table after dynamic partition pruning, in order to evaluate if it is worth adding an extra subquery as the pruning filter if broadcast reuse is not applicable.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningUseStats>SQLConf.dynamicPartitionPruningUseStats</a> for the current value</p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/PartitionPruning/ >PartitionPruning</a> logical optimization rule is <a href=../logical-optimizations/PartitionPruning/#pruningHasBenefit>executed</a></li> </ul> <h3 id=spark.sql.optimizer.dynamicPartitionPruning.enabled>dynamicPartitionPruning.enabled<a class=headerlink href=#spark.sql.optimizer.dynamicPartitionPruning.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.enabled</strong></p> <p>Enables generating predicates for partition columns used as join keys</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningEnabled>SQLConf.dynamicPartitionPruningEnabled</a> for the current value</p> <p>Used to control whether to execute the following optimizations or skip them altogether:</p> <ul> <li><a href=../logical-optimizations/CleanupDynamicPruningFilters/ >CleanupDynamicPruningFilters</a> logical optimization</li> <li><a href=../logical-optimizations/PartitionPruning/ >PartitionPruning</a> logical optimization</li> <li><a href=../physical-optimizations/PlanAdaptiveDynamicPruningFilters/ >PlanAdaptiveDynamicPruningFilters</a> physical optimization</li> <li><a href=../physical-optimizations/PlanDynamicPruningFilters/ >PlanDynamicPruningFilters</a> physical optimization</li> </ul> <h3 id=spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly>dynamicPartitionPruning.reuseBroadcastOnly<a class=headerlink href=#spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly</strong></p> <p><strong>(internal)</strong> When <code>true</code>, dynamic partition pruning will only apply when the broadcast exchange of a broadcast hash join operation can be reused as the dynamic pruning filter.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningReuseBroadcastOnly>SQLConf.dynamicPartitionPruningReuseBroadcastOnly</a> for the current value</p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/PartitionPruning/ >PartitionPruning</a> logical optimization is executed (and requested to <a href=../logical-optimizations/PartitionPruning/#insertPredicate>insertPredicate</a>)</li> </ul> <h3 id=spark.sql.optimizer.enableCsvExpressionOptimization>enableCsvExpressionOptimization<a class=headerlink href=#spark.sql.optimizer.enableCsvExpressionOptimization title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.enableCsvExpressionOptimization</strong></p> <p>Whether to optimize CSV expressions in SQL optimizer. It includes pruning unnecessary columns from <code>from_csv</code>.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#csvExpressionOptimization>SQLConf.csvExpressionOptimization</a> for the current value</p> <h3 id=spark.sql.optimizer.excludedRules>excludedRules<a class=headerlink href=#spark.sql.optimizer.excludedRules title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.excludedRules</strong></p> <p>Comma-separated list of fully-qualified class names of the optimization rules that should be disabled (excluded) from <a href=../catalyst/Optimizer/#spark.sql.optimizer.excludedRules>logical query optimization</a>.</p> <p>Default: <code>(empty)</code></p> <p>Use <a href=../SQLConf/#optimizerExcludedRules>SQLConf.optimizerExcludedRules</a> method to access the current value.</p> <div class="admonition important"> <p class=admonition-title>Important</p> <p>It is not guaranteed that all the rules to be excluded will eventually be excluded, as some rules are <a href=../catalyst/Optimizer/#nonExcludableRules>non-excludable</a>.</p> </div> <h3 id=spark.sql.optimizer.expressionProjectionCandidateLimit><span id=EXPRESSION_PROJECTION_CANDIDATE_LIMIT> expressionProjectionCandidateLimit<a class=headerlink href=#spark.sql.optimizer.expressionProjectionCandidateLimit title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.expressionProjectionCandidateLimit</strong></p> <p><strong>(internal)</strong> The maximum number of the candidates of output expressions whose alias are replaced. It can preserve the output partitioning and ordering. Negative value means disable this optimization.</p> <p>Default: <code>100</code></p> <p>Used when:</p> <ul> <li><code>AliasAwareOutputExpression</code> is requested for the <a href=../physical-operators/AliasAwareOutputExpression/#aliasCandidateLimit>aliasCandidateLimit</a></li> </ul> <h3 id=spark.sql.optimizer.expression.nestedPruning.enabled>expression.nestedPruning.enabled<a class=headerlink href=#spark.sql.optimizer.expression.nestedPruning.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.expression.nestedPruning.enabled</strong></p> <p><strong>(internal)</strong> Prune nested fields from expressions in an operator which are unnecessary in satisfying a query. Note that this optimization doesn't prune nested fields from physical data source scanning. For pruning nested fields from scanning, please use <a href=#spark.sql.optimizer.nestedSchemaPruning.enabled>spark.sql.optimizer.nestedSchemaPruning.enabled</a> config.</p> <p>Default: <code>true</code></p> <h3 id=spark.sql.optimizer.inSetConversionThreshold>inSetConversionThreshold<a class=headerlink href=#spark.sql.optimizer.inSetConversionThreshold title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.inSetConversionThreshold</strong></p> <p><strong>(internal)</strong> The threshold of set size for <code>InSet</code> conversion.</p> <p>Default: <code>10</code></p> <p>Use <a href=../SQLConf/#optimizerInSetConversionThreshold>SQLConf.optimizerInSetConversionThreshold</a> method to access the current value.</p> <h3 id=spark.sql.optimizer.inSetSwitchThreshold>inSetSwitchThreshold<a class=headerlink href=#spark.sql.optimizer.inSetSwitchThreshold title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.inSetSwitchThreshold</strong></p> <p><strong>(internal)</strong> Configures the max set size in InSet for which Spark will generate code with switch statements. This is applicable only to bytes, shorts, ints, dates.</p> <p>Must be non-negative and less than or equal to 600.</p> <p>Default: <code>400</code></p> <h3 id=spark.sql.optimizer.maxIterations>maxIterations<a class=headerlink href=#spark.sql.optimizer.maxIterations title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.maxIterations</strong></p> <p>Maximum number of iterations for <a href=../Analyzer/#fixedPoint>Analyzer</a> and <a href=../catalyst/Optimizer/#fixedPoint>Logical Optimizer</a>.</p> <p>Default: <code>100</code></p> <h3 id=spark.sql.optimizer.nestedSchemaPruning.enabled>nestedSchemaPruning.enabled<a class=headerlink href=#spark.sql.optimizer.nestedSchemaPruning.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.nestedSchemaPruning.enabled</strong></p> <p><strong>(internal)</strong> Prune nested fields from the output of a logical relation that are not necessary in satisfying a query. This optimization allows columnar file format readers to avoid reading unnecessary nested column data.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#nestedSchemaPruningEnabled>SQLConf.nestedSchemaPruningEnabled</a> method to access the current value.</p> <h3 id=spark.sql.optimizer.nestedPredicatePushdown.supportedFileSources>nestedPredicatePushdown.supportedFileSources<a class=headerlink href=#spark.sql.optimizer.nestedPredicatePushdown.supportedFileSources title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.nestedPredicatePushdown.supportedFileSources</strong></p> <p><strong>(internal)</strong> A comma-separated list of data source short names or fully qualified data source implementation class names for which Spark tries to push down predicates for nested columns and/or names containing <code>dots</code> to data sources. This configuration is only effective with file-based data source in DSv1. Currently, Parquet implements both optimizations while ORC only supports predicates for names containing <code>dots</code>. The other data sources don't support this feature yet.</p> <p>Default: <code>parquet,orc</code></p> <h3 id=spark.sql.optimizer.optimizeOneRowRelationSubquery>optimizeOneRowRelationSubquery<a class=headerlink href=#spark.sql.optimizer.optimizeOneRowRelationSubquery title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.optimizeOneRowRelationSubquery</strong></p> <p><strong>(internal)</strong> When <code>true</code>, the optimizer will inline subqueries with <code>OneRowRelation</code> leaf nodes</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#OPTIMIZE_ONE_ROW_RELATION_SUBQUERY>SQLConf.OPTIMIZE_ONE_ROW_RELATION_SUBQUERY</a> method to access the property (in a type-safe way)</p> <h3 id=spark.sql.optimizer.planChangeLog.batches>planChangeLog.batches<a class=headerlink href=#spark.sql.optimizer.planChangeLog.batches title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.planChangeLog.batches</strong></p> <p><strong>(internal)</strong> Configures a list of batches to be logged in the optimizer, in which the batches are specified by their batch names and separated by comma.</p> <p>Default: <code>(undefined)</code></p> <h3 id=spark.sql.optimizer.planChangeLog.level>planChangeLog.level<a class=headerlink href=#spark.sql.optimizer.planChangeLog.level title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.planChangeLog.level</strong></p> <p><strong>(internal)</strong> Configures the log level for logging the change from the original plan to the new plan after a rule or batch is applied. The value can be <code>TRACE</code>, <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code> or <code>ERROR</code>.</p> <p>Default: <code>TRACE</code></p> <h3 id=spark.sql.optimizer.planChangeLog.rules>planChangeLog.rules<a class=headerlink href=#spark.sql.optimizer.planChangeLog.rules title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.planChangeLog.rules</strong></p> <p><strong>(internal)</strong> Configures a list of rules to be logged in the optimizer, in which the rules are specified by their rule names and separated by comma.</p> <p>Default: <code>(undefined)</code></p> <h3 id=spark.sql.optimizer.propagateDistinctKeys.enabled>propagateDistinctKeys.enabled<a class=headerlink href=#spark.sql.optimizer.propagateDistinctKeys.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.propagateDistinctKeys.enabled</strong></p> <p><strong>(internal)</strong> Controls whether the <a href=../catalyst/Optimizer/ >Logical Query Optimizer</a> propagates the distinct attributes of logical operators for query optimization</p> <p>Default: <code>true</code></p> <p>Used when:</p> <ul> <li><code>LogicalPlanDistinctKeys</code> logical operator is requested for the <a href=../logical-operators/LogicalPlanDistinctKeys/#distinctKeys>distinct keys</a></li> </ul> <h3 id=spark.sql.optimizer.replaceExceptWithFilter>replaceExceptWithFilter<a class=headerlink href=#spark.sql.optimizer.replaceExceptWithFilter title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.replaceExceptWithFilter</strong></p> <p><strong>(internal)</strong> When <code>true</code>, the <code>apply</code> function of the rule verifies whether the right node of the <code>except</code> operation is of type <code>Filter</code> or <code>Project</code> followed by <code>Filter</code>. If so, the rule further verifies the following conditions:</p> <ol> <li>Excluding the filter operations from the right (as well as the left node, if any) on the top, whether both the nodes evaluates to a same result</li> <li>The left and right nodes don't contain any <a href=../expressions/SubqueryExpression/ >SubqueryExpression</a>s</li> <li>The output column names of the left node are distinct</li> </ol> <p>If all the conditions are met, the rule will replace the <code>except</code> operation with a <code>Filter</code> by flipping the filter condition(s) of the right node.</p> <p>Default: <code>true</code></p> <h3 id=spark.sql.optimizer.runtime.bloomFilter.creationSideThreshold>runtime.bloomFilter.creationSideThreshold<a class=headerlink href=#spark.sql.optimizer.runtime.bloomFilter.creationSideThreshold title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.runtime.bloomFilter.creationSideThreshold</strong></p> <p>Size threshold of the bloom filter creation side plan. Estimated size needs to be under this value to try to inject bloom filter.</p> <p>Default: <code>10MB</code></p> <p>Use <a href=../SQLConf/#runtimeFilterCreationSideThreshold>SQLConf.runtimeFilterCreationSideThreshold</a> for the current value</p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/InjectRuntimeFilter/ >InjectRuntimeFilter</a> logical optimization is executed (to <a href=../logical-optimizations/InjectRuntimeFilter/#injectBloomFilter>injectBloomFilter</a>)</li> </ul> <h3 id=spark.sql.optimizer.runtime.bloomFilter.enabled>runtime.bloomFilter.enabled<a class=headerlink href=#spark.sql.optimizer.runtime.bloomFilter.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.runtime.bloomFilter.enabled</strong></p> <p>Enables a bloom filter on one side of a shuffle join if the other side has a selective predicate (to reduce the amount of shuffle data)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#runtimeFilterBloomFilterEnabled>SQLConf.runtimeFilterBloomFilterEnabled</a> for the current value</p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/InjectRuntimeFilter/ >InjectRuntimeFilter</a> logical optimization is executed</li> </ul> <h3 id=spark.sql.optimizer.runtime.bloomFilter.expectedNumItems>runtime.bloomFilter.expectedNumItems<a class=headerlink href=#spark.sql.optimizer.runtime.bloomFilter.expectedNumItems title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.runtime.bloomFilter.expectedNumItems</strong></p> <p>The default number of expected items for the runtime bloomfilter</p> <p>Default: <code>1000000L</code></p> <p><a href=../SQLConf/#RUNTIME_BLOOM_FILTER_EXPECTED_NUM_ITEMS>SQLConf.RUNTIME_BLOOM_FILTER_EXPECTED_NUM_ITEMS</a></p> <p>Used when:</p> <ul> <li><a href=../expressions/BloomFilterAggregate/#estimatedNumItemsExpression>BloomFilterAggregate</a> expression is created</li> </ul> <h3 id=spark.sql.optimizer.runtime.bloomFilter.maxNumBits>runtime.bloomFilter.maxNumBits<a class=headerlink href=#spark.sql.optimizer.runtime.bloomFilter.maxNumBits title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.runtime.bloomFilter.maxNumBits</strong></p> <p>Maximum number of bits for the runtime bloom filter</p> <p>Default: <code>67108864L</code> (8MB)</p> <p>Must be a <a href=../expressions/BloomFilterAggregate/#checkInputDataTypes>non-zero positive number</a></p> <p><a href=../SQLConf/#RUNTIME_BLOOM_FILTER_MAX_NUM_BITS>SQLConf.RUNTIME_BLOOM_FILTER_MAX_NUM_BITS</a></p> <p>Used when:</p> <ul> <li><code>BloomFilterAggregate</code> is requested to <a href=../expressions/BloomFilterAggregate/#checkInputDataTypes>checkInputDataTypes</a> and for the <a href=../expressions/BloomFilterAggregate/#numBits>numBits</a></li> </ul> <h3 id=spark.sql.optimizer.runtime.rowLevelOperationGroupFilter.enabled><span id=RUNTIME_ROW_LEVEL_OPERATION_GROUP_FILTER_ENABLED> runtime.rowLevelOperationGroupFilter.enabled<a class=headerlink href=#spark.sql.optimizer.runtime.rowLevelOperationGroupFilter.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.runtime.rowLevelOperationGroupFilter.enabled</strong></p> <p>Enables runtime group filtering for group-based row-level operations.</p> <p>Data sources that replace groups of data (e.g. files, partitions) may prune entire groups using provided data source filters when planning a row-level operation scan. However, such filtering is limited as not all expressions can be converted into data source filters and some expressions can only be evaluated by Spark (e.g. subqueries). Since rewriting groups is expensive, Spark can execute a query at runtime to find what records match the condition of the row-level operation. The information about matching records will be passed back to the row-level operation scan, allowing data sources to discard groups that don't have to be rewritten.</p> <p>Default: <code>true</code></p> <p>Current value: <a href=../SQLConf/#runtimeRowLevelOperationGroupFilterEnabled>SQLConf.runtimeRowLevelOperationGroupFilterEnabled</a></p> <p>Used when:</p> <ul> <li><code>RowLevelOperationRuntimeGroupFiltering</code> logical optimization is executed</li> </ul> <h3 id=spark.sql.optimizer.runtimeFilter.number.threshold>runtimeFilter.number.threshold<a class=headerlink href=#spark.sql.optimizer.runtimeFilter.number.threshold title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.runtimeFilter.number.threshold</strong></p> <p>The total number of injected runtime filters (non-DPP) for a single query. This is to prevent driver OOMs with too many Bloom filters.</p> <p>Default: <code>10</code></p> <p>Must be a non-zero positive number</p> <p><a href=../SQLConf/#RUNTIME_FILTER_NUMBER_THRESHOLD>SQLConf.RUNTIME_FILTER_NUMBER_THRESHOLD</a></p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/InjectRuntimeFilter/ >InjectRuntimeFilter</a> logical optimization is executed</li> </ul> <h3 id=spark.sql.optimizer.runtimeFilter.semiJoinReduction.enabled>runtimeFilter.semiJoinReduction.enabled<a class=headerlink href=#spark.sql.optimizer.runtimeFilter.semiJoinReduction.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.runtimeFilter.semiJoinReduction.enabled</strong></p> <p>Enables inserting a semi join on one side of a shuffle join if the other side has a selective predicate (to reduce the amount of shuffle data)</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#runtimeFilterSemiJoinReductionEnabled>SQLConf.runtimeFilterSemiJoinReductionEnabled</a> for the current value</p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/InjectRuntimeFilter/ >InjectRuntimeFilter</a> logical optimization is executed</li> </ul> <h3 id=spark.sql.optimizer.serializer.nestedSchemaPruning.enabled>serializer.nestedSchemaPruning.enabled<a class=headerlink href=#spark.sql.optimizer.serializer.nestedSchemaPruning.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.optimizer.serializer.nestedSchemaPruning.enabled</strong></p> <p><strong>(internal)</strong> Prune nested fields from object serialization operator which are unnecessary in satisfying a query. This optimization allows object serializers to avoid executing unnecessary nested expressions.</p> <p>Default: <code>true</code></p> <h2 id=spark.sql>spark.sql<a class=headerlink href=#spark.sql title="Permanent link">&para;</a></h2> <h3 id=spark.sql.retainGroupColumns><span id=DATAFRAME_RETAIN_GROUP_COLUMNS> retainGroupColumns<a class=headerlink href=#spark.sql.retainGroupColumns title="Permanent link">&para;</a></h3> <p><strong>spark.sql.retainGroupColumns</strong></p> <p><strong>(internal)</strong> Controls whether to <a href=../RelationalGroupedDataset/#toDF>include (retain) grouping columns or not</a> in <a href=../aggregations/ >Aggregation Queries</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dataFrameRetainGroupColumns>SQLConf.dataFrameRetainGroupColumns</a> for the current value</p> <h2 id=spark.sql.files>spark.sql.files<a class=headerlink href=#spark.sql.files title="Permanent link">&para;</a></h2> <h3 id=spark.sql.files.maxPartitionBytes><span id=FILES_MAX_PARTITION_BYTES> maxPartitionBytes<a class=headerlink href=#spark.sql.files.maxPartitionBytes title="Permanent link">&para;</a></h3> <p><strong>spark.sql.files.maxPartitionBytes</strong></p> <p>Maximum number of bytes to pack into a single partition when reading files for file-based data sources (e.g., <a href=../parquet/ >Parquet</a>)</p> <p>Default: <code>128MB</code> (like <code>parquet.block.size</code>)</p> <p>Use <a href=../SQLConf/#filesMaxPartitionBytes>SQLConf.filesMaxPartitionBytes</a> for the current value</p> <p>Used when:</p> <ul> <li><code>FilePartition</code> is requested for <a href=../files/FilePartition/#maxSplitBytes>maxSplitBytes</a></li> </ul> <h3 id=spark.sql.files.maxPartitionNum><span id=FILES_MAX_PARTITION_NUM> maxPartitionNum<a class=headerlink href=#spark.sql.files.maxPartitionNum title="Permanent link">&para;</a></h3> <p><strong>spark.sql.files.maxPartitionNum</strong></p> <p>The suggested (not guaranteed) maximum number of split file partitions. If set, Spark will rescale each partition to make the number of partitions close to this value if the initial number of partitions exceeds this value.</p> <p>Effective only with file-based sources such as Parquet, JSON and ORC.</p> <p>Default: <code>(undefined)</code></p> <p>Use <a href=../SQLConf/#filesMaxPartitionNum>SQLConf.filesMaxPartitionNum</a> for the current value</p> <p>Used when:</p> <ul> <li><code>FilePartition</code> is requested for the <a href=../files/FilePartition/#getFilePartitions>file partitions</a></li> </ul> <h3 id=spark.sql.files.maxRecordsPerFile><span id=MAX_RECORDS_PER_FILE> maxRecordsPerFile<a class=headerlink href=#spark.sql.files.maxRecordsPerFile title="Permanent link">&para;</a></h3> <p><strong>spark.sql.files.maxRecordsPerFile</strong></p> <p>Maximum number of records to write out to a single file. If <code>0</code> or negative, there is no limit.</p> <p>Default: <code>0</code></p> <p>Use <a href=../SQLConf/#maxRecordsPerFile>SQLConf.maxRecordsPerFile</a> method for the current value</p> <p>Used when:</p> <ul> <li><code>FileFormatWriter</code> is requested to <a href=../files/FileFormatWriter/#write>write data out</a></li> <li><code>FileWrite</code> is requested for a <a href=../files/FileWrite/#toBatch>BatchWrite</a> (and <a href=../files/FileWrite/#createWriteJobDescription>creates a WriteJobDescription</a>)</li> </ul> <h3 id=spark.sql.files.minPartitionNum><span id=FILES_MIN_PARTITION_NUM> minPartitionNum<a class=headerlink href=#spark.sql.files.minPartitionNum title="Permanent link">&para;</a></h3> <p><strong>spark.sql.files.minPartitionNum</strong></p> <p>Hint about the minimum number of partitions for file-based data sources (e.g., <a href=../parquet/ >Parquet</a>)</p> <p>Default: <a href=../SparkSession/#leafNodeDefaultParallelism>spark.sql.leafNodeDefaultParallelism</a></p> <p>Use <a href=../SQLConf/#filesMinPartitionNum>SQLConf.filesMinPartitionNum</a> for the current value</p> <p>Used when:</p> <ul> <li><code>FilePartition</code> is requested for <a href=../files/FilePartition/#maxSplitBytes>maxSplitBytes</a></li> </ul> <h3 id=spark.sql.files.openCostInBytes><span id=FILES_OPEN_COST_IN_BYTES> openCostInBytes<a class=headerlink href=#spark.sql.files.openCostInBytes title="Permanent link">&para;</a></h3> <p><strong>spark.sql.files.openCostInBytes</strong></p> <p><strong>(internal)</strong> The estimated cost to open a file, measured by the number of bytes could be scanned at the same time (to include multiple files into a partition). Effective only for file-based sources such as Parquet, JSON and ORC.</p> <p>Default: <code>4MB</code></p> <p>It's better to over-estimate it, then the partitions with small files will be faster than partitions with bigger files (which is scheduled first).</p> <p>Use <a href=../SQLConf/#filesOpenCostInBytes>SQLConf.filesOpenCostInBytes</a> for the current value</p> <p>Used when:</p> <ul> <li><code>FileSourceScanExec</code> physical operator is requested to <a href=../physical-operators/FileSourceScanExec/#createReadRDD>create an RDD for a non-bucketed read</a></li> <li><code>FilePartition</code> is requested to <a href=../files/FilePartition/#getFilePartitions>getFilePartitions</a> and <a href=../files/FilePartition/#maxSplitBytes>maxSplitBytes</a></li> </ul> <h2 id=spark.sql.parquet>spark.sql.parquet<a class=headerlink href=#spark.sql.parquet title="Permanent link">&para;</a></h2> <h3 id=spark.sql.parquet.aggregatePushdown>aggregatePushdown<a class=headerlink href=#spark.sql.parquet.aggregatePushdown title="Permanent link">&para;</a></h3> <p><strong>spark.sql.parquet.aggregatePushdown</strong></p> <p>Controls <a href=../parquet/ParquetScanBuilder/#pushAggregation>aggregate pushdown</a> in <a href=../parquet/ >parquet connector</a></p> <p>Supports MIN, MAX and COUNT as aggregate expression:</p> <ul> <li>For MIN/MAX, support boolean, integer, float and date types.</li> <li>For COUNT, support all data types.</li> </ul> <p>If statistics is missing from any Parquet file footer, exception would be thrown.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#parquetAggregatePushDown>SQLConf.parquetAggregatePushDown</a> for the current value</p> <p>Used when:</p> <ul> <li><code>ParquetScanBuilder</code> is requested to <a href=../parquet/ParquetScanBuilder/#pushAggregation>pushAggregation</a></li> </ul> <h3 id=spark.sql.parquet.columnarReaderBatchSize>columnarReaderBatchSize<a class=headerlink href=#spark.sql.parquet.columnarReaderBatchSize title="Permanent link">&para;</a></h3> <p><strong>spark.sql.parquet.columnarReaderBatchSize</strong></p> <p>The number of rows to include in a parquet vectorized reader batch (the capacity of <a href=../parquet/VectorizedParquetRecordReader/ >VectorizedParquetRecordReader</a>)</p> <p>Default: <code>4096</code> (4k)</p> <p>The number should be carefully chosen to minimize overhead and avoid OOMs while reading data.</p> <p>Use <a href=../SQLConf/#parquetVectorizedReaderBatchSize>SQLConf.parquetVectorizedReaderBatchSize</a> for the current value</p> <p>Used when:</p> <ul> <li><code>ParquetFileFormat</code> is requested for a <a href=../parquet/ParquetFileFormat/#buildReaderWithPartitionValues>data reader</a> (and creates a <a href=../parquet/VectorizedParquetRecordReader/ >VectorizedParquetRecordReader</a> for <a href=../vectorized-decoding/ >Vectorized Parquet Decoding</a>)</li> <li><code>ParquetPartitionReaderFactory</code> is <a href=../parquet/ParquetPartitionReaderFactory/#capacity>created</a></li> <li><code>WritableColumnVector</code> is requested to <code>reserve</code> required capacity (and fails)</li> </ul> <h3 id=spark.sql.parquet.enableNestedColumnVectorizedReader>enableNestedColumnVectorizedReader<a class=headerlink href=#spark.sql.parquet.enableNestedColumnVectorizedReader title="Permanent link">&para;</a></h3> <p><strong>spark.sql.parquet.enableNestedColumnVectorizedReader</strong></p> <p>Enables <a href=../vectorized-decoding/ >vectorized parquet decoding</a> for nested columns (e.g., <a href=../types/ArrayType/ >array</a>s, <a href=../types/StructType/ >struct</a>s and maps). Requires <a href=#spark.sql.parquet.enableVectorizedReader>spark.sql.parquet.enableVectorizedReader</a> to be enabled</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetVectorizedReaderNestedColumnEnabled>SQLConf.parquetVectorizedReaderNestedColumnEnabled</a> for the current value</p> <p>Used when:</p> <ul> <li><code>ParquetUtils</code> is requested to <a href=../parquet/ParquetUtils/#isBatchReadSupported>isBatchReadSupported</a></li> </ul> <h3 id=spark.sql.parquet.filterPushdown>filterPushdown<a class=headerlink href=#spark.sql.parquet.filterPushdown title="Permanent link">&para;</a></h3> <p><strong>spark.sql.parquet.filterPushdown</strong></p> <p>Controls filter predicate push-down optimization for <a href=../parquet/ >parquet connector</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDown>SQLConf.parquetFilterPushDown</a> for the current value</p> <p>Used when:</p> <ul> <li><code>ParquetFileFormat</code> is <a href=../parquet/ParquetFileFormat/#enableParquetFilterPushDown>created</a></li> <li><code>ParquetPartitionReaderFactory</code> is <a href=../parquet/ParquetPartitionReaderFactory/#enableParquetFilterPushDown>created</a></li> <li><code>ParquetScanBuilder</code> is requested to <a href=../parquet/ParquetScanBuilder/#pushDataFilters>pushDataFilters</a></li> </ul> <h3 id=spark.sql.parquet.filterPushdown.stringPredicate>filterPushdown.stringPredicate<a class=headerlink href=#spark.sql.parquet.filterPushdown.stringPredicate title="Permanent link">&para;</a></h3> <p><strong>spark.sql.parquet.filterPushdown.stringPredicate</strong></p> <p><strong>(internal)</strong> Controls Parquet filter push-down optimization for string predicate such as startsWith/endsWith/contains functions. Effective only with <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> enabled.</p> <p>Default: <a href=#spark.sql.parquet.filterPushdown.string.startsWith>spark.sql.parquet.filterPushdown.string.startsWith</a></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownStringPredicate>SQLConf.parquetFilterPushDownStringPredicate</a> for the current value</p> <p>Used when:</p> <ul> <li><code>ParquetFileFormat</code> is requested to <a href=../parquet/ParquetFileFormat/#buildReaderWithPartitionValues>buildReaderWithPartitionValues</a></li> <li><code>ParquetPartitionReaderFactory</code> is <a href=../parquet/ParquetPartitionReaderFactory/#pushDownStringPredicate>created</a></li> <li><code>ParquetScanBuilder</code> is requested to <a href=../parquet/ParquetScanBuilder/#pushDataFilters>pushDataFilters</a></li> </ul> <h3 id=spark.sql.parquet.mergeSchema>mergeSchema<a class=headerlink href=#spark.sql.parquet.mergeSchema title="Permanent link">&para;</a></h3> <p><strong>spark.sql.parquet.mergeSchema</strong></p> <p>Controls whether the Parquet data source merges schemas collected from all data files or not. If <code>false</code>, the schema is picked from the summary file or a random data file if no summary file is available.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#isParquetSchemaMergingEnabled>SQLConf.isParquetSchemaMergingEnabled</a> for the current value</p> <p>Parquet option (of higher priority): <a href=../parquet/ParquetOptions/#mergeSchema>mergeSchema</a></p> <p>Used when:</p> <ul> <li><code>ParquetOptions</code> is created (and initializes <a href=../parquet/ParquetOptions/#mergeSchema>mergeSchema</a> option)</li> </ul> <h3 id=spark.sql.parquet.output.committer.class><span id=PARQUET_OUTPUT_COMMITTER_CLASS> output.committer.class<a class=headerlink href=#spark.sql.parquet.output.committer.class title="Permanent link">&para;</a></h3> <p><strong>spark.sql.parquet.output.committer.class</strong></p> <p><strong>(internal)</strong> The output committer class used by <a href=../parquet/ >parquet</a> data source. The specified class needs to be a subclass of <code>org.apache.hadoop.mapreduce.OutputCommitter</code>. Typically, it's also a subclass of <code>org.apache.parquet.hadoop.ParquetOutputCommitter</code>. If it is not, then metadata summaries will never be created, irrespective of the value of <code>parquet.summary.metadata.level</code>.</p> <p>Default: <code>org.apache.parquet.hadoop.ParquetOutputCommitter</code></p> <p>Use <a href=../SQLConf/#parquetOutputCommitterClass>SQLConf.parquetOutputCommitterClass</a> for the current value</p> <p>Used when:</p> <ul> <li><code>ParquetUtils</code> is requested to <a href=../parquet/ParquetUtils/#prepareWrite>prepareWrite</a></li> </ul> <h2 id=spark.sql.sources>spark.sql.sources<a class=headerlink href=#spark.sql.sources title="Permanent link">&para;</a></h2> <h3 id=spark.sql.sources.bucketing.enabled>bucketing.enabled<a class=headerlink href=#spark.sql.sources.bucketing.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.sources.bucketing.enabled</strong></p> <p>Enables <a href=../bucketing/ >Bucketing</a></p> <p>Default: <code>true</code></p> <p>When disabled (i.e. <code>false</code>), bucketed tables are considered regular (non-bucketed) tables.</p> <p>Use <a href=../SQLConf/#bucketingEnabled>SQLConf.bucketingEnabled</a> method for the current value</p> <h3 id=spark.sql.sources.commitProtocolClass>commitProtocolClass<a class=headerlink href=#spark.sql.sources.commitProtocolClass title="Permanent link">&para;</a></h3> <p><strong>spark.sql.sources.commitProtocolClass</strong></p> <p><strong>(internal)</strong> Fully-qualified class name of a <code>FileCommitProtocol</code> (<a href=https://books.japila.pl/apache-spark-internals/FileCommitProtocol>Spark Core</a>) for <a href=../transactional-writes/ >Transactional Writes</a></p> <p>Default: <a href=../transactional-writes/SQLHadoopMapReduceCommitProtocol/ >SQLHadoopMapReduceCommitProtocol</a></p> <p>Use <a href=../SQLConf/#fileCommitProtocolClass>SQLConf.fileCommitProtocolClass</a> method for the current value</p> <p>Used when:</p> <ul> <li><code>FileWrite</code> is requested for a <a href=../files/FileWrite/#toBatch>BatchWrite</a></li> <li><a href=../logical-operators/InsertIntoHadoopFsRelationCommand/ >InsertIntoHadoopFsRelationCommand</a> logical command is executed</li> <li><code>SaveAsHiveFile</code> is requested to <a href=../hive/SaveAsHiveFile/#saveAsHiveFile>saveAsHiveFile</a></li> </ul> <h3 id=spark.sql.sources.outputCommitterClass><span id=OUTPUT_COMMITTER_CLASS> outputCommitterClass<a class=headerlink href=#spark.sql.sources.outputCommitterClass title="Permanent link">&para;</a></h3> <p><strong>spark.sql.sources.outputCommitterClass</strong></p> <p><strong>(internal)</strong> The fully-qualified class name of the user-defined Hadoop <a href=https://hadoop.apache.org/docs/r3.3.4/api/org/apache/hadoop/mapreduce/OutputCommitter.html>OutputCommitter</a> for <a href=../transactional-writes/SQLHadoopMapReduceCommitProtocol/#setupCommitter>SQLHadoopMapReduceCommitProtocol</a></p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#OUTPUT_COMMITTER_CLASS>SQLConf.OUTPUT_COMMITTER_CLASS</a> to access the property</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p><code>ParquetUtils</code> uses <a href=#spark.sql.parquet.output.committer.class>spark.sql.parquet.output.committer.class</a> or the default <code>ParquetOutputCommitter</code> instead.</p> </div> <h2 id=sparksqlobjecthashaggregatesortbasedfallbackthreshold><span id=spark.sql.objectHashAggregate.sortBased.fallbackThreshold> spark.sql.objectHashAggregate.sortBased.fallbackThreshold<a class=headerlink href=#sparksqlobjecthashaggregatesortbasedfallbackthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The number of entires in an in-memory hash map (to store aggregation buffers per grouping keys) before <a href=../physical-operators/ObjectHashAggregateExec/ >ObjectHashAggregateExec</a> (<a href=../aggregations/ObjectAggregationIterator/#processInputs>ObjectAggregationIterator</a>, precisely) falls back to sort-based aggregation</p> <p>Default: <code>128</code> (entries)</p> <p>Use <a href=../SQLConf/#objectAggSortBasedFallbackThreshold>SQLConf.objectAggSortBasedFallbackThreshold</a> for the current value</p> <p>Learn more in <a href=../demo/objecthashaggregateexec-sort-based-fallback-tasks/ >Demo: ObjectHashAggregateExec and Sort-Based Fallback Tasks</a></p> <h2 id=sparksqllegacyallownonemptylocationinctas><span id=spark.sql.legacy.allowNonEmptyLocationInCTAS> spark.sql.legacy.allowNonEmptyLocationInCTAS<a class=headerlink href=#sparksqllegacyallownonemptylocationinctas title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>false</code>, CTAS with LOCATION throws an analysis exception if the location is not empty.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#allowNonEmptyLocationInCTAS>SQLConf.allowNonEmptyLocationInCTAS</a> for the current value</p> <h2 id=sparksqllegacyallowautogeneratedaliasforview><span id=spark.sql.legacy.allowAutoGeneratedAliasForView> spark.sql.legacy.allowAutoGeneratedAliasForView<a class=headerlink href=#sparksqllegacyallowautogeneratedaliasforview title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, it's allowed to use an input query without explicit alias when creating a permanent view.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#allowAutoGeneratedAliasForView>SQLConf.allowAutoGeneratedAliasForView</a> for the current value</p> <h2 id=sparksqlsessionwindowbufferspillthreshold><span id=spark.sql.sessionWindow.buffer.spill.threshold> spark.sql.sessionWindow.buffer.spill.threshold<a class=headerlink href=#sparksqlsessionwindowbufferspillthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The threshold for number of rows to be spilled by window operator. Note that the buffer is used only for the query Spark SQL cannot apply aggregations on determining session window.</p> <p>Default: <a href=#spark.shuffle.spill.numElementsForceSpillThreshold>spark.shuffle.spill.numElementsForceSpillThreshold</a></p> <p>Use <a href=../SQLConf/#sessionWindowBufferSpillThreshold>SQLConf.sessionWindowBufferSpillThreshold</a> for the current value</p> <h2 id=sparksqllegacyallowstarwithsingletableidentifierincount><span id=spark.sql.legacy.allowStarWithSingleTableIdentifierInCount> spark.sql.legacy.allowStarWithSingleTableIdentifierInCount<a class=headerlink href=#sparksqllegacyallowstarwithsingletableidentifierincount title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the SQL function <code>count</code> is allowed to take a single <code>tblName.*</code> as parameter</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#allowStarWithSingleTableIdentifierInCount>SQLConf.allowStarWithSingleTableIdentifierInCount</a> for the current value</p> <h2 id=sparksqlsessionwindowbufferinmemorythreshold><span id=spark.sql.sessionWindow.buffer.in.memory.threshold> spark.sql.sessionWindow.buffer.in.memory.threshold<a class=headerlink href=#sparksqlsessionwindowbufferinmemorythreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Threshold for number of windows guaranteed to be held in memory by the session window operator. Note that the buffer is used only for the query Spark SQL cannot apply aggregations on determining session window.</p> <p>Default: <code>4096</code></p> <p>Use <a href=../SQLConf/#sessionWindowBufferInMemoryThreshold>SQLConf.sessionWindowBufferInMemoryThreshold</a> for the current value</p> <h2 id=sparksqlorcenablenestedcolumnvectorizedreader><span id=spark.sql.orc.enableNestedColumnVectorizedReader> spark.sql.orc.enableNestedColumnVectorizedReader<a class=headerlink href=#sparksqlorcenablenestedcolumnvectorizedreader title="Permanent link">&para;</a></h2> <p>Enables vectorized orc decoding for nested column</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#orcVectorizedReaderNestedColumnEnabled>SQLConf.orcVectorizedReaderNestedColumnEnabled</a> for the current value</p> <h2 id=sparksqlanalyzermaxiterations><span id=spark.sql.analyzer.maxIterations> spark.sql.analyzer.maxIterations<a class=headerlink href=#sparksqlanalyzermaxiterations title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The max number of iterations the analyzer runs.</p> <p>Default: <code>100</code></p> <h2 id=sparksqlanalyzerfailambiguousselfjoin><span id=spark.sql.analyzer.failAmbiguousSelfJoin> spark.sql.analyzer.failAmbiguousSelfJoin<a class=headerlink href=#sparksqlanalyzerfailambiguousselfjoin title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, fail the Dataset query if it contains ambiguous self-join.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlansienabled><span id=spark.sql.ansi.enabled> spark.sql.ansi.enabled<a class=headerlink href=#sparksqlansienabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, Spark tries to conform to the ANSI SQL specification:</p> <ol> <li>Spark will throw a runtime exception if an overflow occurs in any operation on integral/decimal field.</li> <li>Spark will forbid using the reserved keywords of ANSI SQL as identifiers in the SQL parser.</li> </ol> <p>Default: <code>false</code></p> <h2 id=sparksqlcliprintheader><span id=spark.sql.cli.print.header> spark.sql.cli.print.header<a class=headerlink href=#sparksqlcliprintheader title="Permanent link">&para;</a></h2> <p>When <code>true</code>, spark-sql CLI prints the names of the columns in query output</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#cliPrintHeader>SQLConf.cliPrintHeader</a> for the current value</p> <h2 id=sparksqldebugmaxtostringfields><span id=spark.sql.debug.maxToStringFields> spark.sql.debug.maxToStringFields<a class=headerlink href=#sparksqldebugmaxtostringfields title="Permanent link">&para;</a></h2> <p>Maximum number of fields of sequence-like entries can be converted to strings in debug output. Any elements beyond the limit will be dropped and replaced by a "... N more fields" placeholder.</p> <p>Default: <code>25</code></p> <p>Use <a href=../SQLConf/#maxToStringFields>SQLConf.maxToStringFields</a> method to access the current value.</p> <h2 id=sparksqldefaultcatalog><span id=spark.sql.defaultCatalog> spark.sql.defaultCatalog<a class=headerlink href=#sparksqldefaultcatalog title="Permanent link">&para;</a></h2> <p>Name of the default catalog</p> <p>Default: <a href=../connector/catalog/CatalogManager/#SESSION_CATALOG_NAME>spark_catalog</a></p> <p>Use <a href=../SQLConf/#DEFAULT_CATALOG>SQLConf.DEFAULT_CATALOG</a> to access the current value.</p> <h2 id=sparksqlstatisticshistogramenabled><span id=spark.sql.statistics.histogram.enabled> spark.sql.statistics.histogram.enabled<a class=headerlink href=#sparksqlstatisticshistogramenabled title="Permanent link">&para;</a></h2> <p>Enables generating histograms for <a href=../sql/AstBuilder/#visitAnalyze>ANALYZE TABLE</a> SQL statement</p> <p>Default: <code>false</code></p> <div class="admonition note"> <p class=admonition-title>Equi-Height Histogram</p> <p>Histograms can provide better estimation accuracy. Currently, Spark only supports equi-height histogram. Note that collecting histograms takes extra cost. For example, collecting column statistics usually takes only one table scan, but generating equi-height histogram will cause an extra table scan.</p> </div> <p>Use <a href=../SQLConf/#histogramEnabled>SQLConf.histogramEnabled</a> method to access the current value.</p> <h2 id=sparksqlsessiontimezone><span id=spark.sql.session.timeZone> spark.sql.session.timeZone<a class=headerlink href=#sparksqlsessiontimezone title="Permanent link">&para;</a></h2> <p>The ID of session-local timezone (e.g. "GMT", "America/Los_Angeles")</p> <p>Default: Java's <code>TimeZone.getDefault.getID</code></p> <p>Use <a href=../SQLConf/#sessionLocalTimeZone>SQLConf.sessionLocalTimeZone</a> method to access the current value.</p> <h2 id=sparksqlsourcesignoredatalocality><span id=spark.sql.sources.ignoreDataLocality> spark.sql.sources.ignoreDataLocality<a class=headerlink href=#sparksqlsourcesignoredatalocality title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, Spark will not fetch the block locations for each file on listing files. This speeds up file listing, but the scheduler cannot schedule tasks to take advantage of data locality. It can be particularly useful if data is read from a remote cluster so the scheduler could never take advantage of locality anyway.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlsourcesvalidatepartitioncolumns><span id=spark.sql.sources.validatePartitionColumns> spark.sql.sources.validatePartitionColumns<a class=headerlink href=#sparksqlsourcesvalidatepartitioncolumns title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When this option is set to true, partition column values will be validated with user-specified schema. If the validation fails, a runtime exception is thrown. When this option is set to false, the partition column value will be converted to null if it can not be casted to corresponding user-specified schema.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlsourcesusev1sourcelist><span id=spark.sql.sources.useV1SourceList><span id=USE_V1_SOURCE_LIST> spark.sql.sources.useV1SourceList<a class=headerlink href=#sparksqlsourcesusev1sourcelist title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> A comma-separated list of data source short names (<a href=../DataSourceRegister/ >DataSourceRegister</a>s) or fully-qualified canonical class names of the data sources (<a href=../connector/TableProvider/ >TableProvider</a>s) for which DataSource V2 code path is disabled (and Data Source V1 code path used).</p> <p>Default: <code>avro,csv,json,kafka,orc,parquet,text</code></p> <p>Used when:</p> <ul> <li><code>DataSource</code> utility is used to <a href=../DataSource/#lookupDataSourceV2>lookupDataSourceV2</a></li> </ul> <h2 id=sparksqlstoreassignmentpolicy><span id=spark.sql.storeAssignmentPolicy> spark.sql.storeAssignmentPolicy<a class=headerlink href=#sparksqlstoreassignmentpolicy title="Permanent link">&para;</a></h2> <p>When inserting a value into a column with different data type, Spark will perform type coercion. Currently, we support 3 policies for the type coercion rules: ANSI, legacy and strict. With ANSI policy, Spark performs the type coercion as per ANSI SQL. In practice, the behavior is mostly the same as PostgreSQL. It disallows certain unreasonable type conversions such as converting <code>string</code> to <code>int</code> or <code>double</code> to <code>boolean</code>. With legacy policy, Spark allows the type coercion as long as it is a valid <code>Cast</code>, which is very loose. e.g. converting <code>string</code> to <code>int</code> or <code>double</code> to <code>boolean</code> is allowed. It is also the only behavior in Spark 2.x and it is compatible with Hive. With strict policy, Spark doesn't allow any possible precision loss or data truncation in type coercion, e.g. converting <code>double</code> to <code>int</code> or <code>decimal</code> to <code>double</code> is not allowed.</p> <p>Possible values: <code>ANSI</code>, <code>LEGACY</code>, <code>STRICT</code></p> <p>Default: <code>ANSI</code></p> <h2 id=sparksqlthriftserverinterruptoncancel><span id=spark.sql.thriftServer.interruptOnCancel> spark.sql.thriftServer.interruptOnCancel<a class=headerlink href=#sparksqlthriftserverinterruptoncancel title="Permanent link">&para;</a></h2> <p>When <code>true</code>, all running tasks will be interrupted if one cancels a query. When <code>false</code>, all running tasks will remain until finished.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#THRIFTSERVER_FORCE_CANCEL>SQLConf.THRIFTSERVER_FORCE_CANCEL</a> to access the property</p> <h2 id=sparksqlhivetablepropertylengththreshold><span id=spark.sql.hive.tablePropertyLengthThreshold> spark.sql.hive.tablePropertyLengthThreshold<a class=headerlink href=#sparksqlhivetablepropertylengththreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The maximum length allowed in a single cell when storing Spark-specific information in Hive's metastore as table properties. Currently it covers 2 things: the schema's JSON string, the histogram of column statistics.</p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningEnabled>SQLConf.dynamicPartitionPruningEnabled</a> to access the current value.</p> <h2 id=sparksqlorcmergeschema><span id=spark.sql.orc.mergeSchema> spark.sql.orc.mergeSchema<a class=headerlink href=#sparksqlorcmergeschema title="Permanent link">&para;</a></h2> <p>When true, the Orc data source merges schemas collected from all data files, otherwise the schema is picked from a random data file.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlsourcesbucketingautobucketedscanenabled><span id=spark.sql.sources.bucketing.autoBucketedScan.enabled> spark.sql.sources.bucketing.autoBucketedScan.enabled<a class=headerlink href=#sparksqlsourcesbucketingautobucketedscanenabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, decide whether to do bucketed scan on input tables based on query plan automatically. Do not use bucketed scan if 1. query does not have operators to utilize bucketing (e.g. join, group-by, etc), or 2. there's an exchange operator between these operators and table scan.</p> <p>Note when <a href=#spark.sql.sources.bucketing.enabled>spark.sql.sources.bucketing.enabled</a> is set to <code>false</code>, this configuration does not take any effect.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#autoBucketedScanEnabled>SQLConf.autoBucketedScanEnabled</a> to access the property</p> <h2 id=sparksqldatetimejava8apienabled><span id=spark.sql.datetime.java8API.enabled> spark.sql.datetime.java8API.enabled<a class=headerlink href=#sparksqldatetimejava8apienabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, java.time.Instant and java.time.LocalDate classes of Java 8 API are used as external types for Catalyst's TimestampType and DateType. When <code>false</code>, java.sql.Timestamp and java.sql.Date are used for the same purpose.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyintervalenabled><span id=spark.sql.legacy.interval.enabled> spark.sql.legacy.interval.enabled<a class=headerlink href=#sparksqllegacyintervalenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, Spark SQL uses the mixed legacy interval type <code>CalendarIntervalType</code> instead of the ANSI compliant interval types <code>YearMonthIntervalType</code> and <code>DayTimeIntervalType</code>. For instance, the date subtraction expression returns <code>CalendarIntervalType</code> when the SQL config is set to <code>true</code> otherwise an ANSI interval.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#legacyIntervalEnabled>SQLConf.legacyIntervalEnabled</a> to access the current value</p> <h2 id=sparksqlsourcesbinaryfilemaxlength><span id=spark.sql.sources.binaryFile.maxLength> spark.sql.sources.binaryFile.maxLength<a class=headerlink href=#sparksqlsourcesbinaryfilemaxlength title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The max length of a file that can be read by the binary file data source. Spark will fail fast and not attempt to read the file if its length exceeds this value. The theoretical max is Int.MaxValue, though VMs might implement a smaller max.</p> <p>Default: <code>Int.MaxValue</code></p> <h2 id=sparksqlmapkeydeduppolicy><span id=spark.sql.mapKeyDedupPolicy> spark.sql.mapKeyDedupPolicy<a class=headerlink href=#sparksqlmapkeydeduppolicy title="Permanent link">&para;</a></h2> <p>The policy to deduplicate map keys in builtin function: CreateMap, MapFromArrays, MapFromEntries, StringToMap, MapConcat and TransformKeys. When EXCEPTION, the query fails if duplicated map keys are detected. When LAST_WIN, the map key that is inserted at last takes precedence.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LAST_WIN</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqlmaxconcurrentoutputfilewriters><span id=spark.sql.maxConcurrentOutputFileWriters> spark.sql.maxConcurrentOutputFileWriters<a class=headerlink href=#sparksqlmaxconcurrentoutputfilewriters title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Maximum number of output file writers for <code>FileFormatWriter</code> to use concurrently (<a href=../files/FileFormatWriter/#write>writing out a query result</a>). If number of writers needed reaches this limit, a task will sort rest of output then writing them.</p> <p>Default: <code>0</code></p> <p>Use <a href=../SQLConf/#maxConcurrentOutputFileWriters>SQLConf.maxConcurrentOutputFileWriters</a> for the current value</p> <h2 id=sparksqlmaxmetadatastringlength><span id=spark.sql.maxMetadataStringLength> spark.sql.maxMetadataStringLength<a class=headerlink href=#sparksqlmaxmetadatastringlength title="Permanent link">&para;</a></h2> <p>Maximum number of characters to output for a metadata string (e.g., <code>Location</code> in <a href=../files/FileScan/#getMetaData>FileScan</a>)</p> <p>Default: <code>100</code></p> <p>Must be bigger than <code>3</code></p> <p>Use <a href=../SQLConf/#maxMetadataStringLength>SQLConf.maxMetadataStringLength</a> for the current value</p> <h2 id=sparksqlmavenadditionalremoterepositories><span id=spark.sql.maven.additionalRemoteRepositories> spark.sql.maven.additionalRemoteRepositories<a class=headerlink href=#sparksqlmavenadditionalremoterepositories title="Permanent link">&para;</a></h2> <p>A comma-delimited string config of the optional additional remote Maven mirror repositories. This is only used for downloading Hive jars in IsolatedClientLoader if the default Maven Central repo is unreachable.</p> <p>Default: <code>https://maven-central.storage-download.googleapis.com/maven2/</code></p> <h2 id=sparksqlmaxplanstringlength><span id=spark.sql.maxPlanStringLength> spark.sql.maxPlanStringLength<a class=headerlink href=#sparksqlmaxplanstringlength title="Permanent link">&para;</a></h2> <p>Maximum number of characters to output for a plan string. If the plan is longer, further output will be truncated. The default setting always generates a full plan. Set this to a lower value such as 8k if plan strings are taking up too much memory or are causing OutOfMemory errors in the driver or UI processes.</p> <p>Default: <code>Integer.MAX_VALUE - 15</code></p> <h2 id=sparksqladdpartitioninbatchsize><span id=spark.sql.addPartitionInBatch.size> spark.sql.addPartitionInBatch.size<a class=headerlink href=#sparksqladdpartitioninbatchsize title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The number of partitions to be handled in one turn when use <code>AlterTableAddPartitionCommand</code> to add partitions into table. The smaller batch size is, the less memory is required for the real handler, e.g. Hive Metastore.</p> <p>Default: <code>100</code></p> <h2 id=sparksqlscripttransformationexittimeoutinseconds><span id=spark.sql.scriptTransformation.exitTimeoutInSeconds> spark.sql.scriptTransformation.exitTimeoutInSeconds<a class=headerlink href=#sparksqlscripttransformationexittimeoutinseconds title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Timeout for executor to wait for the termination of transformation script when EOF.</p> <p>Default: <code>10</code> seconds</p> <h2 id=sparksqlavrocompressioncodec><span id=spark.sql.avro.compression.codec> spark.sql.avro.compression.codec<a class=headerlink href=#sparksqlavrocompressioncodec title="Permanent link">&para;</a></h2> <p>The compression codec to use when writing Avro data to disk</p> <p>Default: <code>snappy</code></p> <p>The supported codecs are:</p> <ul> <li><code>uncompressed</code></li> <li><code>deflate</code></li> <li><code>snappy</code></li> <li><code>bzip2</code></li> <li><code>xz</code></li> </ul> <p>Use <a href=../SQLConf/#avroCompressionCodec>SQLConf.avroCompressionCodec</a> method to access the current value.</p> <h2 id=sparksqlbroadcasttimeout><span id=spark.sql.broadcastTimeout> spark.sql.broadcastTimeout<a class=headerlink href=#sparksqlbroadcasttimeout title="Permanent link">&para;</a></h2> <p>Timeout in seconds for the broadcast wait time in broadcast joins.</p> <p>Default: <code>5 * 60</code></p> <p>When negative, it is assumed infinite (i.e. <code>Duration.Inf</code>)</p> <p>Use <a href=../SQLConf/#broadcastTimeout>SQLConf.broadcastTimeout</a> method to access the current value.</p> <h2 id=sparksqlbucketingcoalescebucketsinjoinenabled><span id=spark.sql.bucketing.coalesceBucketsInJoin.enabled> spark.sql.bucketing.coalesceBucketsInJoin.enabled<a class=headerlink href=#sparksqlbucketingcoalescebucketsinjoinenabled title="Permanent link">&para;</a></h2> <p>When enabled (<code>true</code>), if two bucketed tables with the different number of buckets are joined, the side with a bigger number of buckets will be coalesced to have the same number of buckets as the other side. Bigger number of buckets is divisible by the smaller number of buckets. Bucket coalescing is applied to sort-merge joins and shuffled hash join.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>Coalescing bucketed table can avoid unnecessary shuffling in join, but it also reduces parallelism and could possibly cause OOM for shuffled hash join.</p> </div> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#coalesceBucketsInJoinEnabled>SQLConf.coalesceBucketsInJoinEnabled</a> method to access the current value.</p> <h2 id=sparksqlcasesensitive><span id=spark.sql.caseSensitive> spark.sql.caseSensitive<a class=headerlink href=#sparksqlcasesensitive title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether the query analyzer should be case sensitive (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>false</code></p> <p>It is highly discouraged to turn on case sensitive mode.</p> <p>Use <a href=../SQLConf/#caseSensitiveAnalysis>SQLConf.caseSensitiveAnalysis</a> method to access the current value.</p> <h2 id=sparksqlcatalogspark_catalog><span id=spark.sql.catalog.spark_catalog><span id=V2_SESSION_CATALOG_IMPLEMENTATION> spark.sql.catalog.spark_catalog<a class=headerlink href=#sparksqlcatalogspark_catalog title="Permanent link">&para;</a></h2> <p>The <a href=../connector/catalog/CatalogPlugin/ >CatalogPlugin</a> for <code>spark_catalog</code></p> <p>Default: <a href=../connector/catalog/CatalogManager/#defaultSessionCatalog>defaultSessionCatalog</a></p> <h2 id=sparksqlcboenabled><span id=spark.sql.cbo.enabled> spark.sql.cbo.enabled<a class=headerlink href=#sparksqlcboenabled title="Permanent link">&para;</a></h2> <p>Enables <a href=../cost-based-optimization/ >Cost-Based Optimization</a> (CBO) for estimation of plan statistics when <code>true</code>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#cboEnabled>SQLConf.cboEnabled</a> method to access the current value.</p> <h2 id=sparksqlcbojoinreorderenabled><span id=spark.sql.cbo.joinReorder.enabled> spark.sql.cbo.joinReorder.enabled<a class=headerlink href=#sparksqlcbojoinreorderenabled title="Permanent link">&para;</a></h2> <p>Enables join reorder for cost-based optimization (CBO).</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#joinReorderEnabled>SQLConf.joinReorderEnabled</a> method to access the current value.</p> <h2 id=sparksqlcboplanstatsenabled><span id=spark.sql.cbo.planStats.enabled> spark.sql.cbo.planStats.enabled<a class=headerlink href=#sparksqlcboplanstatsenabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, the logical plan will fetch row counts and column statistics from catalog.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlcbostarschemadetection><span id=spark.sql.cbo.starSchemaDetection> spark.sql.cbo.starSchemaDetection<a class=headerlink href=#sparksqlcbostarschemadetection title="Permanent link">&para;</a></h2> <p>Enables <em>join reordering</em> based on star schema detection for cost-based optimization (CBO) in <a href=../logical-optimizations/ReorderJoin/ >ReorderJoin</a> logical plan optimization.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#starSchemaDetection>SQLConf.starSchemaDetection</a> method to access the current value.</p> <h2 id=sparksqlcodegen>spark.sql.codegen<a class=headerlink href=#sparksqlcodegen title="Permanent link">&para;</a></h2> <h3 id=spark.sql.codegen.aggregate.map.vectorized.enable>aggregate.map.vectorized.enable<a class=headerlink href=#spark.sql.codegen.aggregate.map.vectorized.enable title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.aggregate.map.vectorized.enable</strong></p> <p><strong>(internal)</strong> Enables vectorized aggregate hash map. This is for testing/benchmarking only.</p> <p>Default: <code>false</code></p> <h3 id=spark.sql.codegen.aggregate.sortAggregate.enabled><span id=ENABLE_SORT_AGGREGATE_CODEGEN> aggregate.sortAggregate.enabled<a class=headerlink href=#spark.sql.codegen.aggregate.sortAggregate.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.aggregate.sortAggregate.enabled</strong></p> <p>Enables code generation for <a href=../physical-operators/SortAggregateExec/#supportCodegen>SortAggregateExec</a> physical operator</p> <p>Default: <code>true</code></p> <h3 id=spark.sql.codegen.aggregate.splitAggregateFunc.enabled>aggregate.splitAggregateFunc.enabled<a class=headerlink href=#spark.sql.codegen.aggregate.splitAggregateFunc.enabled title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.aggregate.splitAggregateFunc.enabled</strong></p> <p><strong>(internal)</strong> When true, the code generator would split aggregate code into individual methods instead of a single big method. This can be used to avoid oversized function that can miss the opportunity of JIT optimization.</p> <p>Default: <code>true</code></p> <h3 id=spark.sql.codegen.comments>comments<a class=headerlink href=#spark.sql.codegen.comments title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.comments</strong></p> <p>Controls whether <code>CodegenContext</code> should <a href=../physical-operators/CodegenSupport/#registerComment>register comments</a> (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>false</code></p> <h3 id=spark.sql.codegen.factoryMode>factoryMode<a class=headerlink href=#spark.sql.codegen.factoryMode title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.factoryMode</strong></p> <p><strong>(internal)</strong> Determines the codegen generator fallback behavior</p> <p>Default: <code>FALLBACK</code></p> <p>Acceptable values:</p> <ul> <li><code>CODEGEN_ONLY</code> - disable fallback mode</li> <li><code>FALLBACK</code> - try codegen first and, if any compile error happens, fallback to interpreted mode</li> <li><code>NO_CODEGEN</code> - skips codegen and always uses interpreted path</li> </ul> <p>Used when <code>CodeGeneratorWithInterpretedFallback</code> is requested to <a href=../expressions/CodeGeneratorWithInterpretedFallback/#createObject>createObject</a> (when <code>UnsafeProjection</code> is requested to <a href=../expressions/UnsafeProjection/#create>create an UnsafeProjection for Catalyst expressions</a>)</p> <h3 id=spark.sql.codegen.useIdInClassName>useIdInClassName<a class=headerlink href=#spark.sql.codegen.useIdInClassName title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.useIdInClassName</strong></p> <p><strong>(internal)</strong> Controls whether to embed the (whole-stage) codegen stage ID into the class name of the generated class as a suffix (<code>true</code>) or not (<code>false</code>)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageUseIdInClassName>SQLConf.wholeStageUseIdInClassName</a> method to access the current value.</p> <h3 id=spark.sql.codegen.maxFields>maxFields<a class=headerlink href=#spark.sql.codegen.maxFields title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.maxFields</strong></p> <p><strong>(internal)</strong> Maximum number of output fields (including nested fields) that whole-stage codegen supports. Going above the number deactivates whole-stage codegen.</p> <p>Default: <code>100</code></p> <p>Use <a href=../SQLConf/#wholeStageMaxNumFields>SQLConf.wholeStageMaxNumFields</a> method to access the current value.</p> <h3 id=spark.sql.codegen.splitConsumeFuncByOperator>splitConsumeFuncByOperator<a class=headerlink href=#spark.sql.codegen.splitConsumeFuncByOperator title="Permanent link">&para;</a></h3> <p><strong>spark.sql.codegen.splitConsumeFuncByOperator</strong></p> <p><strong>(internal)</strong> Controls whether whole stage codegen puts the logic of consuming rows of each physical operator into individual methods, instead of a single big method. This can be used to avoid oversized function that can miss the opportunity of JIT optimization.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageSplitConsumeFuncByOperator>SQLConf.wholeStageSplitConsumeFuncByOperator</a> method to access the current value.</p> <h2 id=sparksqlcolumnnameofcorruptrecord><span id=spark.sql.columnNameOfCorruptRecord> spark.sql.columnNameOfCorruptRecord<a class=headerlink href=#sparksqlcolumnnameofcorruptrecord title="Permanent link">&para;</a></h2> <h2 id=sparksqlconstraintpropagationenabled><span id=spark.sql.constraintPropagation.enabled> spark.sql.constraintPropagation.enabled<a class=headerlink href=#sparksqlconstraintpropagationenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, the query optimizer will infer and propagate data constraints in the query plan to optimize them. Constraint propagation can sometimes be computationally expensive for certain kinds of query plans (such as those with a large number of predicates and aliases) which might negatively impact overall runtime.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#constraintPropagationEnabled>SQLConf.constraintPropagationEnabled</a> method to access the current value.</p> <h2 id=sparksqlcsvfilterpushdownenabled><span id=spark.sql.csv.filterPushdown.enabled> spark.sql.csv.filterPushdown.enabled<a class=headerlink href=#sparksqlcsvfilterpushdownenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, enable filter pushdown to CSV datasource.</p> <p>Default: <code>true</code></p> <h2 id=sparksqldefaultsizeinbytes><span id=spark.sql.defaultSizeInBytes> spark.sql.defaultSizeInBytes<a class=headerlink href=#sparksqldefaultsizeinbytes title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Estimated size of a table or relation used in query planning</p> <p>Default: Java's <code>Long.MaxValue</code></p> <p>Set to Java's <code>Long.MaxValue</code> which is larger than <a href=#spark.sql.autoBroadcastJoinThreshold>spark.sql.autoBroadcastJoinThreshold</a> to be more conservative. That is to say by default the optimizer will not choose to broadcast a table unless it knows for sure that the table size is small enough.</p> <p>Used by the planner to decide when it is safe to broadcast a relation. By default, the system will assume that tables are too large to broadcast.</p> <p>Use <a href=../SQLConf/#defaultSizeInBytes>SQLConf.defaultSizeInBytes</a> method to access the current value.</p> <h2 id=sparksqldialect><span id=spark.sql.dialect> spark.sql.dialect<a class=headerlink href=#sparksqldialect title="Permanent link">&para;</a></h2> <h2 id=executionuseobjecthashaggregateexec><span id=spark.sql.execution.useObjectHashAggregateExec> execution.useObjectHashAggregateExec<a class=headerlink href=#executionuseobjecthashaggregateexec title="Permanent link">&para;</a></h2> <p><strong>spark.sql.execution.useObjectHashAggregateExec</strong></p> <p><strong>(internal)</strong> <a href=../aggregations/AggUtils/#createAggregate>Prefers ObjectHashAggregateExec (over SortAggregateExec) for aggregation</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#useObjectHashAggregation>SQLConf.useObjectHashAggregation</a> method to access the current value.</p> <h2 id=sparksqlfilesignorecorruptfiles><span id=spark.sql.files.ignoreCorruptFiles> spark.sql.files.ignoreCorruptFiles<a class=headerlink href=#sparksqlfilesignorecorruptfiles title="Permanent link">&para;</a></h2> <p>Controls whether to ignore corrupt files (<code>true</code>) or not (<code>false</code>). If <code>true</code>, the Spark jobs will continue to run when encountering corrupted files and the contents that have been read will still be returned.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#ignoreCorruptFiles>SQLConf.ignoreCorruptFiles</a> method to access the current value.</p> <h2 id=sparksqlfilesignoremissingfiles><span id=spark.sql.files.ignoreMissingFiles> spark.sql.files.ignoreMissingFiles<a class=headerlink href=#sparksqlfilesignoremissingfiles title="Permanent link">&para;</a></h2> <p>Controls whether to ignore missing files (<code>true</code>) or not (<code>false</code>). If <code>true</code>, the Spark jobs will continue to run when encountering missing files and the contents that have been read will still be returned.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#ignoreMissingFiles>SQLConf.ignoreMissingFiles</a> method to access the current value.</p> <h2 id=sparksqlinmemorycolumnarstoragecompressed><span id=spark.sql.inMemoryColumnarStorage.compressed> spark.sql.inMemoryColumnarStorage.compressed<a class=headerlink href=#sparksqlinmemorycolumnarstoragecompressed title="Permanent link">&para;</a></h2> <p>When enabled, Spark SQL will automatically select a compression codec for each column based on statistics of the data.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#useCompression>SQLConf.useCompression</a> method to access the current value.</p> <h2 id=sparksqlinmemorycolumnarstoragebatchsize><span id=spark.sql.inMemoryColumnarStorage.batchSize> spark.sql.inMemoryColumnarStorage.batchSize<a class=headerlink href=#sparksqlinmemorycolumnarstoragebatchsize title="Permanent link">&para;</a></h2> <p>Controls the size of batches for columnar caching. Larger batch sizes can improve memory utilization and compression, but risk OOMs when caching data.</p> <p>Default: <code>10000</code></p> <p>Use <a href=../SQLConf/#columnBatchSize>SQLConf.columnBatchSize</a> method to access the current value.</p> <h2 id=sparksqlinmemorytablescanstatisticsenable><span id=spark.sql.inMemoryTableScanStatistics.enable> spark.sql.inMemoryTableScanStatistics.enable<a class=headerlink href=#sparksqlinmemorytablescanstatisticsenable title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, enable in-memory table scan accumulators.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlinmemorycolumnarstorageenablevectorizedreader><span id=spark.sql.inMemoryColumnarStorage.enableVectorizedReader> spark.sql.inMemoryColumnarStorage.enableVectorizedReader<a class=headerlink href=#sparksqlinmemorycolumnarstorageenablevectorizedreader title="Permanent link">&para;</a></h2> <p>Enables <a href=../vectorized-query-execution/ >vectorized reader</a> for columnar caching</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#cacheVectorizedReaderEnabled>SQLConf.cacheVectorizedReaderEnabled</a> method to access the current value.</p> <h2 id=sparksqljoinprefersortmergejoin><span id=spark.sql.join.preferSortMergeJoin> spark.sql.join.preferSortMergeJoin<a class=headerlink href=#sparksqljoinprefersortmergejoin title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether <a href=../execution-planning-strategies/JoinSelection/ >JoinSelection</a> execution planning strategy prefers <a href=../physical-operators/SortMergeJoinExec/ >sort merge join</a> over <a href=../physical-operators/ShuffledHashJoinExec/ >shuffled hash join</a>.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#preferSortMergeJoin>SQLConf.preferSortMergeJoin</a> method to access the current value.</p> <h2 id=sparksqljsongeneratorignorenullfields><span id=spark.sql.jsonGenerator.ignoreNullFields> spark.sql.jsonGenerator.ignoreNullFields<a class=headerlink href=#sparksqljsongeneratorignorenullfields title="Permanent link">&para;</a></h2> <p>Whether to ignore null fields when generating JSON objects in JSON data source and JSON functions such as to_json. If false, it generates null for null fields in JSON objects.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlleafnodedefaultparallelism><span id=spark.sql.leafNodeDefaultParallelism><span id=LEAF_NODE_DEFAULT_PARALLELISM> spark.sql.leafNodeDefaultParallelism<a class=headerlink href=#sparksqlleafnodedefaultparallelism title="Permanent link">&para;</a></h2> <p>The <a href=../SparkSession/#leafNodeDefaultParallelism>default parallelism of leaf operators</a> that produce data</p> <p>Must be positive</p> <p>Default: <code>SparkContext.defaultParallelism</code> (<a href=https://books.japila.pl/apache-spark-internals/SparkContext#defaultParallelism>Spark Core</a>)</p> <h2 id=sparksqllegacydolooseupcast><span id=spark.sql.legacy.doLooseUpcast> spark.sql.legacy.doLooseUpcast<a class=headerlink href=#sparksqllegacydolooseupcast title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the upcast will be loose and allows string to atomic types.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacycteprecedencepolicy><span id=spark.sql.legacy.ctePrecedencePolicy> spark.sql.legacy.ctePrecedencePolicy<a class=headerlink href=#sparksqllegacycteprecedencepolicy title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> This config will be removed in future versions and <code>CORRECTED</code> will be the only behavior.</p> <p>Possible values:</p> <ol> <li><code>CORRECTED</code> - inner CTE definitions take precedence</li> <li><code>EXCEPTION</code> - <code>AnalysisException</code> is thrown while name conflict is detected in nested CTE</li> <li><code>LEGACY</code> - outer CTE definitions takes precedence over inner definitions</li> </ol> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacytimeparserpolicy><span id=spark.sql.legacy.timeParserPolicy> spark.sql.legacy.timeParserPolicy<a class=headerlink href=#sparksqllegacytimeparserpolicy title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, java.text.SimpleDateFormat is used for formatting and parsing dates/timestamps in a locale-sensitive manner, which is the approach before Spark 3.0. When set to CORRECTED, classes from <code>java.time.*</code> packages are used for the same purpose. The default value is EXCEPTION, RuntimeException is thrown when we will get different results.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyfollowthreevaluedlogicinarrayexists><span id=spark.sql.legacy.followThreeValuedLogicInArrayExists> spark.sql.legacy.followThreeValuedLogicInArrayExists<a class=headerlink href=#sparksqllegacyfollowthreevaluedlogicinarrayexists title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, the ArrayExists will follow the three-valued boolean logic.</p> <p>Default: <code>true</code></p> <h2 id=sparksqllegacyfromdaytimestringenabled><span id=spark.sql.legacy.fromDayTimeString.enabled> spark.sql.legacy.fromDayTimeString.enabled<a class=headerlink href=#sparksqllegacyfromdaytimestringenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the <code>from</code> bound is not taken into account in conversion of a day-time string to an interval, and the <code>to</code> bound is used to skip all interval units out of the specified range. When <code>false</code>, <code>ParseException</code> is thrown if the input does not match to the pattern defined by <code>from</code> and <code>to</code>.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacynotreserveproperties><span id=spark.sql.legacy.notReserveProperties> spark.sql.legacy.notReserveProperties<a class=headerlink href=#sparksqllegacynotreserveproperties title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, all database and table properties are not reserved and available for create/alter syntaxes. But please be aware that the reserved properties will be silently removed.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyaddsinglefileinaddfile><span id=spark.sql.legacy.addSingleFileInAddFile> spark.sql.legacy.addSingleFileInAddFile<a class=headerlink href=#sparksqllegacyaddsinglefileinaddfile title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, only a single file can be added using ADD FILE. If false, then users can add directory by passing directory path to ADD FILE.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyexponentliteralasdecimalenabled><span id=spark.sql.legacy.exponentLiteralAsDecimal.enabled> spark.sql.legacy.exponentLiteralAsDecimal.enabled<a class=headerlink href=#sparksqllegacyexponentliteralasdecimalenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, a literal with an exponent (e.g. 1E-30) would be parsed as Decimal rather than Double.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyallownegativescaleofdecimal><span id=spark.sql.legacy.allowNegativeScaleOfDecimal> spark.sql.legacy.allowNegativeScaleOfDecimal<a class=headerlink href=#sparksqllegacyallownegativescaleofdecimal title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, negative scale of Decimal type is allowed. For example, the type of number 1E10BD under legacy mode is DecimalType(2, -9), but is Decimal(11, 0) in non legacy mode.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacybucketedtablescanoutputordering><span id=spark.sql.legacy.bucketedTableScan.outputOrdering> spark.sql.legacy.bucketedTableScan.outputOrdering<a class=headerlink href=#sparksqllegacybucketedtablescanoutputordering title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the bucketed table scan will list files during planning to figure out the output ordering, which is expensive and may make the planning quite slow.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyjsonallowemptystringenabled><span id=spark.sql.legacy.json.allowEmptyString.enabled> spark.sql.legacy.json.allowEmptyString.enabled<a class=headerlink href=#sparksqllegacyjsonallowemptystringenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the parser of JSON data source treats empty strings as null for some data types such as <code>IntegerType</code>.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacycreateemptycollectionusingstringtype><span id=spark.sql.legacy.createEmptyCollectionUsingStringType> spark.sql.legacy.createEmptyCollectionUsingStringType<a class=headerlink href=#sparksqllegacycreateemptycollectionusingstringtype title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, Spark returns an empty collection with <code>StringType</code> as element type if the <code>array</code>/<code>map</code> function is called without any parameters. Otherwise, Spark returns an empty collection with <code>NullType</code> as element type.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyallowuntypedscalaudf><span id=spark.sql.legacy.allowUntypedScalaUDF> spark.sql.legacy.allowUntypedScalaUDF<a class=headerlink href=#sparksqllegacyallowuntypedscalaudf title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, user is allowed to use <code>org.apache.spark.sql.functions.udf(f: AnyRef, dataType: DataType)</code>. Otherwise, an exception will be thrown at runtime.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacydatasetnamenonstructgroupingkeyasvalue><span id=spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue> spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue<a class=headerlink href=#sparksqllegacydatasetnamenonstructgroupingkeyasvalue title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the key attribute resulted from running <code>Dataset.groupByKey</code> for non-struct key type, will be named as <code>value</code>, following the behavior of Spark version 2.4 and earlier.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacysetcommandrejectssparkcoreconfs><span id=spark.sql.legacy.setCommandRejectsSparkCoreConfs> spark.sql.legacy.setCommandRejectsSparkCoreConfs<a class=headerlink href=#sparksqllegacysetcommandrejectssparkcoreconfs title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> If it is set to true, SET command will fail when the key is registered as a SparkConf entry.</p> <p>Default: <code>true</code></p> <h2 id=sparksqllegacytypecoerciondatetimetostringenabled><span id=spark.sql.legacy.typeCoercion.datetimeToString.enabled> spark.sql.legacy.typeCoercion.datetimeToString.enabled<a class=headerlink href=#sparksqllegacytypecoerciondatetimetostringenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, date/timestamp will cast to string in binary comparisons with String</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyallowhashonmaptype><span id=spark.sql.legacy.allowHashOnMapType> spark.sql.legacy.allowHashOnMapType<a class=headerlink href=#sparksqllegacyallowhashonmaptype title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, hash expressions can be applied on elements of MapType. Otherwise, an analysis exception will be thrown.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyparquetdatetimerebasemodeinwrite><span id=spark.sql.legacy.parquet.datetimeRebaseModeInWrite> spark.sql.legacy.parquet.datetimeRebaseModeInWrite<a class=headerlink href=#sparksqllegacyparquetdatetimerebasemodeinwrite title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from Proleptic Gregorian calendar to the legacy hybrid (Julian + Gregorian) calendar when writing Parquet files. When CORRECTED, Spark will not do rebase and write the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the writing if it sees ancient dates/timestamps that are ambiguous between the two calendars.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyparquetdatetimerebasemodeinread><span id=spark.sql.legacy.parquet.datetimeRebaseModeInRead> spark.sql.legacy.parquet.datetimeRebaseModeInRead<a class=headerlink href=#sparksqllegacyparquetdatetimerebasemodeinread title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from the legacy hybrid (Julian + Gregorian) calendar to Proleptic Gregorian calendar when reading Parquet files. When CORRECTED, Spark will not do rebase and read the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the reading if it sees ancient dates/timestamps that are ambiguous between the two calendars. This config is only effective if the writer info (like Spark, Hive) of the Parquet files is unknown.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyavrodatetimerebasemodeinwrite><span id=spark.sql.legacy.avro.datetimeRebaseModeInWrite> spark.sql.legacy.avro.datetimeRebaseModeInWrite<a class=headerlink href=#sparksqllegacyavrodatetimerebasemodeinwrite title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from Proleptic Gregorian calendar to the legacy hybrid (Julian + Gregorian) calendar when writing Avro files. When CORRECTED, Spark will not do rebase and write the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the writing if it sees ancient dates/timestamps that are ambiguous between the two calendars.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyavrodatetimerebasemodeinread><span id=spark.sql.legacy.avro.datetimeRebaseModeInRead> spark.sql.legacy.avro.datetimeRebaseModeInRead<a class=headerlink href=#sparksqllegacyavrodatetimerebasemodeinread title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from the legacy hybrid (Julian + Gregorian) calendar to Proleptic Gregorian calendar when reading Avro files. When CORRECTED, Spark will not do rebase and read the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the reading if it sees ancient dates/timestamps that are ambiguous between the two calendars. This config is only effective if the writer info (like Spark, Hive) of the Avro files is unknown.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyrddapplyconf><span id=spark.sql.legacy.rdd.applyConf> spark.sql.legacy.rdd.applyConf<a class=headerlink href=#sparksqllegacyrddapplyconf title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables propagation of <a href=../SQLConf/#getAllConfs>SQL configurations</a> when executing operations on the <a href=../QueryExecution/#toRdd>RDD that represents a structured query</a>. This is the (buggy) behavior up to 2.4.4.</p> <p>Default: <code>true</code></p> <p>This is for cases not tracked by <a href=../SQLExecution/ >SQL execution</a>, when a <code>Dataset</code> is converted to an RDD either using Dataset.md#rdd[rdd] operation or <a href=../QueryExecution/#toRdd>QueryExecution</a>, and then the returned RDD is used to invoke actions on it.</p> <p>This config is deprecated and will be removed in 3.0.0.</p> <h2 id=sparksqllegacyreplacedatabrickssparkavroenabled><span id=spark.sql.legacy.replaceDatabricksSparkAvro.enabled> spark.sql.legacy.replaceDatabricksSparkAvro.enabled<a class=headerlink href=#sparksqllegacyreplacedatabrickssparkavroenabled title="Permanent link">&para;</a></h2> <p>Enables resolving (<em>mapping</em>) the data source provider <code>com.databricks.spark.avro</code> to the built-in (but external) Avro data source module for backward compatibility.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#replaceDatabricksSparkAvroEnabled>SQLConf.replaceDatabricksSparkAvroEnabled</a> method to access the current value.</p> <h2 id=sparksqllimitscaleupfactor><span id=spark.sql.limit.scaleUpFactor> spark.sql.limit.scaleUpFactor<a class=headerlink href=#sparksqllimitscaleupfactor title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Minimal increase rate in the number of partitions between attempts when executing <code>take</code> operator on a structured query. Higher values lead to more partitions read. Lower values might lead to longer execution times as more jobs will be run.</p> <p>Default: <code>4</code></p> <p>Use <a href=../SQLConf/#limitScaleUpFactor>SQLConf.limitScaleUpFactor</a> method to access the current value.</p> <h2 id=sparksqloptimizenullawareantijoin><span id=spark.sql.optimizeNullAwareAntiJoin> spark.sql.optimizeNullAwareAntiJoin<a class=headerlink href=#sparksqloptimizenullawareantijoin title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables <a href=../ExtractSingleColumnNullAwareAntiJoin/#unapply>single-column NULL-aware anti join execution planning</a> into <a href=../physical-operators/BroadcastHashJoinExec/ >BroadcastHashJoinExec</a> (with flag <a href=../physical-operators/BroadcastHashJoinExec/#isNullAwareAntiJoin>isNullAwareAntiJoin</a> enabled), optimized from O(M*N) calculation into O(M) calculation using hash lookup instead of looping lookup.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#optimizeNullAwareAntiJoin>SQLConf.optimizeNullAwareAntiJoin</a> method to access the current value.</p> <h2 id=sparksqlorcimpl><span id=spark.sql.orc.impl> spark.sql.orc.impl<a class=headerlink href=#sparksqlorcimpl title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>native</code>, use the native version of ORC support instead of the ORC library in Hive 1.2.1.</p> <p>Default: <code>native</code></p> <p>Acceptable values:</p> <ul> <li><code>hive</code></li> <li><code>native</code></li> </ul> <h2 id=sparksqlplanchangeloglevel><span id=spark.sql.planChangeLog.level> spark.sql.planChangeLog.level<a class=headerlink href=#sparksqlplanchangeloglevel title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Log level for logging the change from the original plan to the new plan after a rule or batch is applied.</p> <p>Default: <code>trace</code></p> <p>Supported Values (case-insensitive):</p> <ul> <li>trace</li> <li>debug</li> <li>info</li> <li>warn</li> <li>error</li> </ul> <p>Use <a href=../SQLConf/#planChangeLogLevel>SQLConf.planChangeLogLevel</a> method to access the current value.</p> <h2 id=sparksqlplanchangelogbatches><span id=spark.sql.planChangeLog.batches> spark.sql.planChangeLog.batches<a class=headerlink href=#sparksqlplanchangelogbatches title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Comma-separated list of batch names for plan changes logging</p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#planChangeBatches>SQLConf.planChangeBatches</a> method to access the current value.</p> <h2 id=sparksqlplanchangelogrules><span id=spark.sql.planChangeLog.rules> spark.sql.planChangeLog.rules<a class=headerlink href=#sparksqlplanchangelogrules title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Comma-separated list of rule names for plan changes logging</p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#planChangeRules>SQLConf.planChangeRules</a> method to access the current value.</p> <h2 id=sparksqlpysparkjvmstacktraceenabled><span id=spark.sql.pyspark.jvmStacktrace.enabled> spark.sql.pyspark.jvmStacktrace.enabled<a class=headerlink href=#sparksqlpysparkjvmstacktraceenabled title="Permanent link">&para;</a></h2> <p>When true, it shows the JVM stacktrace in the user-facing PySpark exception together with Python stacktrace. By default, it is disabled and hides JVM stacktrace and shows a Python-friendly exception only.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlparquetbinaryasstring><span id=spark.sql.parquet.binaryAsString> spark.sql.parquet.binaryAsString<a class=headerlink href=#sparksqlparquetbinaryasstring title="Permanent link">&para;</a></h2> <p>Some other Parquet-producing systems, in particular Impala and older versions of Spark SQL, do not differentiate between binary data and strings when writing out the Parquet schema. This flag tells Spark SQL to interpret binary data as a string to provide compatibility with these systems.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#isParquetBinaryAsString>SQLConf.isParquetBinaryAsString</a> method to access the current value.</p> <h2 id=sparksqlparquetcompressioncodec><span id=spark.sql.parquet.compression.codec> spark.sql.parquet.compression.codec<a class=headerlink href=#sparksqlparquetcompressioncodec title="Permanent link">&para;</a></h2> <p>Sets the compression codec used when writing Parquet files. If either <code>compression</code> or <code>parquet.compression</code> is specified in the table-specific options/properties, the precedence would be <code>compression</code>, <code>parquet.compression</code>, <code>spark.sql.parquet.compression.codec</code>.</p> <p>Acceptable values:</p> <ul> <li><code>brotli</code></li> <li><code>gzip</code></li> <li><code>lz4</code></li> <li><code>lzo</code></li> <li><code>none</code></li> <li><code>snappy</code></li> <li><code>uncompressed</code></li> <li><code>zstd</code></li> </ul> <p>Default: <code>snappy</code></p> <p>Use <a href=../SQLConf/#parquetCompressionCodec>SQLConf.parquetCompressionCodec</a> method to access the current value.</p> <h2 id=sparksqlparquetenablevectorizedreader><span id=spark.sql.parquet.enableVectorizedReader> spark.sql.parquet.enableVectorizedReader<a class=headerlink href=#sparksqlparquetenablevectorizedreader title="Permanent link">&para;</a></h2> <p>Enables <a href=../vectorized-decoding/ >vectorized parquet decoding</a>.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetVectorizedReaderEnabled>SQLConf.parquetVectorizedReaderEnabled</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdowndate><span id=spark.sql.parquet.filterPushdown.date> spark.sql.parquet.filterPushdown.date<a class=headerlink href=#sparksqlparquetfilterpushdowndate title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>Date</code> type (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownDate>SQLConf.parquetFilterPushDownDate</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdowndecimal><span id=spark.sql.parquet.filterPushdown.decimal> spark.sql.parquet.filterPushdown.decimal<a class=headerlink href=#sparksqlparquetfilterpushdowndecimal title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>Decimal</code> type (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownDecimal>SQLConf.parquetFilterPushDownDecimal</a> method to access the current value.</p> <h2 id=sparksqlparquetint96rebasemodeinwrite><span id=spark.sql.parquet.int96RebaseModeInWrite> spark.sql.parquet.int96RebaseModeInWrite<a class=headerlink href=#sparksqlparquetint96rebasemodeinwrite title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables rebasing timestamps while writing Parquet files</p> <p>Formerly known as <a href=#spark.sql.legacy.parquet.int96RebaseModeInWrite>spark.sql.legacy.parquet.int96RebaseModeInWrite</a></p> <p>Acceptable values:</p> <ul> <li><code>EXCEPTION</code> - Fail writing parquet files if there are ancient timestamps that are ambiguous between the two calendars</li> <li><code>LEGACY</code> - Rebase <code>INT96</code> timestamps from Proleptic Gregorian calendar to the legacy hybrid (Julian + Gregorian) calendar (gives maximum interoperability)</li> <li><code>CORRECTED</code> - Write datetime values with no change (<em>rabase</em>). Only when you are 100% sure that the written files will only be read by Spark 3.0+ or other systems that use Proleptic Gregorian calendar</li> </ul> <p>Default: <code>EXCEPTION</code></p> <p>Writing dates before <code>1582-10-15</code> or timestamps before <code>1900-01-01T00:00:00Z</code> can be dangerous, as the files may be read by Spark 2.x or legacy versions of Hive later, which uses a legacy hybrid calendar that is different from Spark 3.0+'s Proleptic Gregorian calendar.</p> <p>See more details in SPARK-31404.</p> <h2 id=sparksqlparquetpushdowninfilterthreshold><span id=spark.sql.parquet.pushdown.inFilterThreshold> spark.sql.parquet.pushdown.inFilterThreshold<a class=headerlink href=#sparksqlparquetpushdowninfilterthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> For IN predicate, Parquet filter will push-down a set of OR clauses if its number of values not exceeds this threshold. Otherwise, Parquet filter will push-down a value greater than or equal to its minimum value and less than or equal to its maximum value (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Disabled when <code>0</code></p> <p>Default: <code>10</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownInFilterThreshold>SQLConf.parquetFilterPushDownInFilterThreshold</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdownstringstartswith><span id=spark.sql.parquet.filterPushdown.string.startsWith> spark.sql.parquet.filterPushdown.string.startsWith<a class=headerlink href=#sparksqlparquetfilterpushdownstringstartswith title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>startsWith</code> function (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownStringStartWith>SQLConf.parquetFilterPushDownStringStartWith</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdowntimestamp><span id=spark.sql.parquet.filterPushdown.timestamp> spark.sql.parquet.filterPushdown.timestamp<a class=headerlink href=#sparksqlparquetfilterpushdowntimestamp title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>Timestamp</code> type. It can only have an effect when the following hold:</p> <ol> <li><a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled</li> <li><code>Timestamp</code> stored as <code>TIMESTAMP_MICROS</code> or <code>TIMESTAMP_MILLIS</code> type</li> </ol> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownTimestamp>SQLConf.parquetFilterPushDownTimestamp</a> method to access the current value.</p> <h2 id=sparksqlparquetint96astimestamp><span id=spark.sql.parquet.int96AsTimestamp> spark.sql.parquet.int96AsTimestamp<a class=headerlink href=#sparksqlparquetint96astimestamp title="Permanent link">&para;</a></h2> <p>Some Parquet-producing systems, in particular Impala, store Timestamp into INT96. Spark would also store Timestamp as INT96 because we need to avoid precision lost of the nanoseconds field. This flag tells Spark SQL to interpret INT96 data as a timestamp to provide compatibility with these systems.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#isParquetINT96AsTimestamp>SQLConf.isParquetINT96AsTimestamp</a> method to access the current value.</p> <h2 id=sparksqlparquetint96timestampconversion><span id=spark.sql.parquet.int96TimestampConversion> spark.sql.parquet.int96TimestampConversion<a class=headerlink href=#sparksqlparquetint96timestampconversion title="Permanent link">&para;</a></h2> <p>Controls whether timestamp adjustments should be applied to INT96 data when converting to timestamps, for data written by Impala.</p> <p>Default: <code>false</code></p> <p>This is necessary because Impala stores INT96 data with a different timezone offset than Hive and Spark.</p> <p>Use <a href=../SQLConf/#isParquetINT96TimestampConversion>SQLConf.isParquetINT96TimestampConversion</a> method to access the current value.</p> <h2 id=sparksqlparquetoutputtimestamptype><span id=spark.sql.parquet.outputTimestampType> spark.sql.parquet.outputTimestampType<a class=headerlink href=#sparksqlparquetoutputtimestamptype title="Permanent link">&para;</a></h2> <p>Sets which Parquet timestamp type to use when Spark writes data to Parquet files. INT96 is a non-standard but commonly used timestamp type in Parquet. TIMESTAMP_MICROS is a standard timestamp type in Parquet, which stores number of microseconds from the Unix epoch. TIMESTAMP_MILLIS is also standard, but with millisecond precision, which means Spark has to truncate the microsecond portion of its timestamp value.</p> <p>Acceptable values:</p> <ul> <li><code>INT96</code></li> <li><code>TIMESTAMP_MICROS</code></li> <li><code>TIMESTAMP_MILLIS</code></li> </ul> <p>Default: <code>INT96</code></p> <p>Use <a href=../SQLConf/#parquetOutputTimestampType>SQLConf.parquetOutputTimestampType</a> method to access the current value.</p> <h2 id=sparksqlparquetrecordlevelfilterenabled><span id=spark.sql.parquet.recordLevelFilter.enabled> spark.sql.parquet.recordLevelFilter.enabled<a class=headerlink href=#sparksqlparquetrecordlevelfilterenabled title="Permanent link">&para;</a></h2> <p>Enables Parquet's native record-level filtering using the pushed down filters (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled).</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#parquetRecordFilterEnabled>SQLConf.parquetRecordFilterEnabled</a> method to access the current value.</p> <h2 id=sparksqlparquetrespectsummaryfiles><span id=spark.sql.parquet.respectSummaryFiles> spark.sql.parquet.respectSummaryFiles<a class=headerlink href=#sparksqlparquetrespectsummaryfiles title="Permanent link">&para;</a></h2> <p>When true, we make assumption that all part-files of Parquet are consistent with summary files and we will ignore them when merging schema. Otherwise, if this is false, which is the default, we will merge all part-files. This should be considered as expert-only option, and shouldn't be enabled before knowing what it means exactly.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#isParquetSchemaRespectSummaries>SQLConf.isParquetSchemaRespectSummaries</a> method to access the current value.</p> <h2 id=sparksqlparserquotedregexcolumnnames><span id=spark.sql.parser.quotedRegexColumnNames> spark.sql.parser.quotedRegexColumnNames<a class=headerlink href=#sparksqlparserquotedregexcolumnnames title="Permanent link">&para;</a></h2> <p>Controls whether quoted identifiers (using backticks) in SELECT statements should be interpreted as regular expressions.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#supportQuotedRegexColumnName>SQLConf.supportQuotedRegexColumnName</a> method to access the current value.</p> <h2 id=sparksqlpivotmaxvalues><span id=spark.sql.pivotMaxValues> spark.sql.pivotMaxValues<a class=headerlink href=#sparksqlpivotmaxvalues title="Permanent link">&para;</a></h2> <p>Maximum number of (distinct) values that will be collected without error (when doing a <a href=../RelationalGroupedDataset/#pivot>pivot</a> without specifying the values for the pivot column)</p> <p>Default: <code>10000</code></p> <p>Use <a href=../SQLConf/#dataFramePivotMaxValues>SQLConf.dataFramePivotMaxValues</a> method to access the current value.</p> <h2 id=sparksqlredactionoptionsregex><span id=spark.sql.redaction.options.regex> spark.sql.redaction.options.regex<a class=headerlink href=#sparksqlredactionoptionsregex title="Permanent link">&para;</a></h2> <p>Regular expression to find options of a Spark SQL command with sensitive information</p> <p>Default: <code>(?i)secret!password</code></p> <p>The values of the options matched will be redacted in the explain output.</p> <p>This redaction is applied on top of the global redaction configuration defined by <code>spark.redaction.regex</code> configuration.</p> <p>Used exclusively when <code>SQLConf</code> is requested to <a href=../SQLConf/#redactOptions>redactOptions</a>.</p> <h2 id=sparksqlredactionstringregex><span id=spark.sql.redaction.string.regex> spark.sql.redaction.string.regex<a class=headerlink href=#sparksqlredactionstringregex title="Permanent link">&para;</a></h2> <p>Regular expression to point at sensitive information in text output</p> <p>Default: <code>(undefined)</code></p> <p>When this regex matches a string part, it is replaced by a dummy value (i.e. <code>*********(redacted)</code>). This is currently used to redact the output of SQL explain commands.</p> <p>NOTE: When this conf is not set, the value of <code>spark.redaction.string.regex</code> is used instead.</p> <p>Use <a href=../SQLConf/#stringRedactionPattern>SQLConf.stringRedactionPattern</a> method to access the current value.</p> <h2 id=spark.sql.runSQLOnFiles>spark.sql.runSQLOnFiles<a class=headerlink href=#spark.sql.runSQLOnFiles title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables <code>datasource`.`path</code> table names in SQL queries for <a href=../files/FileFormat/ >FileFormat</a>-based data sources (excluding <a href=../hive/ >hive</a> tables)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#runSQLonFile>SQLConf.runSQLonFile</a> method to access the current value.</p> <p>Used when:</p> <ul> <li><a href=../logical-analysis-rules/ResolveSQLOnFile/ >ResolveSQLOnFile</a> logical analysis rule is executed</li> </ul> <h2 id=sparksqlselfjoinautoresolveambiguity><span id=spark.sql.selfJoinAutoResolveAmbiguity> spark.sql.selfJoinAutoResolveAmbiguity<a class=headerlink href=#sparksqlselfjoinautoresolveambiguity title="Permanent link">&para;</a></h2> <p>Controls whether to resolve ambiguity in join conditions for <a href=../joins/#join>self-joins</a> automatically (<code>true</code>) or not (<code>false</code>)</p> <p>Default: <code>true</code></p> <h2 id=sparksqlsortenableradixsort><span id=spark.sql.sort.enableRadixSort> spark.sql.sort.enableRadixSort<a class=headerlink href=#sparksqlsortenableradixsort title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether to use radix sort (<code>true</code>) or not (<code>false</code>) in <a href=../physical-operators/ShuffleExchangeExec/ >ShuffleExchangeExec</a> and <a href=../physical-operators/SortExec/ >SortExec</a> physical operators</p> <p>Default: <code>true</code></p> <p>Radix sort is much faster but requires additional memory to be reserved up-front. The memory overhead may be significant when sorting very small rows (up to 50% more).</p> <p>Use <a href=../SQLConf/#enableRadixSort>SQLConf.enableRadixSort</a> method to access the current value.</p> <h2 id=sparksqlsourcesdefault><span id=spark.sql.sources.default><span id=DEFAULT_DATA_SOURCE_NAME> spark.sql.sources.default<a class=headerlink href=#sparksqlsourcesdefault title="Permanent link">&para;</a></h2> <p>Default data source to use for loading or saving data</p> <p>Default: <a href=../parquet/ >parquet</a></p> <p>Use <a href=../SQLConf/#defaultDataSourceName>SQLConf.defaultDataSourceName</a> method to access the current value.</p> <h2 id=sparksqlstatisticsfallbacktohdfs><span id=spark.sql.statistics.fallBackToHdfs> spark.sql.statistics.fallBackToHdfs<a class=headerlink href=#sparksqlstatisticsfallbacktohdfs title="Permanent link">&para;</a></h2> <p>Enables automatic calculation of table size statistic by falling back to HDFS if the table statistics are not available from table metadata.</p> <p>Default: <code>false</code></p> <p>This can be useful in determining if a table is small enough for auto broadcast joins in query planning.</p> <p>Use <a href=../SQLConf/#fallBackToHdfsForStatsEnabled>SQLConf.fallBackToHdfsForStatsEnabled</a> method to access the current value.</p> <h2 id=sparksqlstatisticshistogramnumbins><span id=spark.sql.statistics.histogram.numBins> spark.sql.statistics.histogram.numBins<a class=headerlink href=#sparksqlstatisticshistogramnumbins title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The number of bins when generating histograms.</p> <p>Default: <code>254</code></p> <p>NOTE: The number of bins must be greater than 1.</p> <p>Use <a href=../SQLConf/#histogramNumBins>SQLConf.histogramNumBins</a> method to access the current value.</p> <h2 id=sparksqlstatisticsparallelfilelistinginstatscomputationenabled><span id=spark.sql.statistics.parallelFileListingInStatsComputation.enabled> spark.sql.statisticsparallelFileListingInStatsComputation.enabled*<a class=headerlink href=#sparksqlstatisticsparallelfilelistinginstatscomputationenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parallel file listing in SQL commands, e.g. <code>ANALYZE TABLE</code> (as opposed to single thread listing that can be particularly slow with tables with hundreds of partitions)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parallelFileListingInStatsComputation>SQLConf.parallelFileListingInStatsComputation</a> method to access the current value.</p> <h2 id=sparksqlstatisticsndvmaxerror><span id=spark.sql.statistics.ndv.maxError> spark.sql.statistics.ndv.maxError<a class=headerlink href=#sparksqlstatisticsndvmaxerror title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The maximum estimation error allowed in HyperLogLog++ algorithm when generating column level statistics.</p> <p>Default: <code>0.05</code></p> <h2 id=sparksqlstatisticspercentileaccuracy><span id=spark.sql.statistics.percentile.accuracy> spark.sql.statistics.percentile.accuracy<a class=headerlink href=#sparksqlstatisticspercentileaccuracy title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Accuracy of percentile approximation when generating equi-height histograms. Larger value means better accuracy. The relative error can be deduced by 1.0 / PERCENTILE_ACCURACY.</p> <p>Default: <code>10000</code></p> <h2 id=sparksqlstatisticssizeautoupdateenabled><span id=spark.sql.statistics.size.autoUpdate.enabled> spark.sql.statistics.size.autoUpdate.enabled<a class=headerlink href=#sparksqlstatisticssizeautoupdateenabled title="Permanent link">&para;</a></h2> <p>Enables automatic update of the table size statistic of a table after the table has changed.</p> <p>Default: <code>false</code></p> <p>IMPORTANT: If the total number of files of the table is very large this can be expensive and slow down data change commands.</p> <p>Use <a href=../SQLConf/#autoSizeUpdateEnabled>SQLConf.autoSizeUpdateEnabled</a> method to access the current value.</p> <h2 id=sparksqlsubexpressioneliminationenabled><span id=spark.sql.subexpressionElimination.enabled> spark.sql.subexpressionElimination.enabled<a class=headerlink href=#sparksqlsubexpressioneliminationenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables <a href=../subexpression-elimination/ >Subexpression Elimination</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#subexpressionEliminationEnabled>SQLConf.subexpressionEliminationEnabled</a> method to access the current value.</p> <h2 id=spark.sql.subexpressionElimination.skipForShortcutExpr><span id=SUBEXPRESSION_ELIMINATION_SKIP_FOR_SHORTCUT_EXPR><span id=subexpressionElimination.enabled> spark.sql.subexpressionElimination.enabled<a class=headerlink href=#spark.sql.subexpressionElimination.skipForShortcutExpr title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables shortcut eliminate subexpression with <code>AND</code> and <code>OR</code>.</p> <p>The subexpression may not need to eval even if it appears more than once, e.g., <code>if(or(a, and(b, b)))</code>, the expression <code>b</code> would be skipped if <code>a</code> is true.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#subexpressionEliminationSkipForShotcutExpr>SQLConf.subexpressionEliminationSkipForShotcutExpr</a> method to access the current value.</p> <p>Used when:</p> <ul> <li><a href=../subexpression-elimination/EquivalentExpressions/ >EquivalentExpressions</a> is created</li> </ul> <h2 id=sparksqlshufflepartitions><span id=spark.sql.shuffle.partitions> spark.sql.shuffle.partitions<a class=headerlink href=#sparksqlshufflepartitions title="Permanent link">&para;</a></h2> <p>The default number of partitions to use when shuffling data for joins or aggregations.</p> <p>Default: <code>200</code></p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>Corresponds to Apache Hive's <a href=https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-mapred.reduce.tasks>mapred.reduce.tasks</a> property that Spark SQL considers deprecated.</p> </div> <div class="admonition note"> <p class=admonition-title>Spark Structured Streaming</p> <p><code>spark.sql.shuffle.partitions</code> cannot be changed in Spark Structured Streaming between query restarts from the same checkpoint location.</p> </div> <p>Use <a href=../SQLConf/#numShufflePartitions>SQLConf.numShufflePartitions</a> method to access the current value.</p> <h2 id=sparksqlsourcesfilecompressionfactor><span id=spark.sql.sources.fileCompressionFactor> spark.sql.sources.fileCompressionFactor<a class=headerlink href=#sparksqlsourcesfilecompressionfactor title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When estimating the output data size of a table scan, multiply the file size with this factor as the estimated data size, in case the data is compressed in the file and lead to a heavily underestimated result.</p> <p>Default: <code>1.0</code></p> <p>Use <a href=../SQLConf/#fileCompressionFactor>SQLConf.fileCompressionFactor</a> method to access the current value.</p> <h2 id=sparksqlsourcespartitionoverwritemode><span id=spark.sql.sources.partitionOverwriteMode> spark.sql.sources.partitionOverwriteMode<a class=headerlink href=#sparksqlsourcespartitionoverwritemode title="Permanent link">&para;</a></h2> <p>Enables <a href=../dynamic-partition-inserts/ >dynamic partition inserts</a> when <code>dynamic</code></p> <p>Default: <code>static</code></p> <p>When <code>INSERT OVERWRITE</code> a partitioned data source table with dynamic partition columns, Spark SQL supports two modes (case-insensitive):</p> <ul> <li> <p><strong>static</strong> - Spark deletes all the partitions that match the partition specification (e.g. <code>PARTITION(a=1,b)</code>) in the INSERT statement, before overwriting</p> </li> <li> <p><strong>dynamic</strong> - Spark doesn't delete partitions ahead, and only overwrites those partitions that have data written into it</p> </li> </ul> <p>The default <code>STATIC</code> overwrite mode is to keep the same behavior of Spark prior to 2.3. Note that this config doesn't affect Hive serde tables, as they are always overwritten with dynamic mode.</p> <p>Use <a href=../SQLConf/#partitionOverwriteMode>SQLConf.partitionOverwriteMode</a> method to access the current value.</p> <h2 id=sparksqltruncatetableignorepermissionaclenabled><span id=spark.sql.truncateTable.ignorePermissionAcl.enabled> spark.sql.truncateTable.ignorePermissionAcl.enabled<a class=headerlink href=#sparksqltruncatetableignorepermissionaclenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Disables setting back original permission and ACLs when re-creating the table/partition paths for <a href=../logical-operators/TruncateTableCommand/ >TRUNCATE TABLE</a> command.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#truncateTableIgnorePermissionAcl>SQLConf.truncateTableIgnorePermissionAcl</a> method to access the current value.</p> <h2 id=sparksqluiretainedexecutions><span id=spark.sql.ui.retainedExecutions> spark.sql.ui.retainedExecutions<a class=headerlink href=#sparksqluiretainedexecutions title="Permanent link">&para;</a></h2> <p>Number of <code>SQLExecutionUIData</code>s to keep in <code>failedExecutions</code> and <code>completedExecutions</code> internal registries.</p> <p>Default: <code>1000</code></p> <p>When a query execution finishes, the execution is removed from the internal <code>activeExecutions</code> registry and stored in <code>failedExecutions</code> or <code>completedExecutions</code> given the end execution status. It is when <code>SQLListener</code> makes sure that the number of <code>SQLExecutionUIData</code> entires does not exceed <code>spark.sql.ui.retainedExecutions</code> Spark property and removes the excess of entries.</p> <h2 id=sparksqlvariablesubstitute><span id=spark.sql.variable.substitute> spark.sql.variable.substitute<a class=headerlink href=#sparksqlvariablesubstitute title="Permanent link">&para;</a></h2> <p>Enables <a href=../variable-substitution/ >Variable Substitution</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#variableSubstituteEnabled>SQLConf.variableSubstituteEnabled</a> method to access the current value.</p> <h2 id=sparksqlwindowexecbufferinmemorythreshold><span id=spark.sql.windowExec.buffer.in.memory.threshold> spark.sql.windowExec.buffer.in.memory.threshold<a class=headerlink href=#sparksqlwindowexecbufferinmemorythreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Threshold for number of rows guaranteed to be held in memory by <a href=../physical-operators/WindowExec/ >WindowExec</a> physical operator.</p> <p>Default: <code>4096</code></p> <p>Use <a href=../SQLConf/#windowExecBufferInMemoryThreshold>SQLConf.windowExecBufferInMemoryThreshold</a> method to access the current value.</p> <h2 id=sparksqlwindowexecbufferspillthreshold><span id=spark.sql.windowExec.buffer.spill.threshold> spark.sql.windowExec.buffer.spill.threshold<a class=headerlink href=#sparksqlwindowexecbufferspillthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Threshold for number of rows buffered in a <a href=../physical-operators/WindowExec/ >WindowExec</a> physical operator.</p> <p>Default: <code>4096</code></p> <p>Use <a href=../SQLConf/#windowExecBufferSpillThreshold>SQLConf.windowExecBufferSpillThreshold</a> method to access the current value.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2023-2024 Jacek Laskowski </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs Insiders </a> </div> <div class=md-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href=https://jaceklaskowski.medium.com target=_blank rel=noopener title=jaceklaskowski.medium.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M180.5 74.262C80.813 74.262 0 155.633 0 256s80.819 181.738 180.5 181.738S361 356.373 361 256 280.191 74.262 180.5 74.262Zm288.25 10.646c-49.845 0-90.245 76.619-90.245 171.095s40.406 171.1 90.251 171.1 90.251-76.619 90.251-171.1H559c0-94.503-40.4-171.095-90.248-171.095Zm139.506 17.821c-17.526 0-31.735 68.628-31.735 153.274s14.2 153.274 31.735 153.274S640 340.631 640 256c0-84.649-14.215-153.271-31.742-153.271Z"/></svg> </a> <a href=https://fosstodon.org/@jaceklaskowski target=_blank rel="noopener me" title=fosstodon.org class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "navigation.indexes", "navigation.instant", "navigation.path", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../assets/javascripts/workers/search.1e90e0fb.min.js", "tags": {"DeveloperApi": "developerapi"}, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../assets/javascripts/bundle.0d59af3e.min.js></script> </body> </html>