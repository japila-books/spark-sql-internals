<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Demystifying inner-workings of Spark SQL"><meta name=author content="Jacek Laskowski"><link href=https://books.japila.pl/spark-sql-internals/configuration-properties/ rel=canonical><link href=../overview/ rel=prev><link href=../CatalogStatistics/ rel=next><link rel=icon href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.4.2, mkdocs-material-9.0.3+insiders-4.27.1"><title>Configuration Properties - The Internals of Spark SQL</title><link rel=stylesheet href=../assets/stylesheets/main.a608ba1f.min.css><link rel=stylesheet href=../assets/stylesheets/palette.2505c338.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-4DR1Q2HBMZ"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-4DR1Q2HBMZ",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-4DR1Q2HBMZ",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#configuration-properties class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="The Internals of Spark SQL" class="md-header__button md-logo" aria-label="The Internals of Spark SQL" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> The Internals of Spark SQL </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Configuration Properties </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=blue data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/japila-books/spark-sql-internals title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-sql-internals </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../overview/ class="md-tabs__link md-tabs__link--active"> Internals </a> </li> <li class=md-tabs__item> <a href=../sql/ class=md-tabs__link> SQL </a> </li> <li class=md-tabs__item> <a href=../adaptive-query-execution/ class=md-tabs__link> Features </a> </li> <li class=md-tabs__item> <a href=../datasources/ class=md-tabs__link> Data Sources </a> </li> <li class=md-tabs__item> <a href=../basic-aggregation/ class=md-tabs__link> High-Level APIs </a> </li> <li class=md-tabs__item> <a href=../ui/ class=md-tabs__link> Web UI </a> </li> <li class=md-tabs__item> <a href=../demo/ class=md-tabs__link> Demo </a> </li> <li class=md-tabs__item> <a href=../AggregatingAccumulator/ class=md-tabs__link> Misc </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="The Internals of Spark SQL" class="md-nav__button md-logo" aria-label="The Internals of Spark SQL" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m19 2-5 4.5v11l5-4.5V2M6.5 5C4.55 5 2.45 5.4 1 6.5v14.66c0 .25.25.5.5.5.1 0 .15-.07.25-.07 1.35-.65 3.3-1.09 4.75-1.09 1.95 0 4.05.4 5.5 1.5 1.35-.85 3.8-1.5 5.5-1.5 1.65 0 3.35.31 4.75 1.06.1.05.15.03.25.03.25 0 .5-.25.5-.5V6.5c-.6-.45-1.25-.75-2-1V19c-1.1-.35-2.3-.5-3.5-.5-1.7 0-4.15.65-5.5 1.5V6.5C10.55 5.4 8.45 5 6.5 5Z"/></svg> </a> The Internals of Spark SQL </label> <div class=md-nav__source> <a href=https://github.com/japila-books/spark-sql-internals title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> spark-sql-internals </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2 type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 tabindex=0 aria-expanded=true> <span class=md-ellipsis> Internals </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Internals data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Internals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Configuration Properties </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Configuration Properties </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#optimizercanchangecachedplanoutputpartitioning class=md-nav__link> <span class=md-ellipsis> optimizer.canChangeCachedPlanOutputPartitioning </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdecorrelateinnerqueryenabled class=md-nav__link> <span class=md-ellipsis> optimizer.decorrelateInnerQuery.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningfallbackfilterratio class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.fallbackFilterRatio </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningpruningsideextrafilterratio class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningusestats class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.useStats </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningreusebroadcastonly class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.reuseBroadcastOnly </span> </a> </li> <li class=md-nav__item> <a href=#optimizerenablecsvexpressionoptimization class=md-nav__link> <span class=md-ellipsis> optimizer.enableCsvExpressionOptimization </span> </a> </li> <li class=md-nav__item> <a href=#optimizerexcludedrules class=md-nav__link> <span class=md-ellipsis> optimizer.excludedRules </span> </a> </li> <li class=md-nav__item> <a href=#optimizerexpressionnestedpruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.expression.nestedPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerinsetconversionthreshold class=md-nav__link> <span class=md-ellipsis> optimizer.inSetConversionThreshold </span> </a> </li> <li class=md-nav__item> <a href=#optimizerinsetswitchthreshold class=md-nav__link> <span class=md-ellipsis> optimizer.inSetSwitchThreshold </span> </a> </li> <li class=md-nav__item> <a href=#optimizermaxiterations class=md-nav__link> <span class=md-ellipsis> optimizer.maxIterations </span> </a> </li> <li class=md-nav__item> <a href=#optimizernestedschemapruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.nestedSchemaPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizernestedpredicatepushdownsupportedfilesources class=md-nav__link> <span class=md-ellipsis> optimizer.nestedPredicatePushdown.supportedFileSources </span> </a> </li> <li class=md-nav__item> <a href=#optimizeroptimizeonerowrelationsubquery class=md-nav__link> <span class=md-ellipsis> optimizer.optimizeOneRowRelationSubquery </span> </a> </li> <li class=md-nav__item> <a href=#optimizerplanchangelogbatches class=md-nav__link> <span class=md-ellipsis> optimizer.planChangeLog.batches </span> </a> </li> <li class=md-nav__item> <a href=#optimizerplanchangeloglevel class=md-nav__link> <span class=md-ellipsis> optimizer.planChangeLog.level </span> </a> </li> <li class=md-nav__item> <a href=#optimizerplanchangelogrules class=md-nav__link> <span class=md-ellipsis> optimizer.planChangeLog.rules </span> </a> </li> <li class=md-nav__item> <a href=#optimizerreplaceexceptwithfilter class=md-nav__link> <span class=md-ellipsis> optimizer.replaceExceptWithFilter </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimebloomfilterenabled class=md-nav__link> <span class=md-ellipsis> optimizer.runtime.bloomFilter.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimebloomfilterexpectednumitems class=md-nav__link> <span class=md-ellipsis> optimizer.runtime.bloomFilter.expectedNumItems </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimebloomfiltermaxnumbits class=md-nav__link> <span class=md-ellipsis> optimizer.runtime.bloomFilter.maxNumBits </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimefilternumberthreshold class=md-nav__link> <span class=md-ellipsis> optimizer.runtimeFilter.number.threshold </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimefiltersemijoinreductionenabled class=md-nav__link> <span class=md-ellipsis> optimizer.runtimeFilter.semiJoinReduction.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerserializernestedschemapruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.serializer.nestedSchemaPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveautobroadcastjointhreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.autoBroadcastJoinThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecustomcostevaluatorclass class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.customCostEvaluatorClass </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlobjecthashaggregatesortbasedfallbackthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.objectHashAggregate.sortBased.fallbackThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveoptimizeskewsinrebalancepartitionsenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatefasthashmapcapacitybit class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.fastHashMap.capacityBit </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemaptwolevelenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.twolevel.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemapvectorizedenable class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.vectorized.enable </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemaptwolevelpartialonly class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.twolevel.partialOnly </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownonemptylocationinctas class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowNonEmptyLocationInCTAS </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowautogeneratedaliasforview class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowAutoGeneratedAliasForView </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.sessionWindow.buffer.spill.threshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowpysparkselfdestructenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.pyspark.selfDestruct.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowstarwithsingletableidentifierincount class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowStarWithSingleTableIdentifierInCount </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.sessionWindow.buffer.in.memory.threshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcenablenestedcolumnvectorizedreader class=md-nav__link> <span class=md-ellipsis> spark.sql.orc.enableNestedColumnVectorizedReader </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveforceapply class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.forceApply </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsminpartitionsize class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.minPartitionSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsparallelismfirst class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.parallelismFirst </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveadvisorypartitionsizeinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.advisoryPartitionSizeInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsminpartitionsize_1 class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.minPartitionSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsinitialpartitionnum class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.initialPartitionNum </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivefetchshuffleblocksinbatch class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.fetchShuffleBlocksInBatch </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivelocalshufflereaderenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.localShuffleReader.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveloglevel class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.logLevel </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivemaxshuffledhashjoinlocalmapthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveoptimizerexcludedrules class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.optimizer.excludedRules </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveskewjoinenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.skewJoin.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveskewjoinskewedpartitionfactor class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.skewJoin.skewedPartitionFactor </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveskewjoinskewedpartitionthresholdinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivenonemptypartitionratioforbroadcastjoin class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzermaxiterations class=md-nav__link> <span class=md-ellipsis> spark.sql.analyzer.maxIterations </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzerfailambiguousselfjoin class=md-nav__link> <span class=md-ellipsis> spark.sql.analyzer.failAmbiguousSelfJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlansienabled class=md-nav__link> <span class=md-ellipsis> spark.sql.ansi.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcliprintheader class=md-nav__link> <span class=md-ellipsis> spark.sql.cli.print.header </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenwholestage class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.wholeStage </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenmethodsplitthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.methodSplitThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldebugmaxtostringfields class=md-nav__link> <span class=md-ellipsis> spark.sql.debug.maxToStringFields </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultcatalog class=md-nav__link> <span class=md-ellipsis> spark.sql.defaultCatalog </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowpysparkenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.pyspark.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionremoveredundantsorts class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.removeRedundantSorts </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionreusesubquery class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.reuseSubquery </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionsortbeforerepartition class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.sortBeforeRepartition </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionrangeexchangesamplesizeperpartition class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.rangeExchange.sampleSizePerPartition </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowpysparkfallbackenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.pyspark.fallback.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowsparkrenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.sparkr.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionpandasudfbuffersize class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.pandas.udf.buffer.size </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionpandasconverttoarrowarraysafely class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.pandas.convertToArrowArraySafely </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.histogram.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessiontimezone class=md-nav__link> <span class=md-ellipsis> spark.sql.session.timeZone </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcescommitprotocolclass class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.commitProtocolClass </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesignoredatalocality class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.ignoreDataLocality </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesoutputcommitterclass class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.outputCommitterClass </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesvalidatepartitioncolumns class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.validatePartitionColumns </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesusev1sourcelist class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.useV1SourceList </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstoreassignmentpolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.storeAssignmentPolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlthriftserverinterruptoncancel class=md-nav__link> <span class=md-ellipsis> spark.sql.thriftServer.interruptOnCancel </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlhivetablepropertylengththreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.hive.tablePropertyLengthThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcmergeschema class=md-nav__link> <span class=md-ellipsis> spark.sql.orc.mergeSchema </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbucketingautobucketedscanenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.bucketing.autoBucketedScan.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldatetimejava8apienabled class=md-nav__link> <span class=md-ellipsis> spark.sql.datetime.java8API.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyintervalenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.interval.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbinaryfilemaxlength class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.binaryFile.maxLength </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmapkeydeduppolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.mapKeyDedupPolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxconcurrentoutputfilewriters class=md-nav__link> <span class=md-ellipsis> spark.sql.maxConcurrentOutputFileWriters </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxmetadatastringlength class=md-nav__link> <span class=md-ellipsis> spark.sql.maxMetadataStringLength </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmavenadditionalremoterepositories class=md-nav__link> <span class=md-ellipsis> spark.sql.maven.additionalRemoteRepositories </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxplanstringlength class=md-nav__link> <span class=md-ellipsis> spark.sql.maxPlanStringLength </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladdpartitioninbatchsize class=md-nav__link> <span class=md-ellipsis> spark.sql.addPartitionInBatch.size </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlscripttransformationexittimeoutinseconds class=md-nav__link> <span class=md-ellipsis> spark.sql.scriptTransformation.exitTimeoutInSeconds </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlautobroadcastjointhreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.autoBroadcastJoinThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlavrocompressioncodec class=md-nav__link> <span class=md-ellipsis> spark.sql.avro.compression.codec </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbroadcasttimeout class=md-nav__link> <span class=md-ellipsis> spark.sql.broadcastTimeout </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbucketingcoalescebucketsinjoinenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.bucketing.coalesceBucketsInJoin.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcasesensitive class=md-nav__link> <span class=md-ellipsis> spark.sql.caseSensitive </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcatalogspark_catalog class=md-nav__link> <span class=md-ellipsis> spark.sql.catalog.spark_catalog </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbojoinreorderenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.joinReorder.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboplanstatsenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.planStats.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbostarschemadetection class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.starSchemaDetection </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemapvectorizedenable_1 class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.vectorized.enable </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatesplitaggregatefuncenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.splitAggregateFunc.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegencomments class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.comments </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenfactorymode class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.factoryMode </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenfallback class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.fallback </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenhugemethodlimit class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.hugeMethodLimit </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenuseidinclassname class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.useIdInClassName </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenmaxfields class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.maxFields </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegensplitconsumefuncbyoperator class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.splitConsumeFuncByOperator </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcolumnvectoroffheapenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.columnVector.offheap.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcolumnnameofcorruptrecord class=md-nav__link> <span class=md-ellipsis> spark.sql.columnNameOfCorruptRecord </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlconstraintpropagationenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.constraintPropagation.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcsvfilterpushdownenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.csv.filterPushdown.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultsizeinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.defaultSizeInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldialect class=md-nav__link> <span class=md-ellipsis> spark.sql.dialect </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexchangereuse class=md-nav__link> <span class=md-ellipsis> spark.sql.exchange.reuse </span> </a> </li> <li class=md-nav__item> <a href=#executionuseobjecthashaggregateexec class=md-nav__link> <span class=md-ellipsis> execution.useObjectHashAggregateExec </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignorecorruptfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.files.ignoreCorruptFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignoremissingfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.files.ignoreMissingFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesmaxrecordsperfile class=md-nav__link> <span class=md-ellipsis> spark.sql.files.maxRecordsPerFile </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesmaxpartitionbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.files.maxPartitionBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesminpartitionnum class=md-nav__link> <span class=md-ellipsis> spark.sql.files.minPartitionNum </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesopencostinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.files.openCostInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragecompressed class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.compressed </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragebatchsize class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.batchSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorytablescanstatisticsenable class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryTableScanStatistics.enable </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstorageenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.enableVectorizedReader </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragepartitionpruning class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.partitionPruning </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljoinprefersortmergejoin class=md-nav__link> <span class=md-ellipsis> spark.sql.join.preferSortMergeJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljsongeneratorignorenullfields class=md-nav__link> <span class=md-ellipsis> spark.sql.jsonGenerator.ignoreNullFields </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlleafnodedefaultparallelism class=md-nav__link> <span class=md-ellipsis> spark.sql.leafNodeDefaultParallelism </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydolooseupcast class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.doLooseUpcast </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycteprecedencepolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.ctePrecedencePolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytimeparserpolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.timeParserPolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfollowthreevaluedlogicinarrayexists class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.followThreeValuedLogicInArrayExists </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfromdaytimestringenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.fromDayTimeString.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacynotreserveproperties class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.notReserveProperties </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyaddsinglefileinaddfile class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.addSingleFileInAddFile </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyexponentliteralasdecimalenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.exponentLiteralAsDecimal.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownegativescaleofdecimal class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowNegativeScaleOfDecimal </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacybucketedtablescanoutputordering class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.bucketedTableScan.outputOrdering </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyjsonallowemptystringenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.json.allowEmptyString.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycreateemptycollectionusingstringtype class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.createEmptyCollectionUsingStringType </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowuntypedscalaudf class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowUntypedScalaUDF </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydatasetnamenonstructgroupingkeyasvalue class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacysetcommandrejectssparkcoreconfs class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.setCommandRejectsSparkCoreConfs </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytypecoerciondatetimetostringenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.typeCoercion.datetimeToString.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowhashonmaptype class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowHashOnMapType </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.parquet.datetimeRebaseModeInWrite </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.parquet.datetimeRebaseModeInRead </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.avro.datetimeRebaseModeInWrite </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.avro.datetimeRebaseModeInRead </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyrddapplyconf class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.rdd.applyConf </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyreplacedatabrickssparkavroenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.replaceDatabricksSparkAvro.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllimitscaleupfactor class=md-nav__link> <span class=md-ellipsis> spark.sql.limit.scaleUpFactor </span> </a> </li> <li class=md-nav__item> <a href=#sparksqloptimizenullawareantijoin class=md-nav__link> <span class=md-ellipsis> spark.sql.optimizeNullAwareAntiJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcimpl class=md-nav__link> <span class=md-ellipsis> spark.sql.orc.impl </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangeloglevel class=md-nav__link> <span class=md-ellipsis> spark.sql.planChangeLog.level </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogbatches class=md-nav__link> <span class=md-ellipsis> spark.sql.planChangeLog.batches </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogrules class=md-nav__link> <span class=md-ellipsis> spark.sql.planChangeLog.rules </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpysparkjvmstacktraceenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.pyspark.jvmStacktrace.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetbinaryasstring class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.binaryAsString </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetcolumnarreaderbatchsize class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.columnarReaderBatchSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetcompressioncodec class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.compression.codec </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.enableVectorizedReader </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdown class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndate class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.date </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndecimal class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.decimal </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96rebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.int96RebaseModeInWrite </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetpushdowninfilterthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.pushdown.inFilterThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdownstringstartswith class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.string.startsWith </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowntimestamp class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.timestamp </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96astimestamp class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.int96AsTimestamp </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96timestampconversion class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.int96TimestampConversion </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetmergeschema class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.mergeSchema </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetoutputcommitterclass class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.output.committer.class </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetoutputtimestamptype class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.outputTimestampType </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrecordlevelfilterenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.recordLevelFilter.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrespectsummaryfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.respectSummaryFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparserquotedregexcolumnnames class=md-nav__link> <span class=md-ellipsis> spark.sql.parser.quotedRegexColumnNames </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpivotmaxvalues class=md-nav__link> <span class=md-ellipsis> spark.sql.pivotMaxValues </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionoptionsregex class=md-nav__link> <span class=md-ellipsis> spark.sql.redaction.options.regex </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionstringregex class=md-nav__link> <span class=md-ellipsis> spark.sql.redaction.string.regex </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlretaingroupcolumns class=md-nav__link> <span class=md-ellipsis> spark.sql.retainGroupColumns </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlrunsqlonfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.runSQLOnFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlselfjoinautoresolveambiguity class=md-nav__link> <span class=md-ellipsis> spark.sql.selfJoinAutoResolveAmbiguity </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsortenableradixsort class=md-nav__link> <span class=md-ellipsis> spark.sql.sort.enableRadixSort </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbucketingenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.bucketing.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesdefault class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.default </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsfallbacktohdfs class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.fallBackToHdfs </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramnumbins class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.histogram.numBins </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsparallelfilelistinginstatscomputationenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.statisticsparallelFileListingInStatsComputation.enabled* </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsndvmaxerror class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.ndv.maxError </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticspercentileaccuracy class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.percentile.accuracy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticssizeautoupdateenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.size.autoUpdate.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsubexpressioneliminationenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.subexpressionElimination.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlshufflepartitions class=md-nav__link> <span class=md-ellipsis> spark.sql.shuffle.partitions </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesfilecompressionfactor class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.fileCompressionFactor </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcespartitionoverwritemode class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.partitionOverwriteMode </span> </a> </li> <li class=md-nav__item> <a href=#sparksqltruncatetableignorepermissionaclenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.truncateTable.ignorePermissionAcl.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqluiretainedexecutions class=md-nav__link> <span class=md-ellipsis> spark.sql.ui.retainedExecutions </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlvariablesubstitute class=md-nav__link> <span class=md-ellipsis> spark.sql.variable.substitute </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.windowExec.buffer.in.memory.threshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.windowExec.buffer.spill.threshold </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../CatalogStatistics/ class=md-nav__link> <span class=md-ellipsis> CatalogStatistics </span> </a> </li> <li class=md-nav__item> <a href=../DataSource/ class=md-nav__link> <span class=md-ellipsis> DataSource </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_5 type=checkbox id=__nav_2_5> <div class="md-nav__link md-nav__container"> <a href=../connector/ class="md-nav__link "> <span class=md-ellipsis> Connector API </span> </a> <label class="md-nav__link " for=__nav_2_5> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Connector API" data-md-level=2> <label class=md-nav__title for=__nav_2_5> <span class="md-nav__icon md-icon"></span> Connector API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../connector/ApplyTransform/ class=md-nav__link> <span class=md-ellipsis> ApplyTransform </span> </a> </li> <li class=md-nav__item> <a href=../connector/Batch/ class=md-nav__link> <span class=md-ellipsis> Batch </span> </a> </li> <li class=md-nav__item> <a href=../connector/BatchWrite/ class=md-nav__link> <span class=md-ellipsis> BatchWrite </span> </a> </li> <li class=md-nav__item> <a href=../connector/CustomMetric/ class=md-nav__link> <span class=md-ellipsis> CustomMetric </span> </a> </li> <li class=md-nav__item> <a href=../connector/DataSourceV2Implicits/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2Implicits </span> </a> </li> <li class=md-nav__item> <a href=../connector/DataWriter/ class=md-nav__link> <span class=md-ellipsis> DataWriter </span> </a> </li> <li class=md-nav__item> <a href=../connector/DataWriterFactory/ class=md-nav__link> <span class=md-ellipsis> DataWriterFactory </span> </a> </li> <li class=md-nav__item> <a href=../connector/InputPartition/ class=md-nav__link> <span class=md-ellipsis> InputPartition </span> </a> </li> <li class=md-nav__item> <a href=../connector/FileTable/ class=md-nav__link> <span class=md-ellipsis> FileTable </span> </a> </li> <li class=md-nav__item> <a href=../connector/MetadataColumn/ class=md-nav__link> <span class=md-ellipsis> MetadataColumn </span> </a> </li> <li class=md-nav__item> <a href=../connector/MetadataColumnHelper/ class=md-nav__link> <span class=md-ellipsis> MetadataColumnHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/MetadataColumnsHelper/ class=md-nav__link> <span class=md-ellipsis> MetadataColumnsHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/OptionsHelper/ class=md-nav__link> <span class=md-ellipsis> OptionsHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/Partitioning/ class=md-nav__link> <span class=md-ellipsis> Partitioning </span> </a> </li> <li class=md-nav__item> <a href=../connector/PartitionReader/ class=md-nav__link> <span class=md-ellipsis> PartitionReader </span> </a> </li> <li class=md-nav__item> <a href=../connector/PartitionReaderFactory/ class=md-nav__link> <span class=md-ellipsis> PartitionReaderFactory </span> </a> </li> <li class=md-nav__item> <a href=../connector/PartitionSpecsHelper/ class=md-nav__link> <span class=md-ellipsis> PartitionSpecsHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/Predicate/ class=md-nav__link> <span class=md-ellipsis> Predicate </span> </a> </li> <li class=md-nav__item> <a href=../connector/RewritableTransform/ class=md-nav__link> <span class=md-ellipsis> RewritableTransform </span> </a> </li> <li class=md-nav__item> <a href=../connector/Scan/ class=md-nav__link> <span class=md-ellipsis> Scan </span> </a> </li> <li class=md-nav__item> <a href=../connector/ScanBuilder/ class=md-nav__link> <span class=md-ellipsis> ScanBuilder </span> </a> </li> <li class=md-nav__item> <a href=../connector/SessionConfigSupport/ class=md-nav__link> <span class=md-ellipsis> SessionConfigSupport </span> </a> </li> <li class=md-nav__item> <a href=../connector/SimpleTableProvider/ class=md-nav__link> <span class=md-ellipsis> SimpleTableProvider </span> </a> </li> <li class=md-nav__item> <a href=../connector/StagedTable/ class=md-nav__link> <span class=md-ellipsis> StagedTable </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsAtomicPartitionManagement/ class=md-nav__link> <span class=md-ellipsis> SupportsAtomicPartitionManagement </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsDelete/ class=md-nav__link> <span class=md-ellipsis> SupportsDelete </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsDynamicOverwrite/ class=md-nav__link> <span class=md-ellipsis> SupportsDynamicOverwrite </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsMetadata/ class=md-nav__link> <span class=md-ellipsis> SupportsMetadata </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsMetadataColumns/ class=md-nav__link> <span class=md-ellipsis> SupportsMetadataColumns </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsOverwrite/ class=md-nav__link> <span class=md-ellipsis> SupportsOverwrite </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPartitionManagement/ class=md-nav__link> <span class=md-ellipsis> SupportsPartitionManagement </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPushDownFilters/ class=md-nav__link> <span class=md-ellipsis> SupportsPushDownFilters </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPushDownRequiredColumns/ class=md-nav__link> <span class=md-ellipsis> SupportsPushDownRequiredColumns </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsPushDownV2Filters/ class=md-nav__link> <span class=md-ellipsis> SupportsPushDownV2Filters </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsRead/ class=md-nav__link> <span class=md-ellipsis> SupportsRead </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsReportStatistics/ class=md-nav__link> <span class=md-ellipsis> SupportsReportStatistics </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsReportPartitioning/ class=md-nav__link> <span class=md-ellipsis> SupportsReportPartitioning </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsRowLevelOperations/ class=md-nav__link> <span class=md-ellipsis> SupportsRowLevelOperations </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsStreamingUpdate/ class=md-nav__link> <span class=md-ellipsis> SupportsStreamingUpdate </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsTruncate/ class=md-nav__link> <span class=md-ellipsis> SupportsTruncate </span> </a> </li> <li class=md-nav__item> <a href=../connector/SupportsWrite/ class=md-nav__link> <span class=md-ellipsis> SupportsWrite </span> </a> </li> <li class=md-nav__item> <a href=../connector/Table/ class=md-nav__link> <span class=md-ellipsis> Table </span> </a> </li> <li class=md-nav__item> <a href=../connector/TableCapability/ class=md-nav__link> <span class=md-ellipsis> TableCapability </span> </a> </li> <li class=md-nav__item> <a href=../connector/TableHelper/ class=md-nav__link> <span class=md-ellipsis> TableHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/TableProvider/ class=md-nav__link> <span class=md-ellipsis> TableProvider </span> </a> </li> <li class=md-nav__item> <a href=../connector/Transform/ class=md-nav__link> <span class=md-ellipsis> Transform </span> </a> </li> <li class=md-nav__item> <a href=../connector/TruncatableTable/ class=md-nav__link> <span class=md-ellipsis> TruncatableTable </span> </a> </li> <li class=md-nav__item> <a href=../connector/V1Scan/ class=md-nav__link> <span class=md-ellipsis> V1Scan </span> </a> </li> <li class=md-nav__item> <a href=../connector/V1Table/ class=md-nav__link> <span class=md-ellipsis> V1Table </span> </a> </li> <li class=md-nav__item> <a href=../connector/V1WriteBuilder/ class=md-nav__link> <span class=md-ellipsis> V1WriteBuilder </span> </a> </li> <li class=md-nav__item> <a href=../connector/Write/ class=md-nav__link> <span class=md-ellipsis> Write </span> </a> </li> <li class=md-nav__item> <a href=../connector/WriteBuilder/ class=md-nav__link> <span class=md-ellipsis> WriteBuilder </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_6 type=checkbox id=__nav_2_6> <label class=md-nav__link for=__nav_2_6 tabindex=0 aria-expanded=false> <span class=md-ellipsis> DataSource V1 API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="DataSource V1 API" data-md-level=2> <label class=md-nav__title for=__nav_2_6> <span class="md-nav__icon md-icon"></span> DataSource V1 API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../DataSourceRegister/ class=md-nav__link> <span class=md-ellipsis> DataSourceRegister </span> </a> </li> <li class=md-nav__item> <a href=../CreatableRelationProvider/ class=md-nav__link> <span class=md-ellipsis> CreatableRelationProvider </span> </a> </li> <li class=md-nav__item> <a href=../RelationProvider/ class=md-nav__link> <span class=md-ellipsis> RelationProvider </span> </a> </li> <li class=md-nav__item> <a href=../SchemaRelationProvider/ class=md-nav__link> <span class=md-ellipsis> SchemaRelationProvider </span> </a> </li> <li class=md-nav__item> <a href=../BaseRelation/ class=md-nav__link> <span class=md-ellipsis> BaseRelation </span> </a> </li> <li class=md-nav__item> <a href=../FileRelation/ class=md-nav__link> <span class=md-ellipsis> FileRelation </span> </a> </li> <li class=md-nav__item> <a href=../InsertableRelation/ class=md-nav__link> <span class=md-ellipsis> InsertableRelation </span> </a> </li> <li class=md-nav__item> <a href=../PrunedFilteredScan/ class=md-nav__link> <span class=md-ellipsis> PrunedFilteredScan </span> </a> </li> <li class=md-nav__item> <a href=../PrunedScan/ class=md-nav__link> <span class=md-ellipsis> PrunedScan </span> </a> </li> <li class=md-nav__item> <a href=../TableScan/ class=md-nav__link> <span class=md-ellipsis> TableScan </span> </a> </li> <li class=md-nav__item> <a href=../Filter/ class=md-nav__link> <span class=md-ellipsis> Filter </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ExecutionListenerBus/ class=md-nav__link> <span class=md-ellipsis> ExecutionListenerBus </span> </a> </li> <li class=md-nav__item> <a href=../ExecutionListenerManager/ class=md-nav__link> <span class=md-ellipsis> ExecutionListenerManager </span> </a> </li> <li class=md-nav__item> <a href=../Observation/ class=md-nav__link> <span class=md-ellipsis> Observation </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_10 type=checkbox id=__nav_2_10> <div class="md-nav__link md-nav__container"> <a href=../query-execution/ class="md-nav__link "> <span class=md-ellipsis> Query Execution </span> </a> <label class="md-nav__link " for=__nav_2_10> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Query Execution" data-md-level=2> <label class=md-nav__title for=__nav_2_10> <span class="md-nav__icon md-icon"></span> Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Analyzer/ class=md-nav__link> <span class=md-ellipsis> Logical Analyzer </span> </a> </li> <li class=md-nav__item> <a href=../QueryExecution/ class=md-nav__link> <span class=md-ellipsis> QueryExecution </span> </a> </li> <li class=md-nav__item> <a href=../QueryPlanningTracker/ class=md-nav__link> <span class=md-ellipsis> QueryPlanningTracker </span> </a> </li> <li class=md-nav__item> <a href=../SparkOptimizer/ class=md-nav__link> <span class=md-ellipsis> SparkOptimizer </span> </a> </li> <li class=md-nav__item> <a href=../SparkPlanner/ class=md-nav__link> <span class=md-ellipsis> SparkPlanner </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../SharedState/ class=md-nav__link> <span class=md-ellipsis> SharedState </span> </a> </li> <li class=md-nav__item> <a href=../SQLConf/ class=md-nav__link> <span class=md-ellipsis> SQLConf </span> </a> </li> <li class=md-nav__item> <a href=../StaticSQLConf/ class=md-nav__link> <span class=md-ellipsis> StaticSQLConf </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_14 type=checkbox id=__nav_2_14> <label class=md-nav__link for=__nav_2_14 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Statistics and Hints </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Statistics and Hints" data-md-level=2> <label class=md-nav__title for=__nav_2_14> <span class="md-nav__icon md-icon"></span> Statistics and Hints </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logical-operators/Statistics/ class=md-nav__link> <span class=md-ellipsis> Statistics </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalPlanStats/ class=md-nav__link> <span class=md-ellipsis> LogicalPlanStats </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalPlanVisitor/ class=md-nav__link> <span class=md-ellipsis> LogicalPlanVisitor </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SizeInBytesOnlyStatsPlanVisitor/ class=md-nav__link> <span class=md-ellipsis> SizeInBytesOnlyStatsPlanVisitor </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/BasicStatsPlanVisitor/ class=md-nav__link> <span class=md-ellipsis> BasicStatsPlanVisitor </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/JoinEstimation/ class=md-nav__link> <span class=md-ellipsis> JoinEstimation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_15 type=checkbox id=__nav_2_15> <div class="md-nav__link md-nav__container"> <a href=../logical-operators/ class="md-nav__link "> <span class=md-ellipsis> Logical Operators </span> </a> <label class="md-nav__link " for=__nav_2_15> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Logical Operators" data-md-level=2> <label class=md-nav__title for=__nav_2_15> <span class="md-nav__icon md-icon"></span> Logical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logical-operators/AddColumns/ class=md-nav__link> <span class=md-ellipsis> AddColumns </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Aggregate/ class=md-nav__link> <span class=md-ellipsis> Aggregate </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AlterTable/ class=md-nav__link> <span class=md-ellipsis> AlterTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AlterTableAddColumnsCommand/ class=md-nav__link> <span class=md-ellipsis> AlterTableAddColumnsCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AlterTableCommand/ class=md-nav__link> <span class=md-ellipsis> AlterTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeColumn/ class=md-nav__link> <span class=md-ellipsis> AnalyzeColumn </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeColumnCommand/ class=md-nav__link> <span class=md-ellipsis> AnalyzeColumnCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzePartitionCommand/ class=md-nav__link> <span class=md-ellipsis> AnalyzePartitionCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeTable/ class=md-nav__link> <span class=md-ellipsis> AnalyzeTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AnalyzeTableCommand/ class=md-nav__link> <span class=md-ellipsis> AnalyzeTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/AppendData/ class=md-nav__link> <span class=md-ellipsis> AppendData </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CacheTableCommand/ class=md-nav__link> <span class=md-ellipsis> CacheTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ClearCacheCommand/ class=md-nav__link> <span class=md-ellipsis> ClearCacheCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CollectMetrics/ class=md-nav__link> <span class=md-ellipsis> CollectMetrics </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Command/ class=md-nav__link> <span class=md-ellipsis> Command </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CommentOnTable/ class=md-nav__link> <span class=md-ellipsis> CommentOnTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateDataSourceTableAsSelectCommand/ class=md-nav__link> <span class=md-ellipsis> CreateDataSourceTableAsSelectCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateDataSourceTableCommand/ class=md-nav__link> <span class=md-ellipsis> CreateDataSourceTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateTable/ class=md-nav__link> <span class=md-ellipsis> CreateTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateTableAsSelect/ class=md-nav__link> <span class=md-ellipsis> CreateTableAsSelect </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateTempViewUsing/ class=md-nav__link> <span class=md-ellipsis> CreateTempViewUsing </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CreateViewCommand/ class=md-nav__link> <span class=md-ellipsis> CreateViewCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CTERelationDef/ class=md-nav__link> <span class=md-ellipsis> CTERelationDef </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/CTERelationRef/ class=md-nav__link> <span class=md-ellipsis> CTERelationRef </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DataSourceV2Relation/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2Relation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DataSourceV2ScanRelation/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2ScanRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DataWritingCommand/ class=md-nav__link> <span class=md-ellipsis> DataWritingCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DeleteFromTable/ class=md-nav__link> <span class=md-ellipsis> DeleteFromTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DescribeColumnCommand/ class=md-nav__link> <span class=md-ellipsis> DescribeColumnCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DescribeRelation/ class=md-nav__link> <span class=md-ellipsis> DescribeRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DescribeTableCommand/ class=md-nav__link> <span class=md-ellipsis> DescribeTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/DeserializeToObject/ class=md-nav__link> <span class=md-ellipsis> DeserializeToObject </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Except/ class=md-nav__link> <span class=md-ellipsis> Except </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Expand/ class=md-nav__link> <span class=md-ellipsis> Expand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ExplainCommand/ class=md-nav__link> <span class=md-ellipsis> ExplainCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ExternalRDD/ class=md-nav__link> <span class=md-ellipsis> ExternalRDD </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/FlatMapGroupsWithState/ class=md-nav__link> <span class=md-ellipsis> FlatMapGroupsWithState </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Generate/ class=md-nav__link> <span class=md-ellipsis> Generate </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/GlobalLimit/ class=md-nav__link> <span class=md-ellipsis> GlobalLimit </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/GroupingSets/ class=md-nav__link> <span class=md-ellipsis> GroupingSets </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/IgnoreCachedData/ class=md-nav__link> <span class=md-ellipsis> IgnoreCachedData </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InMemoryRelation/ class=md-nav__link> <span class=md-ellipsis> InMemoryRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoDataSourceCommand/ class=md-nav__link> <span class=md-ellipsis> InsertIntoDataSourceCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoDir/ class=md-nav__link> <span class=md-ellipsis> InsertIntoDir </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoHadoopFsRelationCommand/ class=md-nav__link> <span class=md-ellipsis> InsertIntoHadoopFsRelationCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoStatement/ class=md-nav__link> <span class=md-ellipsis> InsertIntoStatement </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/InsertIntoTable/ class=md-nav__link> <span class=md-ellipsis> InsertIntoTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Join/ class=md-nav__link> <span class=md-ellipsis> Join </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LeafNode/ class=md-nav__link> <span class=md-ellipsis> LeafNode </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LeafRunnableCommand/ class=md-nav__link> <span class=md-ellipsis> LeafRunnableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LocalRelation/ class=md-nav__link> <span class=md-ellipsis> LocalRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalPlan/ class=md-nav__link> <span class=md-ellipsis> LogicalPlan </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalQueryStage/ class=md-nav__link> <span class=md-ellipsis> LogicalQueryStage </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalRDD/ class=md-nav__link> <span class=md-ellipsis> LogicalRDD </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/LogicalRelation/ class=md-nav__link> <span class=md-ellipsis> LogicalRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/MapPartitions/ class=md-nav__link> <span class=md-ellipsis> MapPartitions </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/MergeIntoTable/ class=md-nav__link> <span class=md-ellipsis> MergeIntoTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/MultiInstanceRelation/ class=md-nav__link> <span class=md-ellipsis> MultiInstanceRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/NamedRelation/ class=md-nav__link> <span class=md-ellipsis> NamedRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/OverwriteByExpression/ class=md-nav__link> <span class=md-ellipsis> OverwriteByExpression </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/OverwritePartitionsDynamic/ class=md-nav__link> <span class=md-ellipsis> OverwritePartitionsDynamic </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ParsedStatement/ class=md-nav__link> <span class=md-ellipsis> ParsedStatement </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Pivot/ class=md-nav__link> <span class=md-ellipsis> Pivot </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Project/ class=md-nav__link> <span class=md-ellipsis> Project </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RebalancePartitions/ class=md-nav__link> <span class=md-ellipsis> RebalancePartitions </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Repartition/ class=md-nav__link> <span class=md-ellipsis> Repartition </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RepartitionByExpression/ class=md-nav__link> <span class=md-ellipsis> RepartitionByExpression </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RepartitionOperation/ class=md-nav__link> <span class=md-ellipsis> RepartitionOperation </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ReplaceData/ class=md-nav__link> <span class=md-ellipsis> ReplaceData </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ResolvedHint/ class=md-nav__link> <span class=md-ellipsis> ResolvedHint </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ResolvedTable/ class=md-nav__link> <span class=md-ellipsis> ResolvedTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RowLevelWrite/ class=md-nav__link> <span class=md-ellipsis> RowLevelWrite </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/RunnableCommand/ class=md-nav__link> <span class=md-ellipsis> RunnableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SaveIntoDataSourceCommand/ class=md-nav__link> <span class=md-ellipsis> SaveIntoDataSourceCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SetCatalogAndNamespace/ class=md-nav__link> <span class=md-ellipsis> SetCatalogAndNamespace </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowCreateTableCommand/ class=md-nav__link> <span class=md-ellipsis> ShowCreateTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowTableProperties/ class=md-nav__link> <span class=md-ellipsis> ShowTableProperties </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowTablePropertiesCommand/ class=md-nav__link> <span class=md-ellipsis> ShowTablePropertiesCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/ShowTables/ class=md-nav__link> <span class=md-ellipsis> ShowTables </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Sort/ class=md-nav__link> <span class=md-ellipsis> Sort </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SubqueryAlias/ class=md-nav__link> <span class=md-ellipsis> SubqueryAlias </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/SupportsSubquery/ class=md-nav__link> <span class=md-ellipsis> SupportsSubquery </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/TruncateTableCommand/ class=md-nav__link> <span class=md-ellipsis> TruncateTableCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedHaving/ class=md-nav__link> <span class=md-ellipsis> UnresolvedHaving </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedHint/ class=md-nav__link> <span class=md-ellipsis> UnresolvedHint </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedTable/ class=md-nav__link> <span class=md-ellipsis> UnresolvedTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedTableOrView/ class=md-nav__link> <span class=md-ellipsis> UnresolvedTableOrView </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UnresolvedWith/ class=md-nav__link> <span class=md-ellipsis> UnresolvedWith </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/UpdateTable/ class=md-nav__link> <span class=md-ellipsis> UpdateTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/V2CreateTablePlan/ class=md-nav__link> <span class=md-ellipsis> V2CreateTablePlan </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/V2WriteCommand/ class=md-nav__link> <span class=md-ellipsis> V2WriteCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/View/ class=md-nav__link> <span class=md-ellipsis> View </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/Window/ class=md-nav__link> <span class=md-ellipsis> Window </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/WithCTE/ class=md-nav__link> <span class=md-ellipsis> WithCTE </span> </a> </li> <li class=md-nav__item> <a href=../logical-operators/WithWindowDefinition/ class=md-nav__link> <span class=md-ellipsis> WithWindowDefinition </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_16 type=checkbox id=__nav_2_16> <label class=md-nav__link for=__nav_2_16 tabindex=0 aria-expanded=false> <span class=md-ellipsis> SparkSession Registries </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="SparkSession Registries" data-md-level=2> <label class=md-nav__title for=__nav_2_16> <span class="md-nav__icon md-icon"></span> SparkSession Registries </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_16_1 type=checkbox id=__nav_2_16_1> <label class=md-nav__link for=__nav_2_16_1 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Catalog data-md-level=3> <label class=md-nav__title for=__nav_2_16_1> <span class="md-nav__icon md-icon"></span> Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Catalog/ class=md-nav__link> <span class=md-ellipsis> Catalog </span> </a> </li> <li class=md-nav__item> <a href=../CatalogImpl/ class=md-nav__link> <span class=md-ellipsis> CatalogImpl </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ExperimentalMethods/ class=md-nav__link> <span class=md-ellipsis> ExperimentalMethods </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_16_3 type=checkbox id=__nav_2_16_3> <label class=md-nav__link for=__nav_2_16_3 tabindex=0 aria-expanded=false> <span class=md-ellipsis> ExternalCatalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=ExternalCatalog data-md-level=3> <label class=md-nav__title for=__nav_2_16_3> <span class="md-nav__icon md-icon"></span> ExternalCatalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ExternalCatalog/ class=md-nav__link> <span class=md-ellipsis> ExternalCatalog </span> </a> </li> <li class=md-nav__item> <a href=../InMemoryCatalog/ class=md-nav__link> <span class=md-ellipsis> InMemoryCatalog </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_16_4 type=checkbox id=__nav_2_16_4> <label class=md-nav__link for=__nav_2_16_4 tabindex=0 aria-expanded=false> <span class=md-ellipsis> FunctionRegistry </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=FunctionRegistry data-md-level=3> <label class=md-nav__title for=__nav_2_16_4> <span class="md-nav__icon md-icon"></span> FunctionRegistry </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../FunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> FunctionRegistry </span> </a> </li> <li class=md-nav__item> <a href=../FunctionRegistryBase/ class=md-nav__link> <span class=md-ellipsis> FunctionRegistryBase </span> </a> </li> <li class=md-nav__item> <a href=../SimpleFunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> SimpleFunctionRegistry </span> </a> </li> <li class=md-nav__item> <a href=../SimpleFunctionRegistryBase/ class=md-nav__link> <span class=md-ellipsis> SimpleFunctionRegistryBase </span> </a> </li> <li class=md-nav__item> <a href=../SimpleTableFunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> SimpleTableFunctionRegistry </span> </a> </li> <li class=md-nav__item> <a href=../TableFunctionRegistry/ class=md-nav__link> <span class=md-ellipsis> TableFunctionRegistry </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../GlobalTempViewManager/ class=md-nav__link> <span class=md-ellipsis> GlobalTempViewManager </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_16_6 type=checkbox id=__nav_2_16_6> <label class=md-nav__link for=__nav_2_16_6 tabindex=0 aria-expanded=false> <span class=md-ellipsis> SessionCatalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SessionCatalog data-md-level=3> <label class=md-nav__title for=__nav_2_16_6> <span class="md-nav__icon md-icon"></span> SessionCatalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../SessionCatalog/ class=md-nav__link> <span class=md-ellipsis> SessionCatalog </span> </a> </li> <li class=md-nav__item> <a href=../BucketSpec/ class=md-nav__link> <span class=md-ellipsis> BucketSpec </span> </a> </li> <li class=md-nav__item> <a href=../CatalogStorageFormat/ class=md-nav__link> <span class=md-ellipsis> CatalogStorageFormat </span> </a> </li> <li class=md-nav__item> <a href=../CatalogTable/ class=md-nav__link> <span class=md-ellipsis> CatalogTable </span> </a> </li> <li class=md-nav__item> <a href=../CatalogTablePartition/ class=md-nav__link> <span class=md-ellipsis> CatalogTablePartition </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../V2SessionCatalog/ class=md-nav__link> <span class=md-ellipsis> V2SessionCatalog </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_16_8 type=checkbox id=__nav_2_16_8> <label class=md-nav__link for=__nav_2_16_8 tabindex=0 aria-expanded=false> <span class=md-ellipsis> SessionState </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SessionState data-md-level=3> <label class=md-nav__title for=__nav_2_16_8> <span class="md-nav__icon md-icon"></span> SessionState </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../SessionState/ class=md-nav__link> <span class=md-ellipsis> SessionState </span> </a> </li> <li class=md-nav__item> <a href=../BaseSessionStateBuilder/ class=md-nav__link> <span class=md-ellipsis> BaseSessionStateBuilder </span> </a> </li> <li class=md-nav__item> <a href=../SessionStateBuilder/ class=md-nav__link> <span class=md-ellipsis> SessionStateBuilder </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_16_9 type=checkbox id=__nav_2_16_9> <label class=md-nav__link for=__nav_2_16_9 tabindex=0 aria-expanded=false> <span class=md-ellipsis> CacheManager </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CacheManager data-md-level=3> <label class=md-nav__title for=__nav_2_16_9> <span class="md-nav__icon md-icon"></span> CacheManager </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CacheManager/ class=md-nav__link> <span class=md-ellipsis> CacheManager </span> </a> </li> <li class=md-nav__item> <a href=../CachedRDDBuilder/ class=md-nav__link> <span class=md-ellipsis> CachedRDDBuilder </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../RuntimeConfig/ class=md-nav__link> <span class=md-ellipsis> RuntimeConfig </span> </a> </li> <li class=md-nav__item> <a href=../UDFRegistration/ class=md-nav__link> <span class=md-ellipsis> UDFRegistration </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_17 type=checkbox id=__nav_2_17> <div class="md-nav__link md-nav__container"> <a href=../catalyst/ class="md-nav__link "> <span class=md-ellipsis> Catalyst </span> </a> <label class="md-nav__link " for=__nav_2_17> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Catalyst data-md-level=2> <label class=md-nav__title for=__nav_2_17> <span class="md-nav__icon md-icon"></span> Catalyst </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../catalyst/GenericStrategy/ class=md-nav__link> <span class=md-ellipsis> GenericStrategy </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/Optimizer/ class=md-nav__link> <span class=md-ellipsis> Optimizer </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/PlanChangeLogger/ class=md-nav__link> <span class=md-ellipsis> PlanChangeLogger </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/QueryPlan/ class=md-nav__link> <span class=md-ellipsis> QueryPlan </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/QueryPlanner/ class=md-nav__link> <span class=md-ellipsis> QueryPlanner </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/Rule/ class=md-nav__link> <span class=md-ellipsis> Rule </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/RuleExecutor/ class=md-nav__link> <span class=md-ellipsis> RuleExecutor </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/TreeNode/ class=md-nav__link> <span class=md-ellipsis> TreeNode </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/TreePattern/ class=md-nav__link> <span class=md-ellipsis> TreePattern </span> </a> </li> <li class=md-nav__item> <a href=../catalyst/TreePatternBits/ class=md-nav__link> <span class=md-ellipsis> TreePatternBits </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_18 type=checkbox id=__nav_2_18> <label class=md-nav__link for=__nav_2_18 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Encoder </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Encoder data-md-level=2> <label class=md-nav__title for=__nav_2_18> <span class="md-nav__icon md-icon"></span> Encoder </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Encoder/ class=md-nav__link> <span class=md-ellipsis> Encoder </span> </a> </li> <li class=md-nav__item> <a href=../ExpressionEncoder/ class=md-nav__link> <span class=md-ellipsis> ExpressionEncoder </span> </a> </li> <li class=md-nav__item> <a href=../RowEncoder/ class=md-nav__link> <span class=md-ellipsis> RowEncoder </span> </a> </li> <li class=md-nav__item> <a href=../ScalaReflection/ class=md-nav__link> <span class=md-ellipsis> ScalaReflection </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_19 type=checkbox id=__nav_2_19> <div class="md-nav__link md-nav__container"> <a href=../expressions/ class="md-nav__link "> <span class=md-ellipsis> Expressions </span> </a> <label class="md-nav__link " for=__nav_2_19> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Expressions data-md-level=2> <label class=md-nav__title for=__nav_2_19> <span class="md-nav__icon md-icon"></span> Expressions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../expressions/AggregateExpression/ class=md-nav__link> <span class=md-ellipsis> AggregateExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/AggregateFunction/ class=md-nav__link> <span class=md-ellipsis> AggregateFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/AggregateWindowFunction/ class=md-nav__link> <span class=md-ellipsis> AggregateWindowFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Aggregator/ class=md-nav__link> <span class=md-ellipsis> Aggregator </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ArrayFilter/ class=md-nav__link> <span class=md-ellipsis> ArrayFilter </span> </a> </li> <li class=md-nav__item> <a href=../expressions/AttributeSeq/ class=md-nav__link> <span class=md-ellipsis> AttributeSeq </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Attribute/ class=md-nav__link> <span class=md-ellipsis> Attribute </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BasePredicate/ class=md-nav__link> <span class=md-ellipsis> BasePredicate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BinaryComparison/ class=md-nav__link> <span class=md-ellipsis> BinaryComparison </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BinaryOperator/ class=md-nav__link> <span class=md-ellipsis> BinaryOperator </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BloomFilterAggregate/ class=md-nav__link> <span class=md-ellipsis> BloomFilterAggregate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BloomFilterMightContain/ class=md-nav__link> <span class=md-ellipsis> BloomFilterMightContain </span> </a> </li> <li class=md-nav__item> <a href=../expressions/BoundReference/ class=md-nav__link> <span class=md-ellipsis> BoundReference </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CallMethodViaReflection/ class=md-nav__link> <span class=md-ellipsis> CallMethodViaReflection </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CodeGeneratorWithInterpretedFallback/ class=md-nav__link> <span class=md-ellipsis> CodeGeneratorWithInterpretedFallback </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CodegenFallback/ class=md-nav__link> <span class=md-ellipsis> CodegenFallback </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Collect/ class=md-nav__link> <span class=md-ellipsis> Collect </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CollectSet/ class=md-nav__link> <span class=md-ellipsis> CollectSet </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CreateNamedStruct/ class=md-nav__link> <span class=md-ellipsis> CreateNamedStruct </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CreateStruct/ class=md-nav__link> <span class=md-ellipsis> CreateStruct </span> </a> </li> <li class=md-nav__item> <a href=../expressions/CumeDist/ class=md-nav__link> <span class=md-ellipsis> CumeDist </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DeclarativeAggregate/ class=md-nav__link> <span class=md-ellipsis> DeclarativeAggregate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DecodeUsingSerializer/ class=md-nav__link> <span class=md-ellipsis> DecodeUsingSerializer </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DynamicPruningExpression/ class=md-nav__link> <span class=md-ellipsis> DynamicPruningExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/DynamicPruningSubquery/ class=md-nav__link> <span class=md-ellipsis> DynamicPruningSubquery </span> </a> </li> <li class=md-nav__item> <a href=../expressions/EncodeUsingSerializer/ class=md-nav__link> <span class=md-ellipsis> EncodeUsingSerializer </span> </a> </li> <li class=md-nav__item> <a href=../expressions/EqualNullSafe/ class=md-nav__link> <span class=md-ellipsis> EqualNullSafe </span> </a> </li> <li class=md-nav__item> <a href=../expressions/EqualTo/ class=md-nav__link> <span class=md-ellipsis> EqualTo </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExecSubqueryExpression/ class=md-nav__link> <span class=md-ellipsis> ExecSubqueryExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Exists/ class=md-nav__link> <span class=md-ellipsis> Exists </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExpectsInputTypes/ class=md-nav__link> <span class=md-ellipsis> ExpectsInputTypes </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExplodeBase/ class=md-nav__link> <span class=md-ellipsis> ExplodeBase </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Expression/ class=md-nav__link> <span class=md-ellipsis> Expression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/First/ class=md-nav__link> <span class=md-ellipsis> First </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Generator/ class=md-nav__link> <span class=md-ellipsis> Generator </span> </a> </li> <li class=md-nav__item> <a href=../expressions/HashExpression/ class=md-nav__link> <span class=md-ellipsis> HashExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/HashPartitioning/ class=md-nav__link> <span class=md-ellipsis> HashPartitioning </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_19_39 type=checkbox id=__nav_2_19_39> <label class=md-nav__link for=__nav_2_19_39 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Higher-Order Functions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Higher-Order Functions" data-md-level=3> <label class=md-nav__title for=__nav_2_19_39> <span class="md-nav__icon md-icon"></span> Higher-Order Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../expressions/HigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> HigherOrderFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ArrayBasedSimpleHigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> ArrayBasedSimpleHigherOrderFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/MapBasedSimpleHigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> MapBasedSimpleHigherOrderFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SimpleHigherOrderFunction/ class=md-nav__link> <span class=md-ellipsis> SimpleHigherOrderFunction </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../expressions/ImperativeAggregate/ class=md-nav__link> <span class=md-ellipsis> ImperativeAggregate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/In/ class=md-nav__link> <span class=md-ellipsis> In </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Inline/ class=md-nav__link> <span class=md-ellipsis> Inline </span> </a> </li> <li class=md-nav__item> <a href=../expressions/InSet/ class=md-nav__link> <span class=md-ellipsis> InSet </span> </a> </li> <li class=md-nav__item> <a href=../expressions/InSubqueryExec/ class=md-nav__link> <span class=md-ellipsis> InSubqueryExec </span> </a> </li> <li class=md-nav__item> <a href=../expressions/InterpretedProjection/ class=md-nav__link> <span class=md-ellipsis> InterpretedProjection </span> </a> </li> <li class=md-nav__item> <a href=../expressions/JsonToStructs/ class=md-nav__link> <span class=md-ellipsis> JsonToStructs </span> </a> </li> <li class=md-nav__item> <a href=../expressions/LessThanOrEqual/ class=md-nav__link> <span class=md-ellipsis> LessThanOrEqual </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ListQuery/ class=md-nav__link> <span class=md-ellipsis> ListQuery </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Literal/ class=md-nav__link> <span class=md-ellipsis> Literal </span> </a> </li> <li class=md-nav__item> <a href=../expressions/MonotonicallyIncreasingID/ class=md-nav__link> <span class=md-ellipsis> MonotonicallyIncreasingID </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Murmur3Hash/ class=md-nav__link> <span class=md-ellipsis> Murmur3Hash </span> </a> </li> <li class=md-nav__item> <a href=../expressions/MutableProjection/ class=md-nav__link> <span class=md-ellipsis> MutableProjection </span> </a> </li> <li class=md-nav__item> <a href=../expressions/NamedExpression/ class=md-nav__link> <span class=md-ellipsis> NamedExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Nondeterministic/ class=md-nav__link> <span class=md-ellipsis> Nondeterministic </span> </a> </li> <li class=md-nav__item> <a href=../expressions/OffsetWindowFunction/ class=md-nav__link> <span class=md-ellipsis> OffsetWindowFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ParseToDate/ class=md-nav__link> <span class=md-ellipsis> ParseToDate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ParseToTimestamp/ class=md-nav__link> <span class=md-ellipsis> ParseToTimestamp </span> </a> </li> <li class=md-nav__item> <a href=../expressions/PlanExpression/ class=md-nav__link> <span class=md-ellipsis> PlanExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Predicate/ class=md-nav__link> <span class=md-ellipsis> Predicate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Projection/ class=md-nav__link> <span class=md-ellipsis> Projection </span> </a> </li> <li class=md-nav__item> <a href=../expressions/RowOrdering/ class=md-nav__link> <span class=md-ellipsis> RowOrdering </span> </a> </li> <li class=md-nav__item> <a href=../expressions/RuntimeReplaceable/ class=md-nav__link> <span class=md-ellipsis> RuntimeReplaceable </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ScalaAggregator/ class=md-nav__link> <span class=md-ellipsis> ScalaAggregator </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ScalarSubquery/ class=md-nav__link> <span class=md-ellipsis> ScalarSubquery </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ExecSubqueryExpression-ScalarSubquery/ class=md-nav__link> <span class=md-ellipsis> ScalarSubquery (ExecSubqueryExpression) </span> </a> </li> <li class=md-nav__item> <a href=../expressions/ScalaUDF/ class=md-nav__link> <span class=md-ellipsis> ScalaUDF </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SortOrder/ class=md-nav__link> <span class=md-ellipsis> SortOrder </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SparkUserDefinedFunction/ class=md-nav__link> <span class=md-ellipsis> SparkUserDefinedFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Stateful/ class=md-nav__link> <span class=md-ellipsis> Stateful </span> </a> </li> <li class=md-nav__item> <a href=../expressions/StaticInvoke/ class=md-nav__link> <span class=md-ellipsis> StaticInvoke </span> </a> </li> <li class=md-nav__item> <a href=../expressions/SubqueryExpression/ class=md-nav__link> <span class=md-ellipsis> SubqueryExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/TimeWindow/ class=md-nav__link> <span class=md-ellipsis> TimeWindow </span> </a> </li> <li class=md-nav__item> <a href=../expressions/TypedImperativeAggregate/ class=md-nav__link> <span class=md-ellipsis> TypedImperativeAggregate </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnaryExpression/ class=md-nav__link> <span class=md-ellipsis> UnaryExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/Unevaluable/ class=md-nav__link> <span class=md-ellipsis> Unevaluable </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnixTimestamp/ class=md-nav__link> <span class=md-ellipsis> UnixTimestamp </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedAttribute/ class=md-nav__link> <span class=md-ellipsis> UnresolvedAttribute </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedFunction/ class=md-nav__link> <span class=md-ellipsis> UnresolvedFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedGenerator/ class=md-nav__link> <span class=md-ellipsis> UnresolvedGenerator </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedOrdinal/ class=md-nav__link> <span class=md-ellipsis> UnresolvedOrdinal </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnresolvedStar/ class=md-nav__link> <span class=md-ellipsis> UnresolvedStar </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UnsafeProjection/ class=md-nav__link> <span class=md-ellipsis> UnsafeProjection </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedAggregator/ class=md-nav__link> <span class=md-ellipsis> UserDefinedAggregator </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_19_84 type=checkbox id=__nav_2_19_84> <label class=md-nav__link for=__nav_2_19_84 tabindex=0 aria-expanded=false> <span class=md-ellipsis> User-Defined Functions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="User-Defined Functions" data-md-level=3> <label class=md-nav__title for=__nav_2_19_84> <span class="md-nav__icon md-icon"></span> User-Defined Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-udfs/ class=md-nav__link> <span class=md-ellipsis> User-Defined Functions </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedExpression/ class=md-nav__link> <span class=md-ellipsis> UserDefinedExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedFunction/ class=md-nav__link> <span class=md-ellipsis> UserDefinedFunction </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-udfs-blackbox/ class=md-nav__link> <span class=md-ellipsis> UDFs are Blackbox </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../expressions/UserDefinedAggregateFunction/ class=md-nav__link> <span class=md-ellipsis> UserDefinedAggregateFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/WindowExpression/ class=md-nav__link> <span class=md-ellipsis> WindowExpression </span> </a> </li> <li class=md-nav__item> <a href=../expressions/WindowFunction/ class=md-nav__link> <span class=md-ellipsis> WindowFunction </span> </a> </li> <li class=md-nav__item> <a href=../expressions/WindowSpecDefinition/ class=md-nav__link> <span class=md-ellipsis> WindowSpecDefinition </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_20 type=checkbox id=__nav_2_20> <div class="md-nav__link md-nav__container"> <a href=../physical-operators/ class="md-nav__link "> <span class=md-ellipsis> Physical Operators </span> </a> <label class="md-nav__link " for=__nav_2_20> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Physical Operators" data-md-level=2> <label class=md-nav__title for=__nav_2_20> <span class="md-nav__icon md-icon"></span> Physical Operators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/AdaptiveSparkPlanExec/ class=md-nav__link> <span class=md-ellipsis> AdaptiveSparkPlanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AggregateCodegenSupport/ class=md-nav__link> <span class=md-ellipsis> AggregateCodegenSupport </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_20_4 type=checkbox id=__nav_2_20_4> <label class=md-nav__link for=__nav_2_20_4 tabindex=0 aria-expanded=false> <span class=md-ellipsis> AggregationIterators </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=AggregationIterators data-md-level=3> <label class=md-nav__title for=__nav_2_20_4> <span class="md-nav__icon md-icon"></span> AggregationIterators </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/AggregationIterator/ class=md-nav__link> <span class=md-ellipsis> AggregationIterator </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectAggregationIterator/ class=md-nav__link> <span class=md-ellipsis> ObjectAggregationIterator </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectAggregationMap/ class=md-nav__link> <span class=md-ellipsis> ObjectAggregationMap </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SortBasedAggregationIterator/ class=md-nav__link> <span class=md-ellipsis> SortBasedAggregationIterator </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/TungstenAggregationIterator/ class=md-nav__link> <span class=md-ellipsis> TungstenAggregationIterator </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../physical-operators/AliasAwareOutputExpression/ class=md-nav__link> <span class=md-ellipsis> AliasAwareOutputExpression </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AliasAwareOutputOrdering/ class=md-nav__link> <span class=md-ellipsis> AliasAwareOutputOrdering </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AliasAwareOutputPartitioning/ class=md-nav__link> <span class=md-ellipsis> AliasAwareOutputPartitioning </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AlterTableExec/ class=md-nav__link> <span class=md-ellipsis> AlterTableExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AQEShuffleReadExec/ class=md-nav__link> <span class=md-ellipsis> AQEShuffleReadExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/AtomicTableWriteExec/ class=md-nav__link> <span class=md-ellipsis> AtomicTableWriteExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BaseAggregateExec/ class=md-nav__link> <span class=md-ellipsis> BaseAggregateExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BaseJoinExec/ class=md-nav__link> <span class=md-ellipsis> BaseJoinExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BaseSubqueryExec/ class=md-nav__link> <span class=md-ellipsis> BaseSubqueryExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BatchWriteHelper/ class=md-nav__link> <span class=md-ellipsis> BatchWriteHelper </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BatchScanExec/ class=md-nav__link> <span class=md-ellipsis> BatchScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastExchangeExec/ class=md-nav__link> <span class=md-ellipsis> BroadcastExchangeExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastExchangeLike/ class=md-nav__link> <span class=md-ellipsis> BroadcastExchangeLike </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastHashJoinExec/ class=md-nav__link> <span class=md-ellipsis> BroadcastHashJoinExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastNestedLoopJoinExec/ class=md-nav__link> <span class=md-ellipsis> BroadcastNestedLoopJoinExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastQueryStageExec/ class=md-nav__link> <span class=md-ellipsis> BroadcastQueryStageExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CoalesceExec/ class=md-nav__link> <span class=md-ellipsis> CoalesceExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CollectLimitExec/ class=md-nav__link> <span class=md-ellipsis> CollectLimitExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CollectMetricsExec/ class=md-nav__link> <span class=md-ellipsis> CollectMetricsExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ColumnarToRowExec/ class=md-nav__link> <span class=md-ellipsis> ColumnarToRowExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ColumnarToRowTransition/ class=md-nav__link> <span class=md-ellipsis> ColumnarToRowTransition </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CreateTableAsSelectExec/ class=md-nav__link> <span class=md-ellipsis> CreateTableAsSelectExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/CodegenSupport/ class=md-nav__link> <span class=md-ellipsis> CodegenSupport </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ColumnarBatchScan/ class=md-nav__link> <span class=md-ellipsis> ColumnarBatchScan </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DataSourceScanExec/ class=md-nav__link> <span class=md-ellipsis> DataSourceScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DataSourceV2ScanExec/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2ScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DataSourceV2ScanExecBase/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2ScanExecBase </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DataWritingCommandExec/ class=md-nav__link> <span class=md-ellipsis> DataWritingCommandExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DebugExec/ class=md-nav__link> <span class=md-ellipsis> DebugExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DeleteFromTableExec/ class=md-nav__link> <span class=md-ellipsis> DeleteFromTableExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DescribeTableExec/ class=md-nav__link> <span class=md-ellipsis> DescribeTableExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DeserializeToObjectExec/ class=md-nav__link> <span class=md-ellipsis> DeserializeToObjectExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/DropNamespaceExec/ class=md-nav__link> <span class=md-ellipsis> DropNamespaceExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/EvalPythonExec/ class=md-nav__link> <span class=md-ellipsis> EvalPythonExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/Exchange/ class=md-nav__link> <span class=md-ellipsis> Exchange </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ExecutedCommandExec/ class=md-nav__link> <span class=md-ellipsis> ExecutedCommandExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ExternalRDDScanExec/ class=md-nav__link> <span class=md-ellipsis> ExternalRDDScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/FileSourceScanExec/ class=md-nav__link> <span class=md-ellipsis> FileSourceScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/FilterExec/ class=md-nav__link> <span class=md-ellipsis> FilterExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/GenerateExec/ class=md-nav__link> <span class=md-ellipsis> GenerateExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashAggregateExec/ class=md-nav__link> <span class=md-ellipsis> HashAggregateExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashedRelation/ class=md-nav__link> <span class=md-ellipsis> HashedRelation </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashJoin/ class=md-nav__link> <span class=md-ellipsis> HashJoin </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/InMemoryTableScanExec/ class=md-nav__link> <span class=md-ellipsis> InMemoryTableScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/InputAdapter/ class=md-nav__link> <span class=md-ellipsis> InputAdapter </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/JoinCodegenSupport/ class=md-nav__link> <span class=md-ellipsis> JoinCodegenSupport </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/LocalTableScanExec/ class=md-nav__link> <span class=md-ellipsis> LocalTableScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/LongHashedRelation/ class=md-nav__link> <span class=md-ellipsis> LongHashedRelation </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectConsumerExec/ class=md-nav__link> <span class=md-ellipsis> ObjectConsumerExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectHashAggregateExec/ class=md-nav__link> <span class=md-ellipsis> ObjectHashAggregateExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ObjectProducerExec/ class=md-nav__link> <span class=md-ellipsis> ObjectProducerExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/OverwriteByExpressionExec/ class=md-nav__link> <span class=md-ellipsis> OverwriteByExpressionExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ProjectExec/ class=md-nav__link> <span class=md-ellipsis> ProjectExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/QueryStageExec/ class=md-nav__link> <span class=md-ellipsis> QueryStageExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/RangeExec/ class=md-nav__link> <span class=md-ellipsis> RangeExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ReusedExchangeExec/ class=md-nav__link> <span class=md-ellipsis> ReusedExchangeExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ReusedSubqueryExec/ class=md-nav__link> <span class=md-ellipsis> ReusedSubqueryExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/RowDataSourceScanExec/ class=md-nav__link> <span class=md-ellipsis> RowDataSourceScanExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SerializeFromObjectExec/ class=md-nav__link> <span class=md-ellipsis> SerializeFromObjectExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SetCatalogAndNamespaceExec/ class=md-nav__link> <span class=md-ellipsis> SetCatalogAndNamespaceExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShowTablesExec/ class=md-nav__link> <span class=md-ellipsis> ShowTablesExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShowTablePropertiesExec/ class=md-nav__link> <span class=md-ellipsis> ShowTablePropertiesExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleExchangeExec/ class=md-nav__link> <span class=md-ellipsis> ShuffleExchangeExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleExchangeLike/ class=md-nav__link> <span class=md-ellipsis> ShuffleExchangeLike </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffledHashJoinExec/ class=md-nav__link> <span class=md-ellipsis> ShuffledHashJoinExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffledJoin/ class=md-nav__link> <span class=md-ellipsis> ShuffledJoin </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleOrigin/ class=md-nav__link> <span class=md-ellipsis> ShuffleOrigin </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ShuffleQueryStageExec/ class=md-nav__link> <span class=md-ellipsis> ShuffleQueryStageExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SortAggregateExec/ class=md-nav__link> <span class=md-ellipsis> SortAggregateExec </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_20_74 type=checkbox id=__nav_2_20_74> <label class=md-nav__link for=__nav_2_20_74 tabindex=0 aria-expanded=false> <span class=md-ellipsis> SortMergeJoinExec </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=SortMergeJoinExec data-md-level=3> <label class=md-nav__title for=__nav_2_20_74> <span class="md-nav__icon md-icon"></span> SortMergeJoinExec </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/SortMergeJoinExec/ class=md-nav__link> <span class=md-ellipsis> SortMergeJoinExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SortMergeJoinScanner/ class=md-nav__link> <span class=md-ellipsis> SortMergeJoinScanner </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../physical-operators/SortExec/ class=md-nav__link> <span class=md-ellipsis> SortExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SparkPlan/ class=md-nav__link> <span class=md-ellipsis> SparkPlan </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/SubqueryExec/ class=md-nav__link> <span class=md-ellipsis> SubqueryExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/TableWriteExecHelper/ class=md-nav__link> <span class=md-ellipsis> TableWriteExecHelper </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/UnaryExecNode/ class=md-nav__link> <span class=md-ellipsis> UnaryExecNode </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/V2CommandExec/ class=md-nav__link> <span class=md-ellipsis> V2CommandExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/V2ExistingTableWriteExec/ class=md-nav__link> <span class=md-ellipsis> V2ExistingTableWriteExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/V2TableWriteExec/ class=md-nav__link> <span class=md-ellipsis> V2TableWriteExec </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/WholeStageCodegenExec/ class=md-nav__link> <span class=md-ellipsis> WholeStageCodegenExec </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_20_84 type=checkbox id=__nav_2_20_84> <label class=md-nav__link for=__nav_2_20_84 tabindex=0 aria-expanded=false> <span class=md-ellipsis> WindowExec </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=WindowExec data-md-level=3> <label class=md-nav__title for=__nav_2_20_84> <span class="md-nav__icon md-icon"></span> WindowExec </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/WindowExec/ class=md-nav__link> <span class=md-ellipsis> WindowExec </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../physical-operators/WindowExecBase/ class=md-nav__link> <span class=md-ellipsis> WindowExecBase </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_20_86 type=checkbox id=__nav_2_20_86> <label class=md-nav__link for=__nav_2_20_86 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Distribution and Partitioning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Distribution and Partitioning" data-md-level=3> <label class=md-nav__title for=__nav_2_20_86> <span class="md-nav__icon md-icon"></span> Distribution and Partitioning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/Distribution/ class=md-nav__link> <span class=md-ellipsis> Distribution </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/Partitioning/ class=md-nav__link> <span class=md-ellipsis> Partitioning </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_20_86_3 type=checkbox id=__nav_2_20_86_3> <label class=md-nav__link for=__nav_2_20_86_3 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Distribution Specifications </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Distribution Specifications" data-md-level=4> <label class=md-nav__title for=__nav_2_20_86_3> <span class="md-nav__icon md-icon"></span> Distribution Specifications </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/AllTuples/ class=md-nav__link> <span class=md-ellipsis> AllTuples </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/BroadcastDistribution/ class=md-nav__link> <span class=md-ellipsis> BroadcastDistribution </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/ClusteredDistribution/ class=md-nav__link> <span class=md-ellipsis> ClusteredDistribution </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashClusteredDistribution/ class=md-nav__link> <span class=md-ellipsis> HashClusteredDistribution </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/OrderedDistribution/ class=md-nav__link> <span class=md-ellipsis> OrderedDistribution </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/UnspecifiedDistribution/ class=md-nav__link> <span class=md-ellipsis> UnspecifiedDistribution </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_20_86_4 type=checkbox id=__nav_2_20_86_4> <label class=md-nav__link for=__nav_2_20_86_4 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Broadcast Modes </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Broadcast Modes" data-md-level=4> <label class=md-nav__title for=__nav_2_20_86_4> <span class="md-nav__icon md-icon"></span> Broadcast Modes </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-operators/BroadcastMode/ class=md-nav__link> <span class=md-ellipsis> BroadcastMode </span> </a> </li> <li class=md-nav__item> <a href=../physical-operators/HashedRelationBroadcastMode/ class=md-nav__link> <span class=md-ellipsis> HashedRelationBroadcastMode </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_21 type=checkbox id=__nav_2_21> <label class=md-nav__link for=__nav_2_21 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Logical Analysis Rules </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Logical Analysis Rules" data-md-level=2> <label class=md-nav__title for=__nav_2_21> <span class="md-nav__icon md-icon"></span> Logical Analysis Rules </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logical-analysis-rules/AddMetadataColumns/ class=md-nav__link> <span class=md-ellipsis> AddMetadataColumns </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/AliasViewChild/ class=md-nav__link> <span class=md-ellipsis> AliasViewChild </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/CleanupAliases/ class=md-nav__link> <span class=md-ellipsis> CleanupAliases </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/CTESubstitution/ class=md-nav__link> <span class=md-ellipsis> CTESubstitution </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/DataSourceAnalysis/ class=md-nav__link> <span class=md-ellipsis> DataSourceAnalysis </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ExtractWindowExpressions/ class=md-nav__link> <span class=md-ellipsis> ExtractWindowExpressions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/FindDataSourceTable/ class=md-nav__link> <span class=md-ellipsis> FindDataSourceTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/HandleNullInputsForUDF/ class=md-nav__link> <span class=md-ellipsis> HandleNullInputsForUDF </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/LookupFunctions/ class=md-nav__link> <span class=md-ellipsis> LookupFunctions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/PreprocessTableCreation/ class=md-nav__link> <span class=md-ellipsis> PreprocessTableCreation </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/PreWriteCheck/ class=md-nav__link> <span class=md-ellipsis> PreWriteCheck </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/RemoveAllHints/ class=md-nav__link> <span class=md-ellipsis> RemoveAllHints </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveAggregateFunctions/ class=md-nav__link> <span class=md-ellipsis> ResolveAggregateFunctions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveAliases/ class=md-nav__link> <span class=md-ellipsis> ResolveAliases </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveCatalogs/ class=md-nav__link> <span class=md-ellipsis> ResolveCatalogs </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveCoalesceHints/ class=md-nav__link> <span class=md-ellipsis> ResolveCoalesceHints </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveCreateNamedStruct/ class=md-nav__link> <span class=md-ellipsis> ResolveCreateNamedStruct </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveFunctions/ class=md-nav__link> <span class=md-ellipsis> ResolveFunctions </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveGroupingAnalytics/ class=md-nav__link> <span class=md-ellipsis> ResolveGroupingAnalytics </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveInlineTables/ class=md-nav__link> <span class=md-ellipsis> ResolveInlineTables </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveInsertInto/ class=md-nav__link> <span class=md-ellipsis> ResolveInsertInto </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveJoinStrategyHints/ class=md-nav__link> <span class=md-ellipsis> ResolveJoinStrategyHints </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveMissingReferences/ class=md-nav__link> <span class=md-ellipsis> ResolveMissingReferences </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveOrdinalInOrderByAndGroupBy/ class=md-nav__link> <span class=md-ellipsis> ResolveOrdinalInOrderByAndGroupBy </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveOutputRelation/ class=md-nav__link> <span class=md-ellipsis> ResolveOutputRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveReferences/ class=md-nav__link> <span class=md-ellipsis> ResolveReferences </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveRelations/ class=md-nav__link> <span class=md-ellipsis> ResolveRelations </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveSessionCatalog/ class=md-nav__link> <span class=md-ellipsis> ResolveSessionCatalog </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveSQLOnFile/ class=md-nav__link> <span class=md-ellipsis> ResolveSQLOnFile </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveSubquery/ class=md-nav__link> <span class=md-ellipsis> ResolveSubquery </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveTables/ class=md-nav__link> <span class=md-ellipsis> ResolveTables </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveTempViews/ class=md-nav__link> <span class=md-ellipsis> ResolveTempViews </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveTimeZone/ class=md-nav__link> <span class=md-ellipsis> ResolveTimeZone </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveWindowFrame/ class=md-nav__link> <span class=md-ellipsis> ResolveWindowFrame </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveWindowOrder/ class=md-nav__link> <span class=md-ellipsis> ResolveWindowOrder </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/ResolveWithCTE/ class=md-nav__link> <span class=md-ellipsis> ResolveWithCTE </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/RewriteDeleteFromTable/ class=md-nav__link> <span class=md-ellipsis> RewriteDeleteFromTable </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/RewriteRowLevelCommand/ class=md-nav__link> <span class=md-ellipsis> RewriteRowLevelCommand </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/TableCapabilityCheck/ class=md-nav__link> <span class=md-ellipsis> TableCapabilityCheck </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/UpdateOuterReferences/ class=md-nav__link> <span class=md-ellipsis> UpdateOuterReferences </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/WindowFrameCoercion/ class=md-nav__link> <span class=md-ellipsis> WindowFrameCoercion </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/WidenSetOperationTypes/ class=md-nav__link> <span class=md-ellipsis> WidenSetOperationTypes </span> </a> </li> <li class=md-nav__item> <a href=../logical-analysis-rules/WindowsSubstitution/ class=md-nav__link> <span class=md-ellipsis> WindowsSubstitution </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_22 type=checkbox id=__nav_2_22> <label class=md-nav__link for=__nav_2_22 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Logical Optimizations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Logical Optimizations" data-md-level=2> <label class=md-nav__title for=__nav_2_22> <span class="md-nav__icon md-icon"></span> Logical Optimizations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../logical-optimizations/AQEPropagateEmptyRelation/ class=md-nav__link> <span class=md-ellipsis> AQEPropagateEmptyRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CleanupDynamicPruningFilters/ class=md-nav__link> <span class=md-ellipsis> CleanupDynamicPruningFilters </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CollapseWindow/ class=md-nav__link> <span class=md-ellipsis> CollapseWindow </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ColumnPruning/ class=md-nav__link> <span class=md-ellipsis> ColumnPruning </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CombineTypedFilters/ class=md-nav__link> <span class=md-ellipsis> CombineTypedFilters </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CombineUnions/ class=md-nav__link> <span class=md-ellipsis> CombineUnions </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ComputeCurrentTime/ class=md-nav__link> <span class=md-ellipsis> ComputeCurrentTime </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ConstantFolding/ class=md-nav__link> <span class=md-ellipsis> ConstantFolding </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ConvertToLocalRelation/ class=md-nav__link> <span class=md-ellipsis> ConvertToLocalRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/CostBasedJoinReorder/ class=md-nav__link> <span class=md-ellipsis> CostBasedJoinReorder </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/DecimalAggregates/ class=md-nav__link> <span class=md-ellipsis> DecimalAggregates </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/DynamicJoinSelection/ class=md-nav__link> <span class=md-ellipsis> DynamicJoinSelection </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateResolvedHint/ class=md-nav__link> <span class=md-ellipsis> EliminateResolvedHint </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateSerialization/ class=md-nav__link> <span class=md-ellipsis> EliminateSerialization </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateSubqueryAliases/ class=md-nav__link> <span class=md-ellipsis> EliminateSubqueryAliases </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/EliminateView/ class=md-nav__link> <span class=md-ellipsis> EliminateView </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ExtractPythonUDFFromAggregate/ class=md-nav__link> <span class=md-ellipsis> ExtractPythonUDFFromAggregate </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/GetCurrentDatabase/ class=md-nav__link> <span class=md-ellipsis> GetCurrentDatabase </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/GroupBasedRowLevelOperationScanPlanning/ class=md-nav__link> <span class=md-ellipsis> GroupBasedRowLevelOperationScanPlanning </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/InferFiltersFromConstraints/ class=md-nav__link> <span class=md-ellipsis> InferFiltersFromConstraints </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/InjectRuntimeFilter/ class=md-nav__link> <span class=md-ellipsis> InjectRuntimeFilter </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/InlineCTE/ class=md-nav__link> <span class=md-ellipsis> InlineCTE </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/LimitPushDown/ class=md-nav__link> <span class=md-ellipsis> LimitPushDown </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/NullPropagation/ class=md-nav__link> <span class=md-ellipsis> NullPropagation </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/OptimizeIn/ class=md-nav__link> <span class=md-ellipsis> OptimizeIn </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/OptimizeMetadataOnlyQuery/ class=md-nav__link> <span class=md-ellipsis> OptimizeMetadataOnlyQuery </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/OptimizeSubqueries/ class=md-nav__link> <span class=md-ellipsis> OptimizeSubqueries </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PartitionPruning/ class=md-nav__link> <span class=md-ellipsis> PartitionPruning </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PropagateEmptyRelation/ class=md-nav__link> <span class=md-ellipsis> PropagateEmptyRelation </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PruneFileSourcePartitions/ class=md-nav__link> <span class=md-ellipsis> PruneFileSourcePartitions </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PruneFilters/ class=md-nav__link> <span class=md-ellipsis> PruneFilters </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PullupCorrelatedPredicates/ class=md-nav__link> <span class=md-ellipsis> PullupCorrelatedPredicates </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushDownOperatorsToDataSource/ class=md-nav__link> <span class=md-ellipsis> PushDownOperatorsToDataSource </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushDownPredicate/ class=md-nav__link> <span class=md-ellipsis> PushDownPredicate </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushDownPredicates/ class=md-nav__link> <span class=md-ellipsis> PushDownPredicates </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/PushPredicateThroughJoin/ class=md-nav__link> <span class=md-ellipsis> PushPredicateThroughJoin </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReorderJoin/ class=md-nav__link> <span class=md-ellipsis> ReorderJoin </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReplaceExpressions/ class=md-nav__link> <span class=md-ellipsis> ReplaceExpressions </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReplaceExceptWithAntiJoin/ class=md-nav__link> <span class=md-ellipsis> ReplaceExceptWithAntiJoin </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/ReplaceExceptWithFilter/ class=md-nav__link> <span class=md-ellipsis> ReplaceExceptWithFilter </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/RewriteCorrelatedScalarSubquery/ class=md-nav__link> <span class=md-ellipsis> RewriteCorrelatedScalarSubquery </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/RewriteExceptAll/ class=md-nav__link> <span class=md-ellipsis> RewriteExceptAll </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/RewritePredicateSubquery/ class=md-nav__link> <span class=md-ellipsis> RewritePredicateSubquery </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/SchemaPruning/ class=md-nav__link> <span class=md-ellipsis> SchemaPruning </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/SimplifyCasts/ class=md-nav__link> <span class=md-ellipsis> SimplifyCasts </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/UpdateCTERelationStats/ class=md-nav__link> <span class=md-ellipsis> UpdateCTERelationStats </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/UpdateAttributeNullability/ class=md-nav__link> <span class=md-ellipsis> UpdateAttributeNullability </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/V2ScanRelationPushDown/ class=md-nav__link> <span class=md-ellipsis> V2ScanRelationPushDown </span> </a> </li> <li class=md-nav__item> <a href=../logical-optimizations/V2Writes/ class=md-nav__link> <span class=md-ellipsis> V2Writes </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_23 type=checkbox id=__nav_2_23> <label class=md-nav__link for=__nav_2_23 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Execution Planning Strategies </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Execution Planning Strategies" data-md-level=2> <label class=md-nav__title for=__nav_2_23> <span class="md-nav__icon md-icon"></span> Execution Planning Strategies </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../execution-planning-strategies/SparkStrategy/ class=md-nav__link> <span class=md-ellipsis> SparkStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/Aggregation/ class=md-nav__link> <span class=md-ellipsis> Aggregation </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/BasicOperators/ class=md-nav__link> <span class=md-ellipsis> BasicOperators </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/DataSourceStrategy/ class=md-nav__link> <span class=md-ellipsis> DataSourceStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/DataSourceV2Strategy/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2Strategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/FileSourceStrategy/ class=md-nav__link> <span class=md-ellipsis> FileSourceStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/InMemoryScans/ class=md-nav__link> <span class=md-ellipsis> InMemoryScans </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/JoinSelection/ class=md-nav__link> <span class=md-ellipsis> JoinSelection </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/LogicalQueryStageStrategy/ class=md-nav__link> <span class=md-ellipsis> LogicalQueryStageStrategy </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/SpecialLimits/ class=md-nav__link> <span class=md-ellipsis> SpecialLimits </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/SparkStrategies/ class=md-nav__link> <span class=md-ellipsis> SparkStrategies </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/Window/ class=md-nav__link> <span class=md-ellipsis> Window </span> </a> </li> <li class=md-nav__item> <a href=../execution-planning-strategies/WithCTEStrategy/ class=md-nav__link> <span class=md-ellipsis> WithCTEStrategy </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_24 type=checkbox id=__nav_2_24> <label class=md-nav__link for=__nav_2_24 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Physical Optimizations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Physical Optimizations" data-md-level=2> <label class=md-nav__title for=__nav_2_24> <span class="md-nav__icon md-icon"></span> Physical Optimizations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../physical-optimizations/ApplyColumnarRulesAndInsertTransitions/ class=md-nav__link> <span class=md-ellipsis> ApplyColumnarRulesAndInsertTransitions </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/AQEShuffleReadRule/ class=md-nav__link> <span class=md-ellipsis> AQEShuffleReadRule </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/CoalesceBucketsInJoin/ class=md-nav__link> <span class=md-ellipsis> CoalesceBucketsInJoin </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/CoalesceShufflePartitions/ class=md-nav__link> <span class=md-ellipsis> CoalesceShufflePartitions </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/CollapseCodegenStages/ class=md-nav__link> <span class=md-ellipsis> CollapseCodegenStages </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/DisableUnnecessaryBucketedScan/ class=md-nav__link> <span class=md-ellipsis> DisableUnnecessaryBucketedScan </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/EnsureRequirements/ class=md-nav__link> <span class=md-ellipsis> EnsureRequirements </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ExtractPythonUDFs/ class=md-nav__link> <span class=md-ellipsis> ExtractPythonUDFs </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/InsertAdaptiveSparkPlan/ class=md-nav__link> <span class=md-ellipsis> InsertAdaptiveSparkPlan </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/OptimizeShuffleWithLocalRead/ class=md-nav__link> <span class=md-ellipsis> OptimizeShuffleWithLocalRead </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/OptimizeSkewedJoin/ class=md-nav__link> <span class=md-ellipsis> OptimizeSkewedJoin </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/OptimizeSkewInRebalancePartitions/ class=md-nav__link> <span class=md-ellipsis> OptimizeSkewInRebalancePartitions </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanAdaptiveDynamicPruningFilters/ class=md-nav__link> <span class=md-ellipsis> PlanAdaptiveDynamicPruningFilters </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanAdaptiveSubqueries/ class=md-nav__link> <span class=md-ellipsis> PlanAdaptiveSubqueries </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanDynamicPruningFilters/ class=md-nav__link> <span class=md-ellipsis> PlanDynamicPruningFilters </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/PlanSubqueries/ class=md-nav__link> <span class=md-ellipsis> PlanSubqueries </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/RemoveRedundantProjects/ class=md-nav__link> <span class=md-ellipsis> RemoveRedundantProjects </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/RemoveRedundantSorts/ class=md-nav__link> <span class=md-ellipsis> RemoveRedundantSorts </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseAdaptiveSubquery/ class=md-nav__link> <span class=md-ellipsis> ReuseAdaptiveSubquery </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseExchange/ class=md-nav__link> <span class=md-ellipsis> ReuseExchange </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseExchangeAndSubquery/ class=md-nav__link> <span class=md-ellipsis> ReuseExchangeAndSubquery </span> </a> </li> <li class=md-nav__item> <a href=../physical-optimizations/ReuseSubquery/ class=md-nav__link> <span class=md-ellipsis> ReuseSubquery </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../SQLExecution/ class=md-nav__link> <span class=md-ellipsis> SQLExecution </span> </a> </li> <li class=md-nav__item> <a href=../SQLMetric/ class=md-nav__link> <span class=md-ellipsis> SQLMetric </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_2_27 type=checkbox id=__nav_2_27> <div class="md-nav__link md-nav__container"> <a href=../tungsten/ class="md-nav__link "> <span class=md-ellipsis> Tungsten Execution Backend </span> </a> <label class="md-nav__link " for=__nav_2_27> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Tungsten Execution Backend" data-md-level=2> <label class=md-nav__title for=__nav_2_27> <span class="md-nav__icon md-icon"></span> Tungsten Execution Backend </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../CatalystSerde/ class=md-nav__link> <span class=md-ellipsis> CatalystSerde </span> </a> </li> <li class=md-nav__item> <a href=../ExternalAppendOnlyUnsafeRowArray/ class=md-nav__link> <span class=md-ellipsis> ExternalAppendOnlyUnsafeRowArray </span> </a> </li> <li class=md-nav__item> <a href=../HashMapGenerator/ class=md-nav__link> <span class=md-ellipsis> HashMapGenerator </span> </a> </li> <li class=md-nav__item> <a href=../InternalRow/ class=md-nav__link> <span class=md-ellipsis> InternalRow </span> </a> </li> <li class=md-nav__item> <a href=../UnsafeFixedWidthAggregationMap/ class=md-nav__link> <span class=md-ellipsis> UnsafeFixedWidthAggregationMap </span> </a> </li> <li class=md-nav__item> <a href=../UnsafeHashedRelation/ class=md-nav__link> <span class=md-ellipsis> UnsafeHashedRelation </span> </a> </li> <li class=md-nav__item> <a href=../UnsafeRow/ class=md-nav__link> <span class=md-ellipsis> UnsafeRow </span> </a> </li> <li class=md-nav__item> <a href=../tungsten/UnsafeRowSerializerInstance/ class=md-nav__link> <span class=md-ellipsis> UnsafeRowSerializerInstance </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_3 type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../sql/ class="md-nav__link "> <span class=md-ellipsis> SQL </span> </a> <label class="md-nav__link " for=__nav_3> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=SQL data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> SQL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../sql/AbstractSqlParser/ class=md-nav__link> <span class=md-ellipsis> AbstractSqlParser </span> </a> </li> <li class=md-nav__item> <a href=../sql/AstBuilder/ class=md-nav__link> <span class=md-ellipsis> AstBuilder </span> </a> </li> <li class=md-nav__item> <a href=../sql/CatalystSqlParser/ class=md-nav__link> <span class=md-ellipsis> CatalystSqlParser </span> </a> </li> <li class=md-nav__item> <a href=../sql/ParserInterface/ class=md-nav__link> <span class=md-ellipsis> ParserInterface </span> </a> </li> <li class=md-nav__item> <a href=../sql/SparkSqlParser/ class=md-nav__link> <span class=md-ellipsis> SparkSqlParser </span> </a> </li> <li class=md-nav__item> <a href=../sql/SparkSqlAstBuilder/ class=md-nav__link> <span class=md-ellipsis> SparkSqlAstBuilder </span> </a> </li> <li class=md-nav__item> <a href=../sql/VariableSubstitution/ class=md-nav__link> <span class=md-ellipsis> VariableSubstitution </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4 type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Features data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_1 type=checkbox id=__nav_4_1> <div class="md-nav__link md-nav__container"> <a href=../adaptive-query-execution/ class="md-nav__link "> <span class=md-ellipsis> Adaptive Query Execution </span> </a> <label class="md-nav__link " for=__nav_4_1> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Adaptive Query Execution" data-md-level=2> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Adaptive Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../adaptive-query-execution/AdaptiveExecutionContext/ class=md-nav__link> <span class=md-ellipsis> AdaptiveExecutionContext </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/AQEOptimizer/ class=md-nav__link> <span class=md-ellipsis> AQEOptimizer </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/AQEUtils/ class=md-nav__link> <span class=md-ellipsis> AQEUtils </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/CostEvaluator/ class=md-nav__link> <span class=md-ellipsis> CostEvaluator </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/ShufflePartitionsUtil/ class=md-nav__link> <span class=md-ellipsis> ShufflePartitionsUtil </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/SimpleCostEvaluator/ class=md-nav__link> <span class=md-ellipsis> SimpleCostEvaluator </span> </a> </li> <li class=md-nav__item> <a href=../adaptive-query-execution/demo/ class=md-nav__link> <span class=md-ellipsis> Demo </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../bucketing/ class=md-nav__link> <span class=md-ellipsis> Bucketing </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_3 type=checkbox id=__nav_4_3> <div class="md-nav__link md-nav__container"> <a href=../connector/catalog/ class="md-nav__link "> <span class=md-ellipsis> Catalog Plugin API </span> </a> <label class="md-nav__link " for=__nav_4_3> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Catalog Plugin API" data-md-level=2> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> Catalog Plugin API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../connector/catalog/CatalogExtension/ class=md-nav__link> <span class=md-ellipsis> CatalogExtension </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogHelper/ class=md-nav__link> <span class=md-ellipsis> CatalogHelper </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogManager/ class=md-nav__link> <span class=md-ellipsis> CatalogManager </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogPlugin/ class=md-nav__link> <span class=md-ellipsis> CatalogPlugin </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/Catalogs/ class=md-nav__link> <span class=md-ellipsis> Catalogs </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/CatalogV2Util/ class=md-nav__link> <span class=md-ellipsis> CatalogV2Util </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/DelegatingCatalogExtension/ class=md-nav__link> <span class=md-ellipsis> DelegatingCatalogExtension </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/FunctionCatalog/ class=md-nav__link> <span class=md-ellipsis> FunctionCatalog </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/StagingTableCatalog/ class=md-nav__link> <span class=md-ellipsis> StagingTableCatalog </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/SupportsNamespaces/ class=md-nav__link> <span class=md-ellipsis> SupportsNamespaces </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/SupportsCatalogOptions/ class=md-nav__link> <span class=md-ellipsis> SupportsCatalogOptions </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/TableCatalog/ class=md-nav__link> <span class=md-ellipsis> TableCatalog </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/TableChange/ class=md-nav__link> <span class=md-ellipsis> TableChange </span> </a> </li> <li class=md-nav__item> <a href=../connector/catalog/V2TableWithV1Fallback/ class=md-nav__link> <span class=md-ellipsis> V2TableWithV1Fallback </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../common-table-expressions/ class=md-nav__link> <span class=md-ellipsis> Common Table Expressions </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_5 type=checkbox id=__nav_4_5> <div class="md-nav__link md-nav__container"> <a href=../cost-based-optimization/ class="md-nav__link "> <span class=md-ellipsis> Cost-Based Optimization </span> </a> <label class="md-nav__link " for=__nav_4_5> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Cost-Based Optimization" data-md-level=2> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Cost-Based Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../cost-based-optimization/CatalogColumnStat/ class=md-nav__link> <span class=md-ellipsis> CatalogColumnStat </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/ColumnStat/ class=md-nav__link> <span class=md-ellipsis> ColumnStat </span> </a> </li> <li class=md-nav__item> <a href=../CommandUtils/ class=md-nav__link> <span class=md-ellipsis> CommandUtils </span> </a> </li> <li class=md-nav__item> <a href=../cost-based-optimization/EstimationUtils/ class=md-nav__link> <span class=md-ellipsis> EstimationUtils </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_6 type=checkbox id=__nav_4_6> <label class=md-nav__link for=__nav_4_6 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Join Queries </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Join Queries" data-md-level=2> <label class=md-nav__title for=__nav_4_6> <span class="md-nav__icon md-icon"></span> Join Queries </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../joins/ class=md-nav__link> <span class=md-ellipsis> Joins </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-joins-broadcast/ class=md-nav__link> <span class=md-ellipsis> Broadcast Joins </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/statistics/ class=md-nav__link> <span class=md-ellipsis> Statistics </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/metadata-columns/ class=md-nav__link> <span class=md-ellipsis> Metadata Columns </span> </a> </li> <li class=md-nav__item> <a href=../multi-dimensional-aggregation/ class=md-nav__link> <span class=md-ellipsis> Multi-Dimensional Aggregation </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/intervals/ class=md-nav__link> <span class=md-ellipsis> ANSI Intervals </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/catalog-plugin-api-and-multi-catalog-support/ class=md-nav__link> <span class=md-ellipsis> Catalog Plugin API and Multi-Catalog Support </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/dynamic-partition-pruning/ class=md-nav__link> <span class=md-ellipsis> Dynamic Partition Pruning </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/explain-command-improved/ class=md-nav__link> <span class=md-ellipsis> Explaining Query Plans Improved </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_14 type=checkbox id=__nav_4_14> <label class=md-nav__link for=__nav_4_14 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Hints </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Hints data-md-level=2> <label class=md-nav__title for=__nav_4_14> <span class="md-nav__icon md-icon"></span> Hints </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../new-and-noteworthy/hint-framework/ class=md-nav__link> <span class=md-ellipsis> Hint Framework </span> </a> </li> <li class=md-nav__item> <a href=../JoinHint/ class=md-nav__link> <span class=md-ellipsis> JoinHint </span> </a> </li> <li class=md-nav__item> <a href=../HintInfo/ class=md-nav__link> <span class=md-ellipsis> HintInfo </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/join-strategy-hints/ class=md-nav__link> <span class=md-ellipsis> Join Strategy Hints </span> </a> </li> <li class=md-nav__item> <a href=../HintErrorHandler/ class=md-nav__link> <span class=md-ellipsis> HintErrorHandler </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/observable-metrics/ class=md-nav__link> <span class=md-ellipsis> Observable Metrics </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/columnar-processing/ class=md-nav__link> <span class=md-ellipsis> Columnar Processing </span> </a> </li> <li class=md-nav__item> <a href=../new-and-noteworthy/datasource-v2/ class=md-nav__link> <span class=md-ellipsis> DataSource V2 </span> </a> </li> <li class=md-nav__item> <a href=../hive-integration/ class=md-nav__link> <span class=md-ellipsis> Hive Integration </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_19 type=checkbox id=__nav_4_19> <label class=md-nav__link for=__nav_4_19 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Vectorized Parquet Decoding </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Vectorized Parquet Decoding" data-md-level=2> <label class=md-nav__title for=__nav_4_19> <span class="md-nav__icon md-icon"></span> Vectorized Parquet Decoding </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../vectorized-parquet-reader/ class=md-nav__link> <span class=md-ellipsis> Vectorized Parquet Decoding </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_19_2 type=checkbox id=__nav_4_19_2> <label class=md-nav__link for=__nav_4_19_2 tabindex=0 aria-expanded=false> <span class=md-ellipsis> ColumnVectors </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=ColumnVectors data-md-level=3> <label class=md-nav__title for=__nav_4_19_2> <span class="md-nav__icon md-icon"></span> ColumnVectors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ColumnVector/ class=md-nav__link> <span class=md-ellipsis> ColumnVector </span> </a> </li> <li class=md-nav__item> <a href=../WritableColumnVector/ class=md-nav__link> <span class=md-ellipsis> WritableColumnVector </span> </a> </li> <li class=md-nav__item> <a href=../OnHeapColumnVector/ class=md-nav__link> <span class=md-ellipsis> OnHeapColumnVector </span> </a> </li> <li class=md-nav__item> <a href=../OffHeapColumnVector/ class=md-nav__link> <span class=md-ellipsis> OffHeapColumnVector </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../dynamic-partition-inserts/ class=md-nav__link> <span class=md-ellipsis> Dynamic Partition Inserts </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_21 type=checkbox id=__nav_4_21> <div class="md-nav__link md-nav__container"> <a href=../whole-stage-code-generation/ class="md-nav__link "> <span class=md-ellipsis> Whole-Stage CodeGen </span> </a> <label class="md-nav__link " for=__nav_4_21> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Whole-Stage CodeGen" data-md-level=2> <label class=md-nav__title for=__nav_4_21> <span class="md-nav__icon md-icon"></span> Whole-Stage CodeGen </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../whole-stage-code-generation/BufferedRowIterator/ class=md-nav__link> <span class=md-ellipsis> BufferedRowIterator </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/CodegenContext/ class=md-nav__link> <span class=md-ellipsis> CodegenContext </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/CodeGenerator/ class=md-nav__link> <span class=md-ellipsis> CodeGenerator </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/Block/ class=md-nav__link> <span class=md-ellipsis> Block </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateUnsafeProjection/ class=md-nav__link> <span class=md-ellipsis> GenerateUnsafeProjection </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateMutableProjection/ class=md-nav__link> <span class=md-ellipsis> GenerateMutableProjection </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateColumnAccessor/ class=md-nav__link> <span class=md-ellipsis> GenerateColumnAccessor </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateOrdering/ class=md-nav__link> <span class=md-ellipsis> GenerateOrdering </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GeneratePredicate/ class=md-nav__link> <span class=md-ellipsis> GeneratePredicate </span> </a> </li> <li class=md-nav__item> <a href=../whole-stage-code-generation/GenerateSafeProjection/ class=md-nav__link> <span class=md-ellipsis> GenerateSafeProjection </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_21_12 type=checkbox id=__nav_4_21_12> <label class=md-nav__link for=__nav_4_21_12 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Subexpression Elimination </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Subexpression Elimination" data-md-level=3> <label class=md-nav__title for=__nav_4_21_12> <span class="md-nav__icon md-icon"></span> Subexpression Elimination </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../subexpression-elimination/ class=md-nav__link> <span class=md-ellipsis> Subexpression Elimination </span> </a> </li> <li class=md-nav__item> <a href=../EquivalentExpressions/ class=md-nav__link> <span class=md-ellipsis> EquivalentExpressions </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_22 type=checkbox id=__nav_4_22> <label class=md-nav__link for=__nav_4_22 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Vectorized Query Execution </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Vectorized Query Execution" data-md-level=2> <label class=md-nav__title for=__nav_4_22> <span class="md-nav__icon md-icon"></span> Vectorized Query Execution </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../vectorized-query-execution/ class=md-nav__link> <span class=md-ellipsis> Vectorized Query Execution </span> </a> </li> <li class=md-nav__item> <a href=../ColumnarBatch/ class=md-nav__link> <span class=md-ellipsis> ColumnarBatch </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-subqueries/ class=md-nav__link> <span class=md-ellipsis> Subqueries </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_4_24 type=checkbox id=__nav_4_24> <div class="md-nav__link md-nav__container"> <a href=../catalyst-dsl/ class="md-nav__link "> <span class=md-ellipsis> Catalyst DSL </span> </a> <label class="md-nav__link " for=__nav_4_24> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Catalyst DSL" data-md-level=2> <label class=md-nav__title for=__nav_4_24> <span class="md-nav__icon md-icon"></span> Catalyst DSL </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../catalyst-dsl/DslLogicalPlan/ class=md-nav__link> <span class=md-ellipsis> DslLogicalPlan </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../variable-substitution/ class=md-nav__link> <span class=md-ellipsis> Variable Substitution </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5 type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../datasources/ class="md-nav__link "> <span class=md-ellipsis> Data Sources </span> </a> <label class="md-nav__link " for=__nav_5> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Data Sources" data-md-level=1> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Data Sources </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_2 type=checkbox id=__nav_5_2> <div class="md-nav__link md-nav__container"> <a href=../datasources/avro/ class="md-nav__link "> <span class=md-ellipsis> Avro </span> </a> <label class="md-nav__link " for=__nav_5_2> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Avro data-md-level=2> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> Avro </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/avro/AvroOptions/ class=md-nav__link> <span class=md-ellipsis> AvroOptions </span> </a> </li> <li class=md-nav__item> <a href=../datasources/avro/AvroFileFormat/ class=md-nav__link> <span class=md-ellipsis> AvroFileFormat </span> </a> </li> <li class=md-nav__item> <a href=../datasources/avro/CatalystDataToAvro/ class=md-nav__link> <span class=md-ellipsis> CatalystDataToAvro </span> </a> </li> <li class=md-nav__item> <a href=../datasources/avro/AvroDataToCatalyst/ class=md-nav__link> <span class=md-ellipsis> AvroDataToCatalyst </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_3 type=checkbox id=__nav_5_3> <div class="md-nav__link md-nav__container"> <a href=../datasources/console/ class="md-nav__link "> <span class=md-ellipsis> Console </span> </a> <label class="md-nav__link " for=__nav_5_3> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Console data-md-level=2> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> Console </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/console/ConsoleSinkProvider/ class=md-nav__link> <span class=md-ellipsis> ConsoleSinkProvider </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_4 type=checkbox id=__nav_5_4> <label class=md-nav__link for=__nav_5_4 tabindex=0 aria-expanded=false> <span class=md-ellipsis> CSV </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=CSV data-md-level=2> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> CSV </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/csv/CSVFileFormat/ class=md-nav__link> <span class=md-ellipsis> CSVFileFormat </span> </a> </li> <li class=md-nav__item> <a href=../datasources/csv/CSVScanBuilder/ class=md-nav__link> <span class=md-ellipsis> CSVScanBuilder </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_5 type=checkbox id=__nav_5_5> <label class=md-nav__link for=__nav_5_5 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Files </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Files data-md-level=2> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> Files </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/BasicWriteJobStatsTracker/ class=md-nav__link> <span class=md-ellipsis> BasicWriteJobStatsTracker </span> </a> </li> <li class=md-nav__item> <a href=../datasources/BasicWriteTaskStats/ class=md-nav__link> <span class=md-ellipsis> BasicWriteTaskStats </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileBatchWrite/ class=md-nav__link> <span class=md-ellipsis> FileBatchWrite </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileDataSourceV2/ class=md-nav__link> <span class=md-ellipsis> FileDataSourceV2 </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileFormat/ class=md-nav__link> <span class=md-ellipsis> FileFormat </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileFormatDataWriter/ class=md-nav__link> <span class=md-ellipsis> FileFormatDataWriter </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileFormatWriter/ class=md-nav__link> <span class=md-ellipsis> FileFormatWriter </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_5_8 type=checkbox id=__nav_5_5_8> <label class=md-nav__link for=__nav_5_5_8 tabindex=0 aria-expanded=false> <span class=md-ellipsis> FileIndex </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=FileIndex data-md-level=3> <label class=md-nav__title for=__nav_5_5_8> <span class="md-nav__icon md-icon"></span> FileIndex </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/FileIndex/ class=md-nav__link> <span class=md-ellipsis> FileIndex </span> </a> </li> <li class=md-nav__item> <a href=../datasources/CatalogFileIndex/ class=md-nav__link> <span class=md-ellipsis> CatalogFileIndex </span> </a> </li> <li class=md-nav__item> <a href=../datasources/InMemoryFileIndex/ class=md-nav__link> <span class=md-ellipsis> InMemoryFileIndex </span> </a> </li> <li class=md-nav__item> <a href=../datasources/PartitioningAwareFileIndex/ class=md-nav__link> <span class=md-ellipsis> PartitioningAwareFileIndex </span> </a> </li> <li class=md-nav__item> <a href=../datasources/PrunedInMemoryFileIndex/ class=md-nav__link> <span class=md-ellipsis> PrunedInMemoryFileIndex </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../datasources/FilePartition/ class=md-nav__link> <span class=md-ellipsis> FilePartition </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FilePartitionReaderFactory/ class=md-nav__link> <span class=md-ellipsis> FilePartitionReaderFactory </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileScan/ class=md-nav__link> <span class=md-ellipsis> FileScan </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileScanBuilder/ class=md-nav__link> <span class=md-ellipsis> FileScanBuilder </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileWrite/ class=md-nav__link> <span class=md-ellipsis> FileWrite </span> </a> </li> <li class=md-nav__item> <a href=../datasources/FileWriterFactory/ class=md-nav__link> <span class=md-ellipsis> FileWriterFactory </span> </a> </li> <li class=md-nav__item> <a href=../datasources/HadoopFileLinesReader/ class=md-nav__link> <span class=md-ellipsis> HadoopFileLinesReader </span> </a> </li> <li class=md-nav__item> <a href=../datasources/HadoopFsRelation/ class=md-nav__link> <span class=md-ellipsis> HadoopFsRelation </span> </a> </li> <li class=md-nav__item> <a href=../datasources/PartitionedFile/ class=md-nav__link> <span class=md-ellipsis> PartitionedFile </span> </a> </li> <li class=md-nav__item> <a href=../datasources/RecordReaderIterator/ class=md-nav__link> <span class=md-ellipsis> RecordReaderIterator </span> </a> </li> <li class=md-nav__item> <a href=../datasources/SingleDirectoryDataWriter/ class=md-nav__link> <span class=md-ellipsis> SingleDirectoryDataWriter </span> </a> </li> <li class=md-nav__item> <a href=../datasources/SQLHadoopMapReduceCommitProtocol/ class=md-nav__link> <span class=md-ellipsis> SQLHadoopMapReduceCommitProtocol </span> </a> </li> <li class=md-nav__item> <a href=../datasources/TextBasedFileFormat/ class=md-nav__link> <span class=md-ellipsis> TextBasedFileFormat </span> </a> </li> <li class=md-nav__item> <a href=../datasources/WriteJobStatsTracker/ class=md-nav__link> <span class=md-ellipsis> WriteJobStatsTracker </span> </a> </li> <li class=md-nav__item> <a href=../datasources/WriteTaskStats/ class=md-nav__link> <span class=md-ellipsis> WriteTaskStats </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_6 type=checkbox id=__nav_5_6> <div class="md-nav__link md-nav__container"> <a href=../hive/ class="md-nav__link "> <span class=md-ellipsis> Hive </span> </a> <label class="md-nav__link " for=__nav_5_6> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Hive data-md-level=2> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> Hive </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../hive/configuration-properties/ class=md-nav__link> <span class=md-ellipsis> Configuration Properties </span> </a> </li> <li class=md-nav__item> <a href=../hive/spark-sql-hive-metastore/ class=md-nav__link> <span class=md-ellipsis> Hive Metastore </span> </a> </li> <li class=md-nav__item> <a href=../hive/DataSinks/ class=md-nav__link> <span class=md-ellipsis> DataSinks </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveFileFormat/ class=md-nav__link> <span class=md-ellipsis> HiveFileFormat </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_6_6 type=checkbox id=__nav_5_6_6> <label class=md-nav__link for=__nav_5_6_6 tabindex=0 aria-expanded=false> <span class=md-ellipsis> HiveClient </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=HiveClient data-md-level=3> <label class=md-nav__title for=__nav_5_6_6> <span class="md-nav__icon md-icon"></span> HiveClient </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../hive/HiveClient/ class=md-nav__link> <span class=md-ellipsis> HiveClient </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveClientImpl/ class=md-nav__link> <span class=md-ellipsis> HiveClientImpl </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../hive/HiveUtils/ class=md-nav__link> <span class=md-ellipsis> HiveUtils </span> </a> </li> <li class=md-nav__item> <a href=../hive/IsolatedClientLoader/ class=md-nav__link> <span class=md-ellipsis> IsolatedClientLoader </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveTableRelation/ class=md-nav__link> <span class=md-ellipsis> HiveTableRelation </span> </a> </li> <li class=md-nav__item> <a href=../hive/CreateHiveTableAsSelectCommand/ class=md-nav__link> <span class=md-ellipsis> CreateHiveTableAsSelectCommand </span> </a> </li> <li class=md-nav__item> <a href=../hive/SaveAsHiveFile/ class=md-nav__link> <span class=md-ellipsis> SaveAsHiveFile </span> </a> </li> <li class=md-nav__item> <a href=../hive/InsertIntoHiveDirCommand/ class=md-nav__link> <span class=md-ellipsis> InsertIntoHiveDirCommand </span> </a> </li> <li class=md-nav__item> <a href=../hive/InsertIntoHiveTable/ class=md-nav__link> <span class=md-ellipsis> InsertIntoHiveTable </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveTableScans/ class=md-nav__link> <span class=md-ellipsis> HiveTableScans </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveTableScanExec/ class=md-nav__link> <span class=md-ellipsis> HiveTableScanExec </span> </a> </li> <li class=md-nav__item> <a href=../hive/TableReader/ class=md-nav__link> <span class=md-ellipsis> TableReader </span> </a> </li> <li class=md-nav__item> <a href=../hive/HadoopTableReader/ class=md-nav__link> <span class=md-ellipsis> HadoopTableReader </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveSessionStateBuilder/ class=md-nav__link> <span class=md-ellipsis> HiveSessionStateBuilder </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveExternalCatalog/ class=md-nav__link> <span class=md-ellipsis> HiveExternalCatalog </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveSessionCatalog/ class=md-nav__link> <span class=md-ellipsis> HiveSessionCatalog </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveMetastoreCatalog/ class=md-nav__link> <span class=md-ellipsis> HiveMetastoreCatalog </span> </a> </li> <li class=md-nav__item> <a href=../hive/RelationConversions/ class=md-nav__link> <span class=md-ellipsis> RelationConversions </span> </a> </li> <li class=md-nav__item> <a href=../hive/ResolveHiveSerdeTable/ class=md-nav__link> <span class=md-ellipsis> ResolveHiveSerdeTable </span> </a> </li> <li class=md-nav__item> <a href=../hive/DetermineTableStats/ class=md-nav__link> <span class=md-ellipsis> DetermineTableStats </span> </a> </li> <li class=md-nav__item> <a href=../hive/HiveAnalysis/ class=md-nav__link> <span class=md-ellipsis> HiveAnalysis </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_7 type=checkbox id=__nav_5_7> <div class="md-nav__link md-nav__container"> <a href=../datasources/jdbc/ class="md-nav__link "> <span class=md-ellipsis> JDBC </span> </a> <label class="md-nav__link " for=__nav_5_7> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=JDBC data-md-level=2> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> JDBC </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/jdbc/JDBCOptions/ class=md-nav__link> <span class=md-ellipsis> JDBCOptions </span> </a> </li> <li class=md-nav__item> <a href=../datasources/jdbc/JdbcRelationProvider/ class=md-nav__link> <span class=md-ellipsis> JdbcRelationProvider </span> </a> </li> <li class=md-nav__item> <a href=../datasources/jdbc/JDBCRelation/ class=md-nav__link> <span class=md-ellipsis> JDBCRelation </span> </a> </li> <li class=md-nav__item> <a href=../datasources/jdbc/JDBCScan/ class=md-nav__link> <span class=md-ellipsis> JDBCScan </span> </a> </li> <li class=md-nav__item> <a href=../datasources/jdbc/JDBCScanBuilder/ class=md-nav__link> <span class=md-ellipsis> JDBCScanBuilder </span> </a> </li> <li class=md-nav__item> <a href=../datasources/jdbc/JDBCRDD/ class=md-nav__link> <span class=md-ellipsis> JDBCRDD </span> </a> </li> <li class=md-nav__item> <a href=../datasources/jdbc/JdbcDialect/ class=md-nav__link> <span class=md-ellipsis> JdbcDialect </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_8 type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 tabindex=0 aria-expanded=false> <span class=md-ellipsis> JSON </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=JSON data-md-level=2> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> JSON </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/json/JsonFileFormat/ class=md-nav__link> <span class=md-ellipsis> JsonFileFormat </span> </a> </li> <li class=md-nav__item> <a href=../datasources/json/JsonDataSource/ class=md-nav__link> <span class=md-ellipsis> JsonDataSource </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_9 type=checkbox id=__nav_5_9> <div class="md-nav__link md-nav__container"> <a href=../kafka/ class="md-nav__link "> <span class=md-ellipsis> Kafka </span> </a> <label class="md-nav__link " for=__nav_5_9> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Kafka data-md-level=2> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> Kafka </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../kafka/configuration-properties/ class=md-nav__link> <span class=md-ellipsis> Configuration Properties </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaBatch/ class=md-nav__link> <span class=md-ellipsis> KafkaBatch </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaBatchWrite/ class=md-nav__link> <span class=md-ellipsis> KafkaBatchWrite </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaBatchWriterFactory/ class=md-nav__link> <span class=md-ellipsis> KafkaBatchWriterFactory </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaDataConsumer/ class=md-nav__link> <span class=md-ellipsis> KafkaDataConsumer </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaDataWriter/ class=md-nav__link> <span class=md-ellipsis> KafkaDataWriter </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaOffsetRangeLimit/ class=md-nav__link> <span class=md-ellipsis> KafkaOffsetRangeLimit </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaOffsetReader/ class=md-nav__link> <span class=md-ellipsis> KafkaOffsetReader </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaRelation/ class=md-nav__link> <span class=md-ellipsis> KafkaRelation </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaScan/ class=md-nav__link> <span class=md-ellipsis> KafkaScan </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaSourceProvider/ class=md-nav__link> <span class=md-ellipsis> KafkaSourceProvider </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaSourceRDD/ class=md-nav__link> <span class=md-ellipsis> KafkaSourceRDD </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaSourceRDDPartition/ class=md-nav__link> <span class=md-ellipsis> KafkaSourceRDDPartition </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaTable/ class=md-nav__link> <span class=md-ellipsis> KafkaTable </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaWrite/ class=md-nav__link> <span class=md-ellipsis> KafkaWrite </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaWriter/ class=md-nav__link> <span class=md-ellipsis> KafkaWriter </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaWriteTask/ class=md-nav__link> <span class=md-ellipsis> KafkaWriteTask </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_9_19 type=checkbox id=__nav_5_9_19> <label class=md-nav__link for=__nav_5_9_19 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Misc </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Misc data-md-level=3> <label class=md-nav__title for=__nav_5_9_19> <span class="md-nav__icon md-icon"></span> Misc </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../kafka/ConsumerStrategy/ class=md-nav__link> <span class=md-ellipsis> ConsumerStrategy </span> </a> </li> <li class=md-nav__item> <a href=../kafka/InternalKafkaConsumer/ class=md-nav__link> <span class=md-ellipsis> InternalKafkaConsumer </span> </a> </li> <li class=md-nav__item> <a href=../kafka/InternalKafkaProducerPool/ class=md-nav__link> <span class=md-ellipsis> InternalKafkaProducerPool </span> </a> </li> <li class=md-nav__item> <a href=../kafka/JsonUtils/ class=md-nav__link> <span class=md-ellipsis> JsonUtils </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaRowWriter/ class=md-nav__link> <span class=md-ellipsis> KafkaRowWriter </span> </a> </li> <li class=md-nav__item> <a href=../kafka/KafkaRecordToRowConverter/ class=md-nav__link> <span class=md-ellipsis> KafkaRecordToRowConverter </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../kafka/options/ class=md-nav__link> <span class=md-ellipsis> Options </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_10 type=checkbox id=__nav_5_10> <div class="md-nav__link md-nav__container"> <a href=../datasources/noop/ class="md-nav__link "> <span class=md-ellipsis> Noop </span> </a> <label class="md-nav__link " for=__nav_5_10> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Noop data-md-level=2> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> Noop </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/noop/NoopDataSource/ class=md-nav__link> <span class=md-ellipsis> NoopDataSource </span> </a> </li> <li class=md-nav__item> <a href=../datasources/noop/NoopTable/ class=md-nav__link> <span class=md-ellipsis> NoopTable </span> </a> </li> <li class=md-nav__item> <a href=../datasources/noop/NoopWriteBuilder/ class=md-nav__link> <span class=md-ellipsis> NoopWriteBuilder </span> </a> </li> <li class=md-nav__item> <a href=../datasources/noop/NoopBatchWrite/ class=md-nav__link> <span class=md-ellipsis> NoopBatchWrite </span> </a> </li> <li class=md-nav__item> <a href=../datasources/noop/NoopStreamingWrite/ class=md-nav__link> <span class=md-ellipsis> NoopStreamingWrite </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_11 type=checkbox id=__nav_5_11> <label class=md-nav__link for=__nav_5_11 tabindex=0 aria-expanded=false> <span class=md-ellipsis> ORC </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=ORC data-md-level=2> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> ORC </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/orc/OrcScanBuilder/ class=md-nav__link> <span class=md-ellipsis> OrcScanBuilder </span> </a> </li> <li class=md-nav__item> <a href=../datasources/orc/OrcFileFormat/ class=md-nav__link> <span class=md-ellipsis> OrcFileFormat </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_12 type=checkbox id=__nav_5_12> <div class="md-nav__link md-nav__container"> <a href=../datasources/parquet/ class="md-nav__link "> <span class=md-ellipsis> Parquet </span> </a> <label class="md-nav__link " for=__nav_5_12> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Parquet data-md-level=2> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> Parquet </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/parquet/ParquetDataSourceV2/ class=md-nav__link> <span class=md-ellipsis> ParquetDataSourceV2 </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetFileFormat/ class=md-nav__link> <span class=md-ellipsis> ParquetFileFormat </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetFilters/ class=md-nav__link> <span class=md-ellipsis> ParquetFilters </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetOptions/ class=md-nav__link> <span class=md-ellipsis> ParquetOptions </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetPartitionReaderFactory/ class=md-nav__link> <span class=md-ellipsis> ParquetPartitionReaderFactory </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetReadSupport/ class=md-nav__link> <span class=md-ellipsis> ParquetReadSupport </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetScan/ class=md-nav__link> <span class=md-ellipsis> ParquetScan </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetScanBuilder/ class=md-nav__link> <span class=md-ellipsis> ParquetScanBuilder </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetTable/ class=md-nav__link> <span class=md-ellipsis> ParquetTable </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetUtils/ class=md-nav__link> <span class=md-ellipsis> ParquetUtils </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetWrite/ class=md-nav__link> <span class=md-ellipsis> ParquetWrite </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/ParquetWriteSupport/ class=md-nav__link> <span class=md-ellipsis> ParquetWriteSupport </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/SparkToParquetSchemaConverter/ class=md-nav__link> <span class=md-ellipsis> SparkToParquetSchemaConverter </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/SpecificParquetRecordReaderBase/ class=md-nav__link> <span class=md-ellipsis> SpecificParquetRecordReaderBase </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/VectorizedColumnReader/ class=md-nav__link> <span class=md-ellipsis> VectorizedColumnReader </span> </a> </li> <li class=md-nav__item> <a href=../datasources/parquet/VectorizedParquetRecordReader/ class=md-nav__link> <span class=md-ellipsis> VectorizedParquetRecordReader </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_5_13 type=checkbox id=__nav_5_13> <label class=md-nav__link for=__nav_5_13 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Text </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Text data-md-level=2> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> Text </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../datasources/text/TextFileFormat/ class=md-nav__link> <span class=md-ellipsis> TextFileFormat </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../datasources/BaseDynamicPartitionDataWriter/ class=md-nav__link> <span class=md-ellipsis> BaseDynamicPartitionDataWriter </span> </a> </li> <li class=md-nav__item> <a href=../datasources/BasicWriteTaskStatsTracker/ class=md-nav__link> <span class=md-ellipsis> BasicWriteTaskStatsTracker </span> </a> </li> <li class=md-nav__item> <a href=../datasources/DataWritingSparkTask/ class=md-nav__link> <span class=md-ellipsis> DataWritingSparkTask </span> </a> </li> <li class=md-nav__item> <a href=../datasources/DataSourceV2Utils/ class=md-nav__link> <span class=md-ellipsis> DataSourceV2Utils </span> </a> </li> <li class=md-nav__item> <a href=../datasources/DynamicPartitionDataConcurrentWriter/ class=md-nav__link> <span class=md-ellipsis> DynamicPartitionDataConcurrentWriter </span> </a> </li> <li class=md-nav__item> <a href=../datasources/DynamicPartitionDataSingleWriter/ class=md-nav__link> <span class=md-ellipsis> DynamicPartitionDataSingleWriter </span> </a> </li> <li class=md-nav__item> <a href=../datasources/OutputWriter/ class=md-nav__link> <span class=md-ellipsis> OutputWriter </span> </a> </li> <li class=md-nav__item> <a href=../datasources/WriteTaskStatsTracker/ class=md-nav__link> <span class=md-ellipsis> WriteTaskStatsTracker </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_6 type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 tabindex=0 aria-expanded=false> <span class=md-ellipsis> High-Level APIs </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="High-Level APIs" data-md-level=1> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> High-Level APIs </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_6_1 type=checkbox id=__nav_6_1> <div class="md-nav__link md-nav__container"> <a href=../basic-aggregation/ class="md-nav__link "> <span class=md-ellipsis> Basic Aggregation </span> </a> <label class="md-nav__link " for=__nav_6_1> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Basic Aggregation" data-md-level=2> <label class=md-nav__title for=__nav_6_1> <span class="md-nav__icon md-icon"></span> Basic Aggregation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../basic-aggregation/KeyValueGroupedDataset/ class=md-nav__link> <span class=md-ellipsis> KeyValueGroupedDataset </span> </a> </li> <li class=md-nav__item> <a href=../basic-aggregation/RelationalGroupedDataset/ class=md-nav__link> <span class=md-ellipsis> RelationalGroupedDataset </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ColumnarRule/ class=md-nav__link> <span class=md-ellipsis> ColumnarRule </span> </a> </li> <li class=md-nav__item> <a href=../Dataset/ class=md-nav__link> <span class=md-ellipsis> Dataset </span> </a> </li> <li class=md-nav__item> <a href=../DataFrame/ class=md-nav__link> <span class=md-ellipsis> DataFrame </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameReader/ class=md-nav__link> <span class=md-ellipsis> DataFrameReader </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameWriter/ class=md-nav__link> <span class=md-ellipsis> DataFrameWriter </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameWriterV2/ class=md-nav__link> <span class=md-ellipsis> DataFrameWriterV2 </span> </a> </li> <li class=md-nav__item> <a href=../Encoders/ class=md-nav__link> <span class=md-ellipsis> Encoders </span> </a> </li> <li class=md-nav__item> <a href=../QueryExecutionListener/ class=md-nav__link> <span class=md-ellipsis> QueryExecutionListener </span> </a> </li> <li class=md-nav__item> <a href=../SparkSession/ class=md-nav__link> <span class=md-ellipsis> SparkSession </span> </a> </li> <li class=md-nav__item> <a href=../SparkSession-Builder/ class=md-nav__link> <span class=md-ellipsis> SparkSession.Builder </span> </a> </li> <li class=md-nav__item> <a href=../SparkSessionExtensions/ class=md-nav__link> <span class=md-ellipsis> SparkSessionExtensions </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_6_13 type=checkbox id=__nav_6_13> <div class="md-nav__link md-nav__container"> <a href=../functions/ class="md-nav__link "> <span class=md-ellipsis> Standard Functions </span> </a> <label class="md-nav__link " for=__nav_6_13> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Standard Functions" data-md-level=2> <label class=md-nav__title for=__nav_6_13> <span class="md-nav__icon md-icon"></span> Standard Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../functions/aggregate-functions/ class=md-nav__link> <span class=md-ellipsis> Standard Aggregate Functions </span> </a> </li> <li class=md-nav__item> <a href=../functions/collection-functions/ class=md-nav__link> <span class=md-ellipsis> Standard Collection Functions </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-functions-datetime/ class=md-nav__link> <span class=md-ellipsis> Date and Time Functions </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-functions-regular-functions/ class=md-nav__link> <span class=md-ellipsis> Regular Functions (Non-Aggregate Functions) </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-functions-windows/ class=md-nav__link> <span class=md-ellipsis> Standard Functions for Window Aggregation (Window Functions) </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_6_14 type=checkbox id=__nav_6_14> <div class="md-nav__link md-nav__container"> <a href=../window-functions/ class="md-nav__link "> <span class=md-ellipsis> Window Functions </span> </a> <label class="md-nav__link " for=__nav_6_14> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Window Functions" data-md-level=2> <label class=md-nav__title for=__nav_6_14> <span class="md-nav__icon md-icon"></span> Window Functions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../window-functions/AggregateProcessor/ class=md-nav__link> <span class=md-ellipsis> AggregateProcessor </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/RangeFrame/ class=md-nav__link> <span class=md-ellipsis> RangeFrame </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/Window/ class=md-nav__link> <span class=md-ellipsis> Window </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/WindowFunctionFrame/ class=md-nav__link> <span class=md-ellipsis> WindowFunctionFrame </span> </a> </li> <li class=md-nav__item> <a href=../window-functions/WindowSpec/ class=md-nav__link> <span class=md-ellipsis> WindowSpec </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_7 type=checkbox id=__nav_7> <div class="md-nav__link md-nav__container"> <a href=../ui/ class="md-nav__link "> <span class=md-ellipsis> Web UI </span> </a> <label class="md-nav__link " for=__nav_7> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Web UI" data-md-level=1> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Web UI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ui/AllExecutionsPage/ class=md-nav__link> <span class=md-ellipsis> AllExecutionsPage </span> </a> </li> <li class=md-nav__item> <a href=../ui/ExecutionPage/ class=md-nav__link> <span class=md-ellipsis> ExecutionPage </span> </a> </li> <li class=md-nav__item> <a href=../ui/SparkListenerSQLExecutionEnd/ class=md-nav__link> <span class=md-ellipsis> SparkListenerSQLExecutionEnd </span> </a> </li> <li class=md-nav__item> <a href=../ui/SQLAppStatusListener/ class=md-nav__link> <span class=md-ellipsis> SQLAppStatusListener </span> </a> </li> <li class=md-nav__item> <a href=../ui/SQLAppStatusStore/ class=md-nav__link> <span class=md-ellipsis> SQLAppStatusStore </span> </a> </li> <li class=md-nav__item> <a href=../ui/SQLTab/ class=md-nav__link> <span class=md-ellipsis> SQLTab </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_8 type=checkbox id=__nav_8> <div class="md-nav__link md-nav__container"> <a href=../demo/ class="md-nav__link "> <span class=md-ellipsis> Demo </span> </a> <label class="md-nav__link " for=__nav_8> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label=Demo data-md-level=1> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Demo </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../demo/connecting-spark-sql-to-hive-metastore/ class=md-nav__link> <span class=md-ellipsis> Connecting Spark SQL to Hive Metastore (with Remote Metastore Server) </span> </a> </li> <li class=md-nav__item> <a href=../demo/developing-catalogplugin/ class=md-nav__link> <span class=md-ellipsis> Developing CatalogPlugin </span> </a> </li> <li class=md-nav__item> <a href=../demo/hive-partitioned-parquet-table-partition-pruning/ class=md-nav__link> <span class=md-ellipsis> Hive Partitioned Parquet Table and Partition Pruning </span> </a> </li> <li class=md-nav__item> <a href=../demo/objecthashaggregateexec-sort-based-fallback-tasks/ class=md-nav__link> <span class=md-ellipsis> ObjectHashAggregateExec and Sort-Based Fallback Tasks </span> </a> </li> <li class=md-nav__item> <a href=../demo/spilling/ class=md-nav__link> <span class=md-ellipsis> Spilling </span> </a> </li> <li class=md-nav__item> <a href=../demo/using-jdbc-data-source-to-access-postgresql/ class=md-nav__link> <span class=md-ellipsis> Using JDBC Data Source to Access PostgreSQL </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9 type=checkbox id=__nav_9> <label class=md-nav__link for=__nav_9 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Misc </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Misc data-md-level=1> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> Misc </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../AggregatingAccumulator/ class=md-nav__link> <span class=md-ellipsis> AggregatingAccumulator </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_2 type=checkbox id=__nav_9_2> <label class=md-nav__link for=__nav_9_2 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Bloom Filter </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Bloom Filter" data-md-level=2> <label class=md-nav__title for=__nav_9_2> <span class="md-nav__icon md-icon"></span> Bloom Filter </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../BloomFilter/ class=md-nav__link> <span class=md-ellipsis> BloomFilter </span> </a> </li> <li class=md-nav__item> <a href=../BloomFilterImpl/ class=md-nav__link> <span class=md-ellipsis> BloomFilterImpl </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../PushDownUtils/ class=md-nav__link> <span class=md-ellipsis> PushDownUtils </span> </a> </li> <li class=md-nav__item> <a href=../UnsafeExternalRowSorter/ class=md-nav__link> <span class=md-ellipsis> UnsafeExternalRowSorter </span> </a> </li> <li class=md-nav__item> <a href=../BindReferences/ class=md-nav__link> <span class=md-ellipsis> BindReferences </span> </a> </li> <li class=md-nav__item> <a href=../IntervalUtils/ class=md-nav__link> <span class=md-ellipsis> IntervalUtils </span> </a> </li> <li class=md-nav__item> <a href=../ExplainUtils/ class=md-nav__link> <span class=md-ellipsis> ExplainUtils </span> </a> </li> <li class=md-nav__item> <a href=../PartitionedFileUtil/ class=md-nav__link> <span class=md-ellipsis> PartitionedFileUtil </span> </a> </li> <li class=md-nav__item> <a href=../SerializerBuildHelper/ class=md-nav__link> <span class=md-ellipsis> SerializerBuildHelper </span> </a> </li> <li class=md-nav__item> <a href=../SQLExecutionRDD/ class=md-nav__link> <span class=md-ellipsis> SQLExecutionRDD </span> </a> </li> <li class=md-nav__item> <a href=../DataSourceRDD/ class=md-nav__link> <span class=md-ellipsis> DataSourceRDD </span> </a> </li> <li class=md-nav__item> <a href=../DataSourceRDDPartition/ class=md-nav__link> <span class=md-ellipsis> DataSourceRDDPartition </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-dataset-rdd/ class=md-nav__link> <span class=md-ellipsis> Dataset, DataFrame and RDD </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-dataset-vs-sql/ class=md-nav__link> <span class=md-ellipsis> Dataset and SQL </span> </a> </li> <li class=md-nav__item> <a href=../implicits/ class=md-nav__link> <span class=md-ellipsis> Implicits </span> </a> </li> <li class=md-nav__item> <a href=../Row/ class=md-nav__link> <span class=md-ellipsis> Row </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_17 type=checkbox id=__nav_9_17> <label class=md-nav__link for=__nav_9_17 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Data Source API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Data Source API" data-md-level=2> <label class=md-nav__title for=__nav_9_17> <span class="md-nav__icon md-icon"></span> Data Source API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-datasource-api/ class=md-nav__link> <span class=md-ellipsis> DataSource API </span> </a> </li> <li class=md-nav__item> <a href=../CreateTableWriter/ class=md-nav__link> <span class=md-ellipsis> CreateTableWriter </span> </a> </li> <li class=md-nav__item> <a href=../WriteConfigMethods/ class=md-nav__link> <span class=md-ellipsis> WriteConfigMethods </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_18 type=checkbox id=__nav_9_18> <label class=md-nav__link for=__nav_9_18 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Dataset API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Dataset API" data-md-level=2> <label class=md-nav__title for=__nav_9_18> <span class="md-nav__icon md-icon"></span> Dataset API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../spark-sql-dataset-operators/ class=md-nav__link> <span class=md-ellipsis> Dataset API &mdash; Dataset Operators </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-Dataset-typed-transformations/ class=md-nav__link> <span class=md-ellipsis> Typed Transformations </span> </a> </li> <li class=md-nav__item> <a href=../Dataset-untyped-transformations/ class=md-nav__link> <span class=md-ellipsis> Untyped Transformations </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-Dataset-basic-actions/ class=md-nav__link> <span class=md-ellipsis> Dataset API &mdash; Basic Actions </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-Dataset-actions/ class=md-nav__link> <span class=md-ellipsis> Actions </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-DataFrameNaFunctions/ class=md-nav__link> <span class=md-ellipsis> DataFrameNaFunctions &mdash; Working With Missing Data </span> </a> </li> <li class=md-nav__item> <a href=../DataFrameStatFunctions/ class=md-nav__link> <span class=md-ellipsis> DataFrameStatFunctions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_19 type=checkbox id=__nav_9_19> <label class=md-nav__link for=__nav_9_19 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Column </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Column data-md-level=2> <label class=md-nav__title for=__nav_9_19> <span class="md-nav__icon md-icon"></span> Column </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Column/ class=md-nav__link> <span class=md-ellipsis> Column </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-column-operators/ class=md-nav__link> <span class=md-ellipsis> Column Operators </span> </a> </li> <li class=md-nav__item> <a href=../TypedColumn/ class=md-nav__link> <span class=md-ellipsis> TypedColumn </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_20 type=checkbox id=__nav_9_20> <div class="md-nav__link md-nav__container"> <a href=../types/ class="md-nav__link "> <span class=md-ellipsis> Data Types </span> </a> <label class="md-nav__link " for=__nav_9_20> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav aria-label="Data Types" data-md-level=2> <label class=md-nav__title for=__nav_9_20> <span class="md-nav__icon md-icon"></span> Data Types </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../types/AbstractDataType/ class=md-nav__link> <span class=md-ellipsis> AbstractDataType </span> </a> </li> <li class=md-nav__item> <a href=../types/ArrayType/ class=md-nav__link> <span class=md-ellipsis> ArrayType </span> </a> </li> <li class=md-nav__item> <a href=../types/AtomicType/ class=md-nav__link> <span class=md-ellipsis> AtomicType </span> </a> </li> <li class=md-nav__item> <a href=../types/CalendarInterval/ class=md-nav__link> <span class=md-ellipsis> CalendarInterval </span> </a> </li> <li class=md-nav__item> <a href=../types/DataType/ class=md-nav__link> <span class=md-ellipsis> DataType </span> </a> </li> <li class=md-nav__item> <a href=../types/StructField/ class=md-nav__link> <span class=md-ellipsis> StructField </span> </a> </li> <li class=md-nav__item> <a href=../types/StructType/ class=md-nav__link> <span class=md-ellipsis> StructType </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_21 type=checkbox id=__nav_9_21> <label class=md-nav__link for=__nav_9_21 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Caching and Persistence </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Caching and Persistence" data-md-level=2> <label class=md-nav__title for=__nav_9_21> <span class="md-nav__icon md-icon"></span> Caching and Persistence </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../caching-and-persistence/ class=md-nav__link> <span class=md-ellipsis> Caching and Persistence </span> </a> </li> <li class=md-nav__item> <a href=../caching-webui-storage/ class=md-nav__link> <span class=md-ellipsis> User-Friendly Names of Cached Queries in web UI </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../checkpointing/ class=md-nav__link> <span class=md-ellipsis> Checkpointing </span> </a> </li> <li class=md-nav__item> <a href=../rdds/FileScanRDD/ class=md-nav__link> <span class=md-ellipsis> FileScanRDD </span> </a> </li> <li class=md-nav__item> <a href=../spark-logging/ class=md-nav__link> <span class=md-ellipsis> Logging </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_25 type=checkbox id=__nav_9_25> <label class=md-nav__link for=__nav_9_25 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Performance Tuning and Debugging </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Performance Tuning and Debugging" data-md-level=2> <label class=md-nav__title for=__nav_9_25> <span class="md-nav__icon md-icon"></span> Performance Tuning and Debugging </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../debugging-query-execution/ class=md-nav__link> <span class=md-ellipsis> Debugging Query Execution </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-performance-tuning/ class=md-nav__link> <span class=md-ellipsis> Performance Tuning </span> </a> </li> <li class=md-nav__item> <a href=../spark-sql-performance-tuning-groupBy-aggregation/ class=md-nav__link> <span class=md-ellipsis> Case Study </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " data-md-toggle=__nav_9_26 type=checkbox id=__nav_9_26> <label class=md-nav__link for=__nav_9_26 tabindex=0 aria-expanded=false> <span class=md-ellipsis> Spark Thrift Server </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Spark Thrift Server" data-md-level=2> <label class=md-nav__title for=__nav_9_26> <span class="md-nav__icon md-icon"></span> Spark Thrift Server </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../thrift-server/spark-sql-thrift-server/ class=md-nav__link> <span class=md-ellipsis> HiveThriftServer2 </span> </a> </li> <li class=md-nav__item> <a href=../thrift-server/spark-sql-thriftserver-SparkSQLEnv/ class=md-nav__link> <span class=md-ellipsis> SparkSQLEnv </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../spark-sql-RDDConversions/ class=md-nav__link> <span class=md-ellipsis> RDDConversions </span> </a> </li> <li class=md-nav__item> <a href=../ShuffledRowRDD/ class=md-nav__link> <span class=md-ellipsis> ShuffledRowRDD </span> </a> </li> <li class=md-nav__item> <a href=../CheckAnalysis/ class=md-nav__link> <span class=md-ellipsis> CheckAnalysis </span> </a> </li> <li class=md-nav__item> <a href=../CatalystTypeConverters/ class=md-nav__link> <span class=md-ellipsis> CatalystTypeConverters </span> </a> </li> <li class=md-nav__item> <a href=../SubExprUtils/ class=md-nav__link> <span class=md-ellipsis> SubExprUtils </span> </a> </li> <li class=md-nav__item> <a href=../PredicateHelper/ class=md-nav__link> <span class=md-ellipsis> PredicateHelper </span> </a> </li> <li class=md-nav__item> <a href=../AggUtils/ class=md-nav__link> <span class=md-ellipsis> AggUtils </span> </a> </li> <li class=md-nav__item> <a href=../ExtractEquiJoinKeys/ class=md-nav__link> <span class=md-ellipsis> ExtractEquiJoinKeys </span> </a> </li> <li class=md-nav__item> <a href=../ExtractSingleColumnNullAwareAntiJoin/ class=md-nav__link> <span class=md-ellipsis> ExtractSingleColumnNullAwareAntiJoin </span> </a> </li> <li class=md-nav__item> <a href=../ExtractJoinWithBuckets/ class=md-nav__link> <span class=md-ellipsis> ExtractJoinWithBuckets </span> </a> </li> <li class=md-nav__item> <a href=../PhysicalAggregation/ class=md-nav__link> <span class=md-ellipsis> PhysicalAggregation </span> </a> </li> <li class=md-nav__item> <a href=../PhysicalOperation/ class=md-nav__link> <span class=md-ellipsis> PhysicalOperation </span> </a> </li> <li class=md-nav__item> <a href=../KnownSizeEstimation/ class=md-nav__link> <span class=md-ellipsis> KnownSizeEstimation </span> </a> </li> <li class=md-nav__item> <a href=../CompressionCodecs/ class=md-nav__link> <span class=md-ellipsis> CompressionCodecs </span> </a> </li> <li class=md-nav__item> <a href=../JoinStrategyHint/ class=md-nav__link> <span class=md-ellipsis> JoinStrategyHint </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#optimizercanchangecachedplanoutputpartitioning class=md-nav__link> <span class=md-ellipsis> optimizer.canChangeCachedPlanOutputPartitioning </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdecorrelateinnerqueryenabled class=md-nav__link> <span class=md-ellipsis> optimizer.decorrelateInnerQuery.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningfallbackfilterratio class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.fallbackFilterRatio </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningpruningsideextrafilterratio class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningusestats class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.useStats </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerdynamicpartitionpruningreusebroadcastonly class=md-nav__link> <span class=md-ellipsis> optimizer.dynamicPartitionPruning.reuseBroadcastOnly </span> </a> </li> <li class=md-nav__item> <a href=#optimizerenablecsvexpressionoptimization class=md-nav__link> <span class=md-ellipsis> optimizer.enableCsvExpressionOptimization </span> </a> </li> <li class=md-nav__item> <a href=#optimizerexcludedrules class=md-nav__link> <span class=md-ellipsis> optimizer.excludedRules </span> </a> </li> <li class=md-nav__item> <a href=#optimizerexpressionnestedpruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.expression.nestedPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerinsetconversionthreshold class=md-nav__link> <span class=md-ellipsis> optimizer.inSetConversionThreshold </span> </a> </li> <li class=md-nav__item> <a href=#optimizerinsetswitchthreshold class=md-nav__link> <span class=md-ellipsis> optimizer.inSetSwitchThreshold </span> </a> </li> <li class=md-nav__item> <a href=#optimizermaxiterations class=md-nav__link> <span class=md-ellipsis> optimizer.maxIterations </span> </a> </li> <li class=md-nav__item> <a href=#optimizernestedschemapruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.nestedSchemaPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizernestedpredicatepushdownsupportedfilesources class=md-nav__link> <span class=md-ellipsis> optimizer.nestedPredicatePushdown.supportedFileSources </span> </a> </li> <li class=md-nav__item> <a href=#optimizeroptimizeonerowrelationsubquery class=md-nav__link> <span class=md-ellipsis> optimizer.optimizeOneRowRelationSubquery </span> </a> </li> <li class=md-nav__item> <a href=#optimizerplanchangelogbatches class=md-nav__link> <span class=md-ellipsis> optimizer.planChangeLog.batches </span> </a> </li> <li class=md-nav__item> <a href=#optimizerplanchangeloglevel class=md-nav__link> <span class=md-ellipsis> optimizer.planChangeLog.level </span> </a> </li> <li class=md-nav__item> <a href=#optimizerplanchangelogrules class=md-nav__link> <span class=md-ellipsis> optimizer.planChangeLog.rules </span> </a> </li> <li class=md-nav__item> <a href=#optimizerreplaceexceptwithfilter class=md-nav__link> <span class=md-ellipsis> optimizer.replaceExceptWithFilter </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimebloomfilterenabled class=md-nav__link> <span class=md-ellipsis> optimizer.runtime.bloomFilter.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimebloomfilterexpectednumitems class=md-nav__link> <span class=md-ellipsis> optimizer.runtime.bloomFilter.expectedNumItems </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimebloomfiltermaxnumbits class=md-nav__link> <span class=md-ellipsis> optimizer.runtime.bloomFilter.maxNumBits </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimefilternumberthreshold class=md-nav__link> <span class=md-ellipsis> optimizer.runtimeFilter.number.threshold </span> </a> </li> <li class=md-nav__item> <a href=#optimizerruntimefiltersemijoinreductionenabled class=md-nav__link> <span class=md-ellipsis> optimizer.runtimeFilter.semiJoinReduction.enabled </span> </a> </li> <li class=md-nav__item> <a href=#optimizerserializernestedschemapruningenabled class=md-nav__link> <span class=md-ellipsis> optimizer.serializer.nestedSchemaPruning.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveautobroadcastjointhreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.autoBroadcastJoinThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecustomcostevaluatorclass class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.customCostEvaluatorClass </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlobjecthashaggregatesortbasedfallbackthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.objectHashAggregate.sortBased.fallbackThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveoptimizeskewsinrebalancepartitionsenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatefasthashmapcapacitybit class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.fastHashMap.capacityBit </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemaptwolevelenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.twolevel.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemapvectorizedenable class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.vectorized.enable </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemaptwolevelpartialonly class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.twolevel.partialOnly </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownonemptylocationinctas class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowNonEmptyLocationInCTAS </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowautogeneratedaliasforview class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowAutoGeneratedAliasForView </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.sessionWindow.buffer.spill.threshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowpysparkselfdestructenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.pyspark.selfDestruct.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowstarwithsingletableidentifierincount class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowStarWithSingleTableIdentifierInCount </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessionwindowbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.sessionWindow.buffer.in.memory.threshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcenablenestedcolumnvectorizedreader class=md-nav__link> <span class=md-ellipsis> spark.sql.orc.enableNestedColumnVectorizedReader </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveforceapply class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.forceApply </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsminpartitionsize class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.minPartitionSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsparallelismfirst class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.parallelismFirst </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveadvisorypartitionsizeinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.advisoryPartitionSizeInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsminpartitionsize_1 class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.minPartitionSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivecoalescepartitionsinitialpartitionnum class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.coalescePartitions.initialPartitionNum </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivefetchshuffleblocksinbatch class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.fetchShuffleBlocksInBatch </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivelocalshufflereaderenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.localShuffleReader.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveloglevel class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.logLevel </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivemaxshuffledhashjoinlocalmapthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveoptimizerexcludedrules class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.optimizer.excludedRules </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveskewjoinenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.skewJoin.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveskewjoinskewedpartitionfactor class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.skewJoin.skewedPartitionFactor </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptiveskewjoinskewedpartitionthresholdinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladaptivenonemptypartitionratioforbroadcastjoin class=md-nav__link> <span class=md-ellipsis> spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzermaxiterations class=md-nav__link> <span class=md-ellipsis> spark.sql.analyzer.maxIterations </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlanalyzerfailambiguousselfjoin class=md-nav__link> <span class=md-ellipsis> spark.sql.analyzer.failAmbiguousSelfJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlansienabled class=md-nav__link> <span class=md-ellipsis> spark.sql.ansi.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcliprintheader class=md-nav__link> <span class=md-ellipsis> spark.sql.cli.print.header </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenwholestage class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.wholeStage </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenmethodsplitthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.methodSplitThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldebugmaxtostringfields class=md-nav__link> <span class=md-ellipsis> spark.sql.debug.maxToStringFields </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultcatalog class=md-nav__link> <span class=md-ellipsis> spark.sql.defaultCatalog </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowpysparkenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.pyspark.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionremoveredundantsorts class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.removeRedundantSorts </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionreusesubquery class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.reuseSubquery </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionsortbeforerepartition class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.sortBeforeRepartition </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionrangeexchangesamplesizeperpartition class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.rangeExchange.sampleSizePerPartition </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowpysparkfallbackenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.pyspark.fallback.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionarrowsparkrenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.arrow.sparkr.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionpandasudfbuffersize class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.pandas.udf.buffer.size </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexecutionpandasconverttoarrowarraysafely class=md-nav__link> <span class=md-ellipsis> spark.sql.execution.pandas.convertToArrowArraySafely </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.histogram.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsessiontimezone class=md-nav__link> <span class=md-ellipsis> spark.sql.session.timeZone </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcescommitprotocolclass class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.commitProtocolClass </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesignoredatalocality class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.ignoreDataLocality </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesoutputcommitterclass class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.outputCommitterClass </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesvalidatepartitioncolumns class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.validatePartitionColumns </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesusev1sourcelist class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.useV1SourceList </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstoreassignmentpolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.storeAssignmentPolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlthriftserverinterruptoncancel class=md-nav__link> <span class=md-ellipsis> spark.sql.thriftServer.interruptOnCancel </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlhivetablepropertylengththreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.hive.tablePropertyLengthThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcmergeschema class=md-nav__link> <span class=md-ellipsis> spark.sql.orc.mergeSchema </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbucketingautobucketedscanenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.bucketing.autoBucketedScan.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldatetimejava8apienabled class=md-nav__link> <span class=md-ellipsis> spark.sql.datetime.java8API.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyintervalenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.interval.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbinaryfilemaxlength class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.binaryFile.maxLength </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmapkeydeduppolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.mapKeyDedupPolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxconcurrentoutputfilewriters class=md-nav__link> <span class=md-ellipsis> spark.sql.maxConcurrentOutputFileWriters </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxmetadatastringlength class=md-nav__link> <span class=md-ellipsis> spark.sql.maxMetadataStringLength </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmavenadditionalremoterepositories class=md-nav__link> <span class=md-ellipsis> spark.sql.maven.additionalRemoteRepositories </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlmaxplanstringlength class=md-nav__link> <span class=md-ellipsis> spark.sql.maxPlanStringLength </span> </a> </li> <li class=md-nav__item> <a href=#sparksqladdpartitioninbatchsize class=md-nav__link> <span class=md-ellipsis> spark.sql.addPartitionInBatch.size </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlscripttransformationexittimeoutinseconds class=md-nav__link> <span class=md-ellipsis> spark.sql.scriptTransformation.exitTimeoutInSeconds </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlautobroadcastjointhreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.autoBroadcastJoinThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlavrocompressioncodec class=md-nav__link> <span class=md-ellipsis> spark.sql.avro.compression.codec </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbroadcasttimeout class=md-nav__link> <span class=md-ellipsis> spark.sql.broadcastTimeout </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlbucketingcoalescebucketsinjoinenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.bucketing.coalesceBucketsInJoin.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcasesensitive class=md-nav__link> <span class=md-ellipsis> spark.sql.caseSensitive </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcatalogspark_catalog class=md-nav__link> <span class=md-ellipsis> spark.sql.catalog.spark_catalog </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbojoinreorderenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.joinReorder.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcboplanstatsenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.planStats.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcbostarschemadetection class=md-nav__link> <span class=md-ellipsis> spark.sql.cbo.starSchemaDetection </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatemapvectorizedenable_1 class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.map.vectorized.enable </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenaggregatesplitaggregatefuncenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.aggregate.splitAggregateFunc.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegencomments class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.comments </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenfactorymode class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.factoryMode </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenfallback class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.fallback </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenhugemethodlimit class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.hugeMethodLimit </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenuseidinclassname class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.useIdInClassName </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegenmaxfields class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.maxFields </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcodegensplitconsumefuncbyoperator class=md-nav__link> <span class=md-ellipsis> spark.sql.codegen.splitConsumeFuncByOperator </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcolumnvectoroffheapenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.columnVector.offheap.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcolumnnameofcorruptrecord class=md-nav__link> <span class=md-ellipsis> spark.sql.columnNameOfCorruptRecord </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlconstraintpropagationenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.constraintPropagation.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlcsvfilterpushdownenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.csv.filterPushdown.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldefaultsizeinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.defaultSizeInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqldialect class=md-nav__link> <span class=md-ellipsis> spark.sql.dialect </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlexchangereuse class=md-nav__link> <span class=md-ellipsis> spark.sql.exchange.reuse </span> </a> </li> <li class=md-nav__item> <a href=#executionuseobjecthashaggregateexec class=md-nav__link> <span class=md-ellipsis> execution.useObjectHashAggregateExec </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignorecorruptfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.files.ignoreCorruptFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesignoremissingfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.files.ignoreMissingFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesmaxrecordsperfile class=md-nav__link> <span class=md-ellipsis> spark.sql.files.maxRecordsPerFile </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesmaxpartitionbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.files.maxPartitionBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesminpartitionnum class=md-nav__link> <span class=md-ellipsis> spark.sql.files.minPartitionNum </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlfilesopencostinbytes class=md-nav__link> <span class=md-ellipsis> spark.sql.files.openCostInBytes </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragecompressed class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.compressed </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragebatchsize class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.batchSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorytablescanstatisticsenable class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryTableScanStatistics.enable </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstorageenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.enableVectorizedReader </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlinmemorycolumnarstoragepartitionpruning class=md-nav__link> <span class=md-ellipsis> spark.sql.inMemoryColumnarStorage.partitionPruning </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljoinprefersortmergejoin class=md-nav__link> <span class=md-ellipsis> spark.sql.join.preferSortMergeJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqljsongeneratorignorenullfields class=md-nav__link> <span class=md-ellipsis> spark.sql.jsonGenerator.ignoreNullFields </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlleafnodedefaultparallelism class=md-nav__link> <span class=md-ellipsis> spark.sql.leafNodeDefaultParallelism </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydolooseupcast class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.doLooseUpcast </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycteprecedencepolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.ctePrecedencePolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytimeparserpolicy class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.timeParserPolicy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfollowthreevaluedlogicinarrayexists class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.followThreeValuedLogicInArrayExists </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyfromdaytimestringenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.fromDayTimeString.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacynotreserveproperties class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.notReserveProperties </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyaddsinglefileinaddfile class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.addSingleFileInAddFile </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyexponentliteralasdecimalenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.exponentLiteralAsDecimal.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallownegativescaleofdecimal class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowNegativeScaleOfDecimal </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacybucketedtablescanoutputordering class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.bucketedTableScan.outputOrdering </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyjsonallowemptystringenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.json.allowEmptyString.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacycreateemptycollectionusingstringtype class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.createEmptyCollectionUsingStringType </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowuntypedscalaudf class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowUntypedScalaUDF </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacydatasetnamenonstructgroupingkeyasvalue class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacysetcommandrejectssparkcoreconfs class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.setCommandRejectsSparkCoreConfs </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacytypecoerciondatetimetostringenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.typeCoercion.datetimeToString.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyallowhashonmaptype class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.allowHashOnMapType </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.parquet.datetimeRebaseModeInWrite </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyparquetdatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.parquet.datetimeRebaseModeInRead </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.avro.datetimeRebaseModeInWrite </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyavrodatetimerebasemodeinread class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.avro.datetimeRebaseModeInRead </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyrddapplyconf class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.rdd.applyConf </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllegacyreplacedatabrickssparkavroenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.legacy.replaceDatabricksSparkAvro.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqllimitscaleupfactor class=md-nav__link> <span class=md-ellipsis> spark.sql.limit.scaleUpFactor </span> </a> </li> <li class=md-nav__item> <a href=#sparksqloptimizenullawareantijoin class=md-nav__link> <span class=md-ellipsis> spark.sql.optimizeNullAwareAntiJoin </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlorcimpl class=md-nav__link> <span class=md-ellipsis> spark.sql.orc.impl </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangeloglevel class=md-nav__link> <span class=md-ellipsis> spark.sql.planChangeLog.level </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogbatches class=md-nav__link> <span class=md-ellipsis> spark.sql.planChangeLog.batches </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlplanchangelogrules class=md-nav__link> <span class=md-ellipsis> spark.sql.planChangeLog.rules </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpysparkjvmstacktraceenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.pyspark.jvmStacktrace.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetbinaryasstring class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.binaryAsString </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetcolumnarreaderbatchsize class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.columnarReaderBatchSize </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetcompressioncodec class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.compression.codec </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetenablevectorizedreader class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.enableVectorizedReader </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdown class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndate class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.date </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowndecimal class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.decimal </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96rebasemodeinwrite class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.int96RebaseModeInWrite </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetpushdowninfilterthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.pushdown.inFilterThreshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdownstringstartswith class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.string.startsWith </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetfilterpushdowntimestamp class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.filterPushdown.timestamp </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96astimestamp class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.int96AsTimestamp </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetint96timestampconversion class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.int96TimestampConversion </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetmergeschema class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.mergeSchema </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetoutputcommitterclass class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.output.committer.class </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetoutputtimestamptype class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.outputTimestampType </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrecordlevelfilterenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.recordLevelFilter.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparquetrespectsummaryfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.parquet.respectSummaryFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlparserquotedregexcolumnnames class=md-nav__link> <span class=md-ellipsis> spark.sql.parser.quotedRegexColumnNames </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlpivotmaxvalues class=md-nav__link> <span class=md-ellipsis> spark.sql.pivotMaxValues </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionoptionsregex class=md-nav__link> <span class=md-ellipsis> spark.sql.redaction.options.regex </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlredactionstringregex class=md-nav__link> <span class=md-ellipsis> spark.sql.redaction.string.regex </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlretaingroupcolumns class=md-nav__link> <span class=md-ellipsis> spark.sql.retainGroupColumns </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlrunsqlonfiles class=md-nav__link> <span class=md-ellipsis> spark.sql.runSQLOnFiles </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlselfjoinautoresolveambiguity class=md-nav__link> <span class=md-ellipsis> spark.sql.selfJoinAutoResolveAmbiguity </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsortenableradixsort class=md-nav__link> <span class=md-ellipsis> spark.sql.sort.enableRadixSort </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesbucketingenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.bucketing.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesdefault class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.default </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsfallbacktohdfs class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.fallBackToHdfs </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticshistogramnumbins class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.histogram.numBins </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsparallelfilelistinginstatscomputationenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.statisticsparallelFileListingInStatsComputation.enabled* </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticsndvmaxerror class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.ndv.maxError </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticspercentileaccuracy class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.percentile.accuracy </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlstatisticssizeautoupdateenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.statistics.size.autoUpdate.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsubexpressioneliminationenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.subexpressionElimination.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlshufflepartitions class=md-nav__link> <span class=md-ellipsis> spark.sql.shuffle.partitions </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcesfilecompressionfactor class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.fileCompressionFactor </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlsourcespartitionoverwritemode class=md-nav__link> <span class=md-ellipsis> spark.sql.sources.partitionOverwriteMode </span> </a> </li> <li class=md-nav__item> <a href=#sparksqltruncatetableignorepermissionaclenabled class=md-nav__link> <span class=md-ellipsis> spark.sql.truncateTable.ignorePermissionAcl.enabled </span> </a> </li> <li class=md-nav__item> <a href=#sparksqluiretainedexecutions class=md-nav__link> <span class=md-ellipsis> spark.sql.ui.retainedExecutions </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlvariablesubstitute class=md-nav__link> <span class=md-ellipsis> spark.sql.variable.substitute </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferinmemorythreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.windowExec.buffer.in.memory.threshold </span> </a> </li> <li class=md-nav__item> <a href=#sparksqlwindowexecbufferspillthreshold class=md-nav__link> <span class=md-ellipsis> spark.sql.windowExec.buffer.spill.threshold </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=configuration-properties>Configuration Properties<a class=headerlink href=#configuration-properties title="Permanent link">&para;</a></h1> <p><strong>Configuration properties</strong> (aka <strong>settings</strong>) allow you to fine-tune a Spark SQL application.</p> <p>Configuration properties are configured in a <a href=../SparkSession/ >SparkSession</a> while creating a new instance using <a href=../SparkSession-Builder/#config>config</a> method (e.g. <a href=../StaticSQLConf/#spark.sql.warehouse.dir>spark.sql.warehouse.dir</a>).</p> <div class=highlight><pre><span></span><code><span class=k>import</span><span class=w> </span><span class=nn>org</span><span class=p>.</span><span class=nn>apache</span><span class=p>.</span><span class=nn>spark</span><span class=p>.</span><span class=nn>sql</span><span class=p>.</span><span class=nc>SparkSession</span>
<span class=kd>val</span><span class=w> </span><span class=n>spark</span><span class=p>:</span><span class=w> </span><span class=nc>SparkSession</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=nc>SparkSession</span><span class=p>.</span><span class=n>builder</span>
<span class=w>  </span><span class=p>.</span><span class=n>master</span><span class=p>(</span><span class=s>&quot;local[*]&quot;</span><span class=p>)</span>
<span class=w>  </span><span class=p>.</span><span class=n>appName</span><span class=p>(</span><span class=s>&quot;My Spark Application&quot;</span><span class=p>)</span>
<span class=w>  </span><span class=p>.</span><span class=n>config</span><span class=p>(</span><span class=s>&quot;spark.sql.warehouse.dir&quot;</span><span class=p>,</span><span class=w> </span><span class=s>&quot;c:/Temp&quot;</span><span class=p>)</span><span class=w> </span><span class=c1>// &lt;1&gt;</span>
<span class=w>  </span><span class=p>.</span><span class=n>getOrCreate</span>
</code></pre></div> <p>You can also set a property using SQL <code>SET</code> command.</p> <div class=highlight><pre><span></span><code>assert(spark.conf.getOption(&quot;spark.sql.hive.metastore.version&quot;).isEmpty)

scala&gt; spark.sql(&quot;SET spark.sql.hive.metastore.version=2.3.2&quot;).show(truncate = false)
+--------------------------------+-----+
|key                             |value|
+--------------------------------+-----+
|spark.sql.hive.metastore.version|2.3.2|
+--------------------------------+-----+

assert(spark.conf.get(&quot;spark.sql.hive.metastore.version&quot;) == &quot;2.3.2&quot;)
</code></pre></div> <h2 id=optimizercanchangecachedplanoutputpartitioning><span id=spark.sql.optimizer.canChangeCachedPlanOutputPartitioning> optimizer.canChangeCachedPlanOutputPartitioning<a class=headerlink href=#optimizercanchangecachedplanoutputpartitioning title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.canChangeCachedPlanOutputPartitioning</strong></p> <p><strong>(internal)</strong> Whether to forcibly enable some optimization rules that can change the output partitioning of a cached query when executing it for caching. If it is set to true, queries may need an extra shuffle to read the cached data. This configuration is disabled by default. Currently, the optimization rules enabled by this configuration are <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> and <a href=#spark.sql.sources.bucketing.autoBucketedScan.enabled>spark.sql.sources.bucketing.autoBucketedScan.enabled</a>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#CAN_CHANGE_CACHED_PLAN_OUTPUT_PARTITIONING>SQLConf.CAN_CHANGE_CACHED_PLAN_OUTPUT_PARTITIONING</a> to access the property</p> <h2 id=optimizerdecorrelateinnerqueryenabled><span id=spark.sql.optimizer.decorrelateInnerQuery.enabled> optimizer.decorrelateInnerQuery.enabled<a class=headerlink href=#optimizerdecorrelateinnerqueryenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.decorrelateInnerQuery.enabled</strong></p> <p><strong>(internal)</strong> Decorrelates inner queries by eliminating correlated references and build domain joins</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#decorrelateInnerQueryEnabled>SQLConf.decorrelateInnerQueryEnabled</a> for the current value</p> <h2 id=optimizerdynamicpartitionpruningfallbackfilterratio><span id=spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio> optimizer.dynamicPartitionPruning.fallbackFilterRatio<a class=headerlink href=#optimizerdynamicpartitionpruningfallbackfilterratio title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.fallbackFilterRatio</strong></p> <p><strong>(internal)</strong> When statistics are not available or configured not to be used, this config will be used as the fallback filter ratio for computing the data size of the partitioned table after dynamic partition pruning, in order to evaluate if it is worth adding an extra subquery as the pruning filter if broadcast reuse is not applicable.</p> <p>Default: <code>0.5</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningFallbackFilterRatio>SQLConf.dynamicPartitionPruningFallbackFilterRatio</a> method to access the current value.</p> <h2 id=optimizerdynamicpartitionpruningpruningsideextrafilterratio><span id=spark.sql.optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio> optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio<a class=headerlink href=#optimizerdynamicpartitionpruningpruningsideextrafilterratio title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.pruningSideExtraFilterRatio</strong></p> <p><strong>(internal)</strong> When filtering side doesn't support broadcast by join type, and doing DPP means running an extra query that may have significant overhead. This config will be used as the extra filter ratio for computing the data size of the pruning side after DPP, in order to evaluate if it is worth adding an extra subquery as the pruning filter.</p> <p>Must be a double between <code>0.0</code> and <code>1.0</code></p> <p>Default: <code>0.04</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningPruningSideExtraFilterRatio>SQLConf.dynamicPartitionPruningPruningSideExtraFilterRatio</a> to access the current value.</p> <h2 id=optimizerdynamicpartitionpruningusestats><span id=spark.sql.optimizer.dynamicPartitionPruning.useStats> optimizer.dynamicPartitionPruning.useStats<a class=headerlink href=#optimizerdynamicpartitionpruningusestats title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.useStats</strong></p> <p><strong>(internal)</strong> When true, distinct count statistics will be used for computing the data size of the partitioned table after dynamic partition pruning, in order to evaluate if it is worth adding an extra subquery as the pruning filter if broadcast reuse is not applicable.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningUseStats>SQLConf.dynamicPartitionPruningUseStats</a> method to access the current value.</p> <h2 id=optimizerdynamicpartitionpruningenabled><span id=spark.sql.optimizer.dynamicPartitionPruning.enabled> optimizer.dynamicPartitionPruning.enabled<a class=headerlink href=#optimizerdynamicpartitionpruningenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.enabled</strong></p> <p>When <code>true</code>, Spark SQL will generate predicate for partition column used as a join key.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningEnabled>SQLConf.dynamicPartitionPruningEnabled</a> to access the current value.</p> <h2 id=optimizerdynamicpartitionpruningreusebroadcastonly><span id=spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly> optimizer.dynamicPartitionPruning.reuseBroadcastOnly<a class=headerlink href=#optimizerdynamicpartitionpruningreusebroadcastonly title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly</strong></p> <p><strong>(internal)</strong> When true, dynamic partition pruning will only apply when the broadcast exchange of a broadcast hash join operation can be reused as the dynamic pruning filter.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningReuseBroadcastOnly>SQLConf.dynamicPartitionPruningReuseBroadcastOnly</a> method to access the current value.</p> <h2 id=optimizerenablecsvexpressionoptimization><span id=spark.sql.optimizer.enableCsvExpressionOptimization> optimizer.enableCsvExpressionOptimization<a class=headerlink href=#optimizerenablecsvexpressionoptimization title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.enableCsvExpressionOptimization</strong></p> <p>Whether to optimize CSV expressions in SQL optimizer. It includes pruning unnecessary columns from <code>from_csv</code>.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#csvExpressionOptimization>SQLConf.csvExpressionOptimization</a> for the current value</p> <h2 id=optimizerexcludedrules><span id=spark.sql.optimizer.excludedRules> optimizer.excludedRules<a class=headerlink href=#optimizerexcludedrules title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.excludedRules</strong></p> <p>Comma-separated list of fully-qualified class names of the optimization rules that should be disabled (excluded) from <a href=../catalyst/Optimizer/#spark.sql.optimizer.excludedRules>logical query optimization</a>.</p> <p>Default: <code>(empty)</code></p> <p>Use <a href=../SQLConf/#optimizerExcludedRules>SQLConf.optimizerExcludedRules</a> method to access the current value.</p> <div class="admonition important"> <p class=admonition-title>Important</p> <p>It is not guaranteed that all the rules to be excluded will eventually be excluded, as some rules are <a href=../catalyst/Optimizer/#nonExcludableRules>non-excludable</a>.</p> </div> <h2 id=optimizerexpressionnestedpruningenabled><span id=spark.sql.optimizer.expression.nestedPruning.enabled> optimizer.expression.nestedPruning.enabled<a class=headerlink href=#optimizerexpressionnestedpruningenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.expression.nestedPruning.enabled</strong></p> <p><strong>(internal)</strong> Prune nested fields from expressions in an operator which are unnecessary in satisfying a query. Note that this optimization doesn't prune nested fields from physical data source scanning. For pruning nested fields from scanning, please use <a href=#spark.sql.optimizer.nestedSchemaPruning.enabled>spark.sql.optimizer.nestedSchemaPruning.enabled</a> config.</p> <p>Default: <code>true</code></p> <h2 id=optimizerinsetconversionthreshold><span id=spark.sql.optimizer.inSetConversionThreshold> optimizer.inSetConversionThreshold<a class=headerlink href=#optimizerinsetconversionthreshold title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.inSetConversionThreshold</strong></p> <p><strong>(internal)</strong> The threshold of set size for <code>InSet</code> conversion.</p> <p>Default: <code>10</code></p> <p>Use <a href=../SQLConf/#optimizerInSetConversionThreshold>SQLConf.optimizerInSetConversionThreshold</a> method to access the current value.</p> <h2 id=optimizerinsetswitchthreshold><span id=spark.sql.optimizer.inSetSwitchThreshold> optimizer.inSetSwitchThreshold<a class=headerlink href=#optimizerinsetswitchthreshold title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.inSetSwitchThreshold</strong></p> <p><strong>(internal)</strong> Configures the max set size in InSet for which Spark will generate code with switch statements. This is applicable only to bytes, shorts, ints, dates.</p> <p>Must be non-negative and less than or equal to 600.</p> <p>Default: <code>400</code></p> <h2 id=optimizermaxiterations><span id=spark.sql.optimizer.maxIterations> optimizer.maxIterations<a class=headerlink href=#optimizermaxiterations title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.maxIterations</strong></p> <p>Maximum number of iterations for <a href=../Analyzer/#fixedPoint>Analyzer</a> and <a href=../catalyst/Optimizer/#fixedPoint>Logical Optimizer</a>.</p> <p>Default: <code>100</code></p> <h2 id=optimizernestedschemapruningenabled><span id=spark.sql.optimizer.nestedSchemaPruning.enabled> optimizer.nestedSchemaPruning.enabled<a class=headerlink href=#optimizernestedschemapruningenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.nestedSchemaPruning.enabled</strong></p> <p><strong>(internal)</strong> Prune nested fields from the output of a logical relation that are not necessary in satisfying a query. This optimization allows columnar file format readers to avoid reading unnecessary nested column data.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#nestedSchemaPruningEnabled>SQLConf.nestedSchemaPruningEnabled</a> method to access the current value.</p> <h2 id=optimizernestedpredicatepushdownsupportedfilesources><span id=spark.sql.optimizer.nestedPredicatePushdown.supportedFileSources> optimizer.nestedPredicatePushdown.supportedFileSources<a class=headerlink href=#optimizernestedpredicatepushdownsupportedfilesources title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.nestedPredicatePushdown.supportedFileSources</strong></p> <p><strong>(internal)</strong> A comma-separated list of data source short names or fully qualified data source implementation class names for which Spark tries to push down predicates for nested columns and/or names containing <code>dots</code> to data sources. This configuration is only effective with file-based data source in DSv1. Currently, Parquet implements both optimizations while ORC only supports predicates for names containing <code>dots</code>. The other data sources don't support this feature yet.</p> <p>Default: <code>parquet,orc</code></p> <h2 id=optimizeroptimizeonerowrelationsubquery><span id=spark.sql.optimizer.optimizeOneRowRelationSubquery> optimizer.optimizeOneRowRelationSubquery<a class=headerlink href=#optimizeroptimizeonerowrelationsubquery title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.optimizeOneRowRelationSubquery</strong></p> <p><strong>(internal)</strong> When <code>true</code>, the optimizer will inline subqueries with <code>OneRowRelation</code> leaf nodes</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#OPTIMIZE_ONE_ROW_RELATION_SUBQUERY>SQLConf.OPTIMIZE_ONE_ROW_RELATION_SUBQUERY</a> method to access the property (in a type-safe way)</p> <h2 id=optimizerplanchangelogbatches><span id=spark.sql.optimizer.planChangeLog.batches> optimizer.planChangeLog.batches<a class=headerlink href=#optimizerplanchangelogbatches title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.planChangeLog.batches</strong></p> <p><strong>(internal)</strong> Configures a list of batches to be logged in the optimizer, in which the batches are specified by their batch names and separated by comma.</p> <p>Default: <code>(undefined)</code></p> <h2 id=optimizerplanchangeloglevel><span id=spark.sql.optimizer.planChangeLog.level> optimizer.planChangeLog.level<a class=headerlink href=#optimizerplanchangeloglevel title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.planChangeLog.level</strong></p> <p><strong>(internal)</strong> Configures the log level for logging the change from the original plan to the new plan after a rule or batch is applied. The value can be <code>TRACE</code>, <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code> or <code>ERROR</code>.</p> <p>Default: <code>TRACE</code></p> <h2 id=optimizerplanchangelogrules><span id=spark.sql.optimizer.planChangeLog.rules> optimizer.planChangeLog.rules<a class=headerlink href=#optimizerplanchangelogrules title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.planChangeLog.rules</strong></p> <p><strong>(internal)</strong> Configures a list of rules to be logged in the optimizer, in which the rules are specified by their rule names and separated by comma.</p> <p>Default: <code>(undefined)</code></p> <h2 id=optimizerreplaceexceptwithfilter><span id=spark.sql.optimizer.replaceExceptWithFilter> optimizer.replaceExceptWithFilter<a class=headerlink href=#optimizerreplaceexceptwithfilter title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.replaceExceptWithFilter</strong></p> <p><strong>(internal)</strong> When <code>true</code>, the apply function of the rule verifies whether the right node of the except operation is of type Filter or Project followed by Filter. If yes, the rule further verifies 1) Excluding the filter operations from the right (as well as the left node, if any) on the top, whether both the nodes evaluates to a same result. 2) The left and right nodes don't contain any SubqueryExpressions. 3) The output column names of the left node are distinct. If all the conditions are met, the rule will replace the except operation with a Filter by flipping the filter condition(s) of the right node.</p> <p>Default: <code>true</code></p> <h2 id=optimizerruntimebloomfilterenabled><span id=spark.sql.optimizer.runtime.bloomFilter.enabled> optimizer.runtime.bloomFilter.enabled<a class=headerlink href=#optimizerruntimebloomfilterenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.runtime.bloomFilter.enabled</strong></p> <p>Enables a bloom filter on one side of a shuffle join if the other side has a selective predicate (to reduce the amount of shuffle data)</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#runtimeFilterBloomFilterEnabled>SQLConf.runtimeFilterBloomFilterEnabled</a> for the current value</p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/InjectRuntimeFilter/ >InjectRuntimeFilter</a> logical optimization is executed</li> </ul> <h2 id=optimizerruntimebloomfilterexpectednumitems><span id=spark.sql.optimizer.runtime.bloomFilter.expectedNumItems> optimizer.runtime.bloomFilter.expectedNumItems<a class=headerlink href=#optimizerruntimebloomfilterexpectednumitems title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.runtime.bloomFilter.expectedNumItems</strong></p> <p>The default number of expected items for the runtime bloomfilter</p> <p>Default: <code>1000000L</code></p> <p><a href=../SQLConf/#RUNTIME_BLOOM_FILTER_EXPECTED_NUM_ITEMS>SQLConf.RUNTIME_BLOOM_FILTER_EXPECTED_NUM_ITEMS</a></p> <p>Used when:</p> <ul> <li><a href=../expressions/BloomFilterAggregate/#estimatedNumItemsExpression>BloomFilterAggregate</a> expression is created</li> </ul> <h2 id=optimizerruntimebloomfiltermaxnumbits><span id=spark.sql.optimizer.runtime.bloomFilter.maxNumBits> optimizer.runtime.bloomFilter.maxNumBits<a class=headerlink href=#optimizerruntimebloomfiltermaxnumbits title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.runtime.bloomFilter.maxNumBits</strong></p> <p>Maximum number of bits for the runtime bloom filter</p> <p>Default: <code>67108864L</code> (8MB)</p> <p>Must be a <a href=../expressions/BloomFilterAggregate/#checkInputDataTypes>non-zero positive number</a></p> <p><a href=../SQLConf/#RUNTIME_BLOOM_FILTER_MAX_NUM_BITS>SQLConf.RUNTIME_BLOOM_FILTER_MAX_NUM_BITS</a></p> <p>Used when:</p> <ul> <li><code>BloomFilterAggregate</code> is requested to <a href=../expressions/BloomFilterAggregate/#checkInputDataTypes>checkInputDataTypes</a> and for the <a href=../expressions/BloomFilterAggregate/#numBits>numBits</a></li> </ul> <h2 id=optimizerruntimefilternumberthreshold><span id=spark.sql.optimizer.runtimeFilter.number.threshold> optimizer.runtimeFilter.number.threshold<a class=headerlink href=#optimizerruntimefilternumberthreshold title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.runtimeFilter.number.threshold</strong></p> <p>The total number of injected runtime filters (non-DPP) for a single query. This is to prevent driver OOMs with too many Bloom filters.</p> <p>Default: <code>10</code></p> <p>Must be a non-zero positive number</p> <p><a href=../SQLConf/#RUNTIME_FILTER_NUMBER_THRESHOLD>SQLConf.RUNTIME_FILTER_NUMBER_THRESHOLD</a></p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/InjectRuntimeFilter/ >InjectRuntimeFilter</a> logical optimization is executed</li> </ul> <h2 id=optimizerruntimefiltersemijoinreductionenabled><span id=spark.sql.optimizer.runtimeFilter.semiJoinReduction.enabled> optimizer.runtimeFilter.semiJoinReduction.enabled<a class=headerlink href=#optimizerruntimefiltersemijoinreductionenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.runtimeFilter.semiJoinReduction.enabled</strong></p> <p>Enables inserting a semi join on one side of a shuffle join if the other side has a selective predicate (to reduce the amount of shuffle data)</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#runtimeFilterSemiJoinReductionEnabled>SQLConf.runtimeFilterSemiJoinReductionEnabled</a> for the current value</p> <p>Used when:</p> <ul> <li><a href=../logical-optimizations/InjectRuntimeFilter/ >InjectRuntimeFilter</a> logical optimization is executed</li> </ul> <h2 id=optimizerserializernestedschemapruningenabled><span id=spark.sql.optimizer.serializer.nestedSchemaPruning.enabled> optimizer.serializer.nestedSchemaPruning.enabled<a class=headerlink href=#optimizerserializernestedschemapruningenabled title="Permanent link">&para;</a></h2> <p><strong>spark.sql.optimizer.serializer.nestedSchemaPruning.enabled</strong></p> <p><strong>(internal)</strong> Prune nested fields from object serialization operator which are unnecessary in satisfying a query. This optimization allows object serializers to avoid executing unnecessary nested expressions.</p> <p>Default: <code>true</code></p> <h2 id=sparksqladaptiveautobroadcastjointhreshold><span id=spark.sql.adaptive.autoBroadcastJoinThreshold> spark.sql.adaptive.autoBroadcastJoinThreshold<a class=headerlink href=#sparksqladaptiveautobroadcastjointhreshold title="Permanent link">&para;</a></h2> <p>The maximum size (in bytes) of a table to be broadcast when performing a join. <code>-1</code> turns broadcasting off. The default value is same as <a href=#spark.sql.autoBroadcastJoinThreshold>spark.sql.autoBroadcastJoinThreshold</a>.</p> <p>Used only in <a href=../adaptive-query-execution/ >Adaptive Query Execution</a></p> <p>Default: (undefined)</p> <p>Available as <a href=../SQLConf/#ADAPTIVE_AUTO_BROADCASTJOIN_THRESHOLD>SQLConf.ADAPTIVE_AUTO_BROADCASTJOIN_THRESHOLD</a> value.</p> <h2 id=sparksqladaptivecustomcostevaluatorclass><span id=spark.sql.adaptive.customCostEvaluatorClass> spark.sql.adaptive.customCostEvaluatorClass<a class=headerlink href=#sparksqladaptivecustomcostevaluatorclass title="Permanent link">&para;</a></h2> <p>The fully-qualified class name of a custom <a href=../adaptive-query-execution/CostEvaluator/ >CostEvaluator</a> for <a href=../adaptive-query-execution/ >Adaptive Query Execution</a></p> <p>Default: <a href=../adaptive-query-execution/SimpleCostEvaluator/ >SimpleCostEvaluator</a></p> <p>Use <a href=../SQLConf/#ADAPTIVE_CUSTOM_COST_EVALUATOR_CLASS>SQLConf.ADAPTIVE_CUSTOM_COST_EVALUATOR_CLASS</a> method to access the property (in a type-safe way).</p> <h2 id=sparksqlobjecthashaggregatesortbasedfallbackthreshold><span id=spark.sql.objectHashAggregate.sortBased.fallbackThreshold> spark.sql.objectHashAggregate.sortBased.fallbackThreshold<a class=headerlink href=#sparksqlobjecthashaggregatesortbasedfallbackthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The number of entires in an in-memory hash map (to store aggregation buffers per grouping keys) before <a href=../physical-operators/ObjectHashAggregateExec/ >ObjectHashAggregateExec</a> (<a href=../physical-operators/ObjectAggregationIterator/#processInputs>ObjectAggregationIterator</a>, precisely) falls back to sort-based aggregation</p> <p>Default: <code>128</code> (entries)</p> <p>Use <a href=../SQLConf/#objectAggSortBasedFallbackThreshold>SQLConf.objectAggSortBasedFallbackThreshold</a> for the current value</p> <p>Learn more in <a href=../demo/objecthashaggregateexec-sort-based-fallback-tasks/ >Demo: ObjectHashAggregateExec and Sort-Based Fallback Tasks</a></p> <h2 id=sparksqladaptiveoptimizeskewsinrebalancepartitionsenabled><span id=spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled> spark.sql.adaptive.optimizeSkewsInRebalancePartitions.enabled<a class=headerlink href=#sparksqladaptiveoptimizeskewsinrebalancepartitionsenabled title="Permanent link">&para;</a></h2> <p>When <code>true</code> and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is <code>true</code>, Spark SQL will optimize the skewed shuffle partitions in RebalancePartitions and split them to smaller ones according to the target size (specified by <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a>), to avoid data skew</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#ADAPTIVE_OPTIMIZE_SKEWS_IN_REBALANCE_PARTITIONS_ENABLED>SQLConf.ADAPTIVE_OPTIMIZE_SKEWS_IN_REBALANCE_PARTITIONS_ENABLED</a> method to access the property (in a type-safe way)</p> <h2 id=sparksqlcodegenaggregatefasthashmapcapacitybit><span id=spark.sql.codegen.aggregate.fastHashMap.capacityBit> spark.sql.codegen.aggregate.fastHashMap.capacityBit<a class=headerlink href=#sparksqlcodegenaggregatefasthashmapcapacitybit title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Capacity for the max number of rows to be held in memory by the fast hash aggregate product operator. The bit is not for actual value, but the actual <code>numBuckets</code> is determined by <code>loadFactor</code> (e.g., the default bit value <code>16</code>, the actual numBuckets is <code>((1 &lt;&lt; 16) / 0.5</code>).</p> <p>Default: <code>16</code></p> <p>Must be in the range of <code>[10, 30]</code> (inclusive)</p> <p>Use <a href=../SQLConf/#fastHashAggregateRowMaxCapacityBit>SQLConf.fastHashAggregateRowMaxCapacityBit</a> for the current value</p> <p>Used when:</p> <ul> <li><code>HashAggregateExec</code> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#doProduceWithKeys>doProduceWithKeys</a></li> </ul> <h2 id=sparksqlcodegenaggregatemaptwolevelenabled><span id=spark.sql.codegen.aggregate.map.twolevel.enabled> spark.sql.codegen.aggregate.map.twolevel.enabled<a class=headerlink href=#sparksqlcodegenaggregatemaptwolevelenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enable two-level aggregate hash map. When enabled, records will first be inserted/looked-up at a 1<sup>st</sup>-level, small, fast map, and then fallback to a 2<sup>nd</sup>-level, larger, slower map when 1<sup>st</sup> level is full or keys cannot be found. When disabled, records go directly to the 2<sup>nd</sup> level.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#enableTwoLevelAggMap>SQLConf.enableTwoLevelAggMap</a> for the current value</p> <p>Used when:</p> <ul> <li><code>HashAggregateExec</code> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#doProduceWithKeys>doProduceWithKeys</a></li> </ul> <h2 id=sparksqlcodegenaggregatemapvectorizedenable><span id=spark.sql.codegen.aggregate.map.vectorized.enable> spark.sql.codegen.aggregate.map.vectorized.enable<a class=headerlink href=#sparksqlcodegenaggregatemapvectorizedenable title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables vectorized aggregate hash map. For testing/benchmarking only.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#enableVectorizedHashMap>SQLConf.enableVectorizedHashMap</a> for the current value</p> <p>Used when:</p> <ul> <li><code>HashAggregateExec</code> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#enableTwoLevelHashMap>enableTwoLevelHashMap</a>, <a href=../physical-operators/HashAggregateExec/#doProduceWithKeys>doProduceWithKeys</a></li> </ul> <h2 id=sparksqlcodegenaggregatemaptwolevelpartialonly><span id=spark.sql.codegen.aggregate.map.twolevel.partialOnly> spark.sql.codegen.aggregate.map.twolevel.partialOnly<a class=headerlink href=#sparksqlcodegenaggregatemaptwolevelpartialonly title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables two-level aggregate hash map for partial aggregate only, because final aggregate might get more distinct keys compared to partial aggregate. "Overhead of looking up 1<sup>st</sup>-level map might dominate when having a lot of distinct keys.</p> <p>Default: <code>true</code></p> <p>Used when:</p> <ul> <li><a href=../physical-operators/HashAggregateExec/ >HashAggregateExec</a> physical operator is requested to <a href=../physical-operators/HashAggregateExec/#checkIfFastHashMapSupported>checkIfFastHashMapSupported</a></li> </ul> <h2 id=sparksqllegacyallownonemptylocationinctas><span id=spark.sql.legacy.allowNonEmptyLocationInCTAS> spark.sql.legacy.allowNonEmptyLocationInCTAS<a class=headerlink href=#sparksqllegacyallownonemptylocationinctas title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>false</code>, CTAS with LOCATION throws an analysis exception if the location is not empty.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#allowNonEmptyLocationInCTAS>SQLConf.allowNonEmptyLocationInCTAS</a> for the current value</p> <h2 id=sparksqllegacyallowautogeneratedaliasforview><span id=spark.sql.legacy.allowAutoGeneratedAliasForView> spark.sql.legacy.allowAutoGeneratedAliasForView<a class=headerlink href=#sparksqllegacyallowautogeneratedaliasforview title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, it's allowed to use an input query without explicit alias when creating a permanent view.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#allowAutoGeneratedAliasForView>SQLConf.allowAutoGeneratedAliasForView</a> for the current value</p> <h2 id=sparksqlsessionwindowbufferspillthreshold><span id=spark.sql.sessionWindow.buffer.spill.threshold> spark.sql.sessionWindow.buffer.spill.threshold<a class=headerlink href=#sparksqlsessionwindowbufferspillthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The threshold for number of rows to be spilled by window operator. Note that the buffer is used only for the query Spark SQL cannot apply aggregations on determining session window.</p> <p>Default: <a href=#spark.shuffle.spill.numElementsForceSpillThreshold>spark.shuffle.spill.numElementsForceSpillThreshold</a></p> <p>Use <a href=../SQLConf/#sessionWindowBufferSpillThreshold>SQLConf.sessionWindowBufferSpillThreshold</a> for the current value</p> <h2 id=sparksqlexecutionarrowpysparkselfdestructenabled><span id=spark.sql.execution.arrow.pyspark.selfDestruct.enabled> spark.sql.execution.arrow.pyspark.selfDestruct.enabled<a class=headerlink href=#sparksqlexecutionarrowpysparkselfdestructenabled title="Permanent link">&para;</a></h2> <p>(Experimental) When <code>true</code>, make use of Apache Arrow's self-destruct and split-blocks options for columnar data transfers in PySpark, when converting from Arrow to Pandas. This reduces memory usage at the cost of some CPU time. Applies to: <code>pyspark.sql.DataFrame.toPandas</code> when <a href=#spark.sql.execution.arrow.pyspark.enabled>spark.sql.execution.arrow.pyspark.enabled</a> is <code>true</code>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#arrowPySparkSelfDestructEnabled>SQLConf.arrowPySparkSelfDestructEnabled</a> for the current value</p> <h2 id=sparksqllegacyallowstarwithsingletableidentifierincount><span id=spark.sql.legacy.allowStarWithSingleTableIdentifierInCount> spark.sql.legacy.allowStarWithSingleTableIdentifierInCount<a class=headerlink href=#sparksqllegacyallowstarwithsingletableidentifierincount title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the SQL function <code>count</code> is allowed to take a single <code>tblName.*</code> as parameter</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#allowStarWithSingleTableIdentifierInCount>SQLConf.allowStarWithSingleTableIdentifierInCount</a> for the current value</p> <h2 id=sparksqlsessionwindowbufferinmemorythreshold><span id=spark.sql.sessionWindow.buffer.in.memory.threshold> spark.sql.sessionWindow.buffer.in.memory.threshold<a class=headerlink href=#sparksqlsessionwindowbufferinmemorythreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Threshold for number of windows guaranteed to be held in memory by the session window operator. Note that the buffer is used only for the query Spark SQL cannot apply aggregations on determining session window.</p> <p>Default: <code>4096</code></p> <p>Use <a href=../SQLConf/#sessionWindowBufferInMemoryThreshold>SQLConf.sessionWindowBufferInMemoryThreshold</a> for the current value</p> <h2 id=sparksqlorcenablenestedcolumnvectorizedreader><span id=spark.sql.orc.enableNestedColumnVectorizedReader> spark.sql.orc.enableNestedColumnVectorizedReader<a class=headerlink href=#sparksqlorcenablenestedcolumnvectorizedreader title="Permanent link">&para;</a></h2> <p>Enables vectorized orc decoding for nested column</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#orcVectorizedReaderNestedColumnEnabled>SQLConf.orcVectorizedReaderNestedColumnEnabled</a> for the current value</p> <h2 id=sparksqladaptiveforceapply><span id=spark.sql.adaptive.forceApply> spark.sql.adaptive.forceApply<a class=headerlink href=#sparksqladaptiveforceapply title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code> (together with <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> enabled), Spark will <a href=../physical-optimizations/InsertAdaptiveSparkPlan/#shouldApplyAQE>force apply adaptive query execution for all supported queries</a>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#ADAPTIVE_EXECUTION_FORCE_APPLY>SQLConf.ADAPTIVE_EXECUTION_FORCE_APPLY</a> method to access the property (in a type-safe way).</p> <h2 id=sparksqladaptivecoalescepartitionsenabled><span id=spark.sql.adaptive.coalescePartitions.enabled> spark.sql.adaptive.coalescePartitions.enabled<a class=headerlink href=#sparksqladaptivecoalescepartitionsenabled title="Permanent link">&para;</a></h2> <p>Controls coalescing shuffle partitions</p> <p>When <code>true</code> and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is enabled, Spark will coalesce contiguous shuffle partitions according to the target size (specified by <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a>), to avoid too many small tasks.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#coalesceShufflePartitionsEnabled>SQLConf.coalesceShufflePartitionsEnabled</a> method to access the current value.</p> <h2 id=sparksqladaptivecoalescepartitionsminpartitionsize><span id=spark.sql.adaptive.coalescePartitions.minPartitionSize> spark.sql.adaptive.coalescePartitions.minPartitionSize<a class=headerlink href=#sparksqladaptivecoalescepartitionsminpartitionsize title="Permanent link">&para;</a></h2> <p>The minimum size (in bytes unless specified) of shuffle partitions after coalescing. This is useful when the adaptively calculated target size is too small during partition coalescing</p> <p>Default: <code>1MB</code></p> <p>Use <a href=../SQLConf/#coalesceShufflePartitionsEnabled>SQLConf.coalesceShufflePartitionsEnabled</a> method to access the current value.</p> <h2 id=sparksqladaptivecoalescepartitionsparallelismfirst><span id=spark.sql.adaptive.coalescePartitions.parallelismFirst> spark.sql.adaptive.coalescePartitions.parallelismFirst<a class=headerlink href=#sparksqladaptivecoalescepartitionsparallelismfirst title="Permanent link">&para;</a></h2> <p>When <code>true</code>, Spark does not respect the target size specified by <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a> when coalescing contiguous shuffle partitions, but adaptively calculate the target size according to the default parallelism of the Spark cluster. The calculated size is usually smaller than the configured target size. This is to maximize the parallelism and avoid performance regression when enabling adaptive query execution. It's recommended to set this config to <code>false</code> and respect the configured target size.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#coalesceShufflePartitionsEnabled>SQLConf.coalesceShufflePartitionsEnabled</a> method to access the current value.</p> <h2 id=sparksqladaptiveadvisorypartitionsizeinbytes><span id=spark.sql.adaptive.advisoryPartitionSizeInBytes> spark.sql.adaptive.advisoryPartitionSizeInBytes<a class=headerlink href=#sparksqladaptiveadvisorypartitionsizeinbytes title="Permanent link">&para;</a></h2> <p>The advisory size in bytes of the shuffle partition during adaptive optimization (when <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is enabled). It takes effect when Spark coalesces small shuffle partitions or splits skewed shuffle partition.</p> <p>Default: <code>64MB</code></p> <p>Fallback Property: <code>spark.sql.adaptive.shuffle.targetPostShuffleInputSize</code></p> <p>Use <a href=../SQLConf/#ADVISORY_PARTITION_SIZE_IN_BYTES>SQLConf.ADVISORY_PARTITION_SIZE_IN_BYTES</a> to reference the name.</p> <h2 id=sparksqladaptivecoalescepartitionsminpartitionsize_1><span id=spark.sql.adaptive.coalescePartitions.minPartitionSize><span id=COALESCE_PARTITIONS_MIN_PARTITION_SIZE><span id=COALESCE_PARTITIONS_MIN_PARTITION_NUM> spark.sql.adaptive.coalescePartitions.minPartitionSize<a class=headerlink href=#sparksqladaptivecoalescepartitionsminpartitionsize_1 title="Permanent link">&para;</a></h2> <p>The minimum size (in bytes) of shuffle partitions after coalescing.</p> <p>Useful when the adaptively calculated target size is too small during partition coalescing.</p> <p>Default: <code>(undefined)</code></p> <p>Must be positive</p> <p>Used when:</p> <ul> <li><a href=../physical-optimizations/CoalesceShufflePartitions/ >CoalesceShufflePartitions</a> adaptive physical optimization is executed</li> </ul> <h2 id=sparksqladaptivecoalescepartitionsinitialpartitionnum><span id=spark.sql.adaptive.coalescePartitions.initialPartitionNum> spark.sql.adaptive.coalescePartitions.initialPartitionNum<a class=headerlink href=#sparksqladaptivecoalescepartitionsinitialpartitionnum title="Permanent link">&para;</a></h2> <p>The initial number of shuffle partitions before coalescing.</p> <p>By default it equals to <a href=#spark.sql.shuffle.partitions>spark.sql.shuffle.partitions</a>. If not set, the default value is the default parallelism of the Spark cluster. This configuration only has an effect when <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> and <a href=#spark.sql.adaptive.coalescePartitions.enabled>spark.sql.adaptive.coalescePartitions.enabled</a> are both enabled.</p> <p>Default: <code>(undefined)</code></p> <h2 id=sparksqladaptiveenabled><span id=spark.sql.adaptive.enabled> spark.sql.adaptive.enabled<a class=headerlink href=#sparksqladaptiveenabled title="Permanent link">&para;</a></h2> <p>Enables <a href=../adaptive-query-execution/ >Adaptive Query Execution</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#adaptiveExecutionEnabled>SQLConf.adaptiveExecutionEnabled</a> method to access the current value.</p> <h2 id=sparksqladaptivefetchshuffleblocksinbatch><span id=spark.sql.adaptive.fetchShuffleBlocksInBatch> spark.sql.adaptive.fetchShuffleBlocksInBatch<a class=headerlink href=#sparksqladaptivefetchshuffleblocksinbatch title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Whether to fetch the contiguous shuffle blocks in batch. Instead of fetching blocks one by one, fetching contiguous shuffle blocks for the same map task in batch can reduce IO and improve performance. Note, multiple contiguous blocks exist in single "fetch request only happen when <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> and <a href=#spark.sql.adaptive.coalescePartitions.enabled>spark.sql.adaptive.coalescePartitions.enabled</a> are both enabled. This feature also depends on a relocatable serializer, the concatenation support codec in use and the new version shuffle fetch protocol.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#fetchShuffleBlocksInBatch>SQLConf.fetchShuffleBlocksInBatch</a> method to access the current value.</p> <h2 id=sparksqladaptivelocalshufflereaderenabled><span id=spark.sql.adaptive.localShuffleReader.enabled> spark.sql.adaptive.localShuffleReader.enabled<a class=headerlink href=#sparksqladaptivelocalshufflereaderenabled title="Permanent link">&para;</a></h2> <p>When <code>true</code> (and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is <code>true</code>), Spark SQL tries to use local shuffle reader to read the shuffle data when the shuffle partitioning is not needed, for example, after converting sort-merge join to broadcast-hash join.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#LOCAL_SHUFFLE_READER_ENABLED>SQLConf.LOCAL_SHUFFLE_READER_ENABLED</a> to access the property (in a type-safe way)</p> <h2 id=sparksqladaptiveloglevel><span id=spark.sql.adaptive.logLevel> spark.sql.adaptive.logLevel<a class=headerlink href=#sparksqladaptiveloglevel title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Log level for adaptive execution logging of plan changes. The value can be <code>TRACE</code>, <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code> or <code>ERROR</code>.</p> <p>Default: <code>DEBUG</code></p> <p>Use <a href=../SQLConf/#adaptiveExecutionLogLevel>SQLConf.adaptiveExecutionLogLevel</a> for the current value</p> <h2 id=sparksqladaptivemaxshuffledhashjoinlocalmapthreshold><span id=spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold> spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold<a class=headerlink href=#sparksqladaptivemaxshuffledhashjoinlocalmapthreshold title="Permanent link">&para;</a></h2> <p>The maximum size (in bytes) per partition that can be allowed to build local hash map. If this value is not smaller than <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a> and all the partition size are not larger than this config, join selection prefer to use shuffled hash join instead of sort merge join regardless of the value of <a href=#spark.sql.join.preferSortMergeJoin>spark.sql.join.preferSortMergeJoin</a>.</p> <p>Default: <code>0</code></p> <p>Available as <a href=../SQLConf/#ADAPTIVE_MAX_SHUFFLE_HASH_JOIN_LOCAL_MAP_THRESHOLD>SQLConf.ADAPTIVE_MAX_SHUFFLE_HASH_JOIN_LOCAL_MAP_THRESHOLD</a></p> <h2 id=sparksqladaptiveoptimizerexcludedrules><span id=spark.sql.adaptive.optimizer.excludedRules><span id=ADAPTIVE_OPTIMIZER_EXCLUDED_RULES> spark.sql.adaptive.optimizer.excludedRules<a class=headerlink href=#sparksqladaptiveoptimizerexcludedrules title="Permanent link">&para;</a></h2> <p>A comma-separated list of rules (names) to be disabled in the <a href=../adaptive-query-execution/AQEOptimizer/ >adaptive optimizer</a></p> <p>Default: undefined</p> <p>Use <a href=../SQLConf/#ADAPTIVE_OPTIMIZER_EXCLUDED_RULES>SQLConf.ADAPTIVE_OPTIMIZER_EXCLUDED_RULES</a> to reference the property.</p> <h2 id=sparksqladaptiveskewjoinenabled><span id=spark.sql.adaptive.skewJoin.enabled> spark.sql.adaptive.skewJoin.enabled<a class=headerlink href=#sparksqladaptiveskewjoinenabled title="Permanent link">&para;</a></h2> <p>When <code>true</code> and <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> is enabled, Spark dynamically handles skew in sort-merge join by splitting (and replicating if needed) skewed partitions.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#SKEW_JOIN_ENABLED>SQLConf.SKEW_JOIN_ENABLED</a> to reference the property.</p> <h2 id=sparksqladaptiveskewjoinskewedpartitionfactor><span id=spark.sql.adaptive.skewJoin.skewedPartitionFactor> spark.sql.adaptive.skewJoin.skewedPartitionFactor<a class=headerlink href=#sparksqladaptiveskewjoinskewedpartitionfactor title="Permanent link">&para;</a></h2> <p>A partition is considered skewed if its size is larger than this factor multiplying the median partition size and also larger than <a href=#spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes>spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes</a>.</p> <p>Default: <code>5</code></p> <h2 id=sparksqladaptiveskewjoinskewedpartitionthresholdinbytes><span id=spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes> spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes<a class=headerlink href=#sparksqladaptiveskewjoinskewedpartitionthresholdinbytes title="Permanent link">&para;</a></h2> <p>A partition is considered skewed if its size in bytes is larger than this threshold and also larger than <a href=#spark.sql.adaptive.skewJoin.skewedPartitionFactor>spark.sql.adaptive.skewJoin.skewedPartitionFactor</a> multiplying the median partition size. Ideally this config should be set larger than <a href=#spark.sql.adaptive.advisoryPartitionSizeInBytes>spark.sql.adaptive.advisoryPartitionSizeInBytes</a>.</p> <p>Default: <code>256MB</code></p> <h2 id=sparksqladaptivenonemptypartitionratioforbroadcastjoin><span id=spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin> spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin<a class=headerlink href=#sparksqladaptivenonemptypartitionratioforbroadcastjoin title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> A relation with a non-empty partition ratio (the number of non-empty partitions to all partitions) lower than this config will not be considered as the build side of a broadcast-hash join in <a href=../adaptive-query-execution/ >Adaptive Query Execution</a> regardless of the size.</p> <p>Effective with <a href=#spark.sql.adaptive.enabled>spark.sql.adaptive.enabled</a> <code>true</code></p> <p>Default: <code>0.2</code></p> <p>Use <a href=../SQLConf/#nonEmptyPartitionRatioForBroadcastJoin>SQLConf.nonEmptyPartitionRatioForBroadcastJoin</a> method to access the current value.</p> <h2 id=sparksqlanalyzermaxiterations><span id=spark.sql.analyzer.maxIterations> spark.sql.analyzer.maxIterations<a class=headerlink href=#sparksqlanalyzermaxiterations title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The max number of iterations the analyzer runs.</p> <p>Default: <code>100</code></p> <h2 id=sparksqlanalyzerfailambiguousselfjoin><span id=spark.sql.analyzer.failAmbiguousSelfJoin> spark.sql.analyzer.failAmbiguousSelfJoin<a class=headerlink href=#sparksqlanalyzerfailambiguousselfjoin title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, fail the Dataset query if it contains ambiguous self-join.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlansienabled><span id=spark.sql.ansi.enabled> spark.sql.ansi.enabled<a class=headerlink href=#sparksqlansienabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, Spark tries to conform to the ANSI SQL specification:</p> <ol> <li>Spark will throw a runtime exception if an overflow occurs in any operation on integral/decimal field.</li> <li>Spark will forbid using the reserved keywords of ANSI SQL as identifiers in the SQL parser.</li> </ol> <p>Default: <code>false</code></p> <h2 id=sparksqlcliprintheader><span id=spark.sql.cli.print.header> spark.sql.cli.print.header<a class=headerlink href=#sparksqlcliprintheader title="Permanent link">&para;</a></h2> <p>When <code>true</code>, spark-sql CLI prints the names of the columns in query output</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#cliPrintHeader>SQLConf.cliPrintHeader</a> for the current value</p> <h2 id=sparksqlcodegenwholestage><span id=spark.sql.codegen.wholeStage> spark.sql.codegen.wholeStage<a class=headerlink href=#sparksqlcodegenwholestage title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Whether the whole stage (of multiple physical operators) will be compiled into a single Java method (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageEnabled>SQLConf.wholeStageEnabled</a> method to access the current value.</p> <h2 id=sparksqlcodegenmethodsplitthreshold><span id=spark.sql.codegen.methodSplitThreshold> spark.sql.codegen.methodSplitThreshold<a class=headerlink href=#sparksqlcodegenmethodsplitthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The threshold of source-code splitting in the codegen. When the number of characters in a single Java function (without comment) exceeds the threshold, the function will be automatically split to multiple smaller ones. We cannot know how many bytecode will be generated, so use the code length as metric. When running on HotSpot, a function's bytecode should not go beyond 8KB, otherwise it will not be JITted; it also should not be too small, otherwise there will be many function calls.</p> <p>Default: <code>1024</code></p> <p>Use <a href=../SQLConf/#methodSplitThreshold>SQLConf.methodSplitThreshold</a> for the current value</p> <h2 id=sparksqldebugmaxtostringfields><span id=spark.sql.debug.maxToStringFields> spark.sql.debug.maxToStringFields<a class=headerlink href=#sparksqldebugmaxtostringfields title="Permanent link">&para;</a></h2> <p>Maximum number of fields of sequence-like entries can be converted to strings in debug output. Any elements beyond the limit will be dropped and replaced by a "... N more fields" placeholder.</p> <p>Default: <code>25</code></p> <p>Use <a href=../SQLConf/#maxToStringFields>SQLConf.maxToStringFields</a> method to access the current value.</p> <h2 id=sparksqldefaultcatalog><span id=spark.sql.defaultCatalog> spark.sql.defaultCatalog<a class=headerlink href=#sparksqldefaultcatalog title="Permanent link">&para;</a></h2> <p>Name of the default catalog</p> <p>Default: <a href=../connector/catalog/CatalogManager/#SESSION_CATALOG_NAME>spark_catalog</a></p> <p>Use <a href=../SQLConf/#DEFAULT_CATALOG>SQLConf.DEFAULT_CATALOG</a> to access the current value.</p> <h2 id=sparksqlexecutionarrowpysparkenabled><span id=spark.sql.execution.arrow.pyspark.enabled> spark.sql.execution.arrow.pyspark.enabled<a class=headerlink href=#sparksqlexecutionarrowpysparkenabled title="Permanent link">&para;</a></h2> <p>When true, make use of Apache Arrow for columnar data transfers in PySpark. This optimization applies to:</p> <ol> <li>pyspark.sql.DataFrame.toPandas</li> <li>pyspark.sql.SparkSession.createDataFrame when its input is a Pandas DataFrame</li> </ol> <p>The following data types are unsupported: BinaryType, MapType, <a href=../types/ArrayType/ >ArrayType</a> of TimestampType, and nested StructType.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlexecutionremoveredundantsorts><span id=spark.sql.execution.removeRedundantSorts> spark.sql.execution.removeRedundantSorts<a class=headerlink href=#sparksqlexecutionremoveredundantsorts title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Whether to remove redundant physical sort node</p> <p>Default: <code>true</code></p> <p>Used as <a href=../SQLConf/#REMOVE_REDUNDANT_SORTS_ENABLED>SQLConf.REMOVE_REDUNDANT_SORTS_ENABLED</a></p> <h2 id=sparksqlexecutionreusesubquery><span id=spark.sql.execution.reuseSubquery> spark.sql.execution.reuseSubquery<a class=headerlink href=#sparksqlexecutionreusesubquery title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the planner will try to find duplicated subqueries and re-use them.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#subqueryReuseEnabled>SQLConf.subqueryReuseEnabled</a> for the current value</p> <h2 id=sparksqlexecutionsortbeforerepartition><span id=spark.sql.execution.sortBeforeRepartition> spark.sql.execution.sortBeforeRepartition<a class=headerlink href=#sparksqlexecutionsortbeforerepartition title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When perform a repartition following a shuffle, the output row ordering would be nondeterministic. If some downstream stages fail and some tasks of the repartition stage retry, these tasks may generate different data, and that can lead to correctness issues. Turn on this config to insert a local sort before actually doing repartition to generate consistent repartition results. The performance of <code>repartition()</code> may go down since we insert extra local sort before it.</p> <p>Default: <code>true</code></p> <p>Since: <code>2.1.4</code></p> <p>Use <a href=../SQLConf/#sortBeforeRepartition>SQLConf.sortBeforeRepartition</a> method to access the current value.</p> <h2 id=sparksqlexecutionrangeexchangesamplesizeperpartition><span id=spark.sql.execution.rangeExchange.sampleSizePerPartition> spark.sql.execution.rangeExchange.sampleSizePerPartition<a class=headerlink href=#sparksqlexecutionrangeexchangesamplesizeperpartition title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Number of points to sample per partition in order to determine the range boundaries for range partitioning, typically used in global sorting (without limit).</p> <p>Default: <code>100</code></p> <p>Since: <code>2.3.0</code></p> <p>Use <a href=../SQLConf/#rangeExchangeSampleSizePerPartition>SQLConf.rangeExchangeSampleSizePerPartition</a> method to access the current value.</p> <h2 id=sparksqlexecutionarrowpysparkfallbackenabled><span id=spark.sql.execution.arrow.pyspark.fallback.enabled> spark.sql.execution.arrow.pyspark.fallback.enabled<a class=headerlink href=#sparksqlexecutionarrowpysparkfallbackenabled title="Permanent link">&para;</a></h2> <p>When true, optimizations enabled by <a href=#spark.sql.execution.arrow.pyspark.enabled>spark.sql.execution.arrow.pyspark.enabled</a> will fallback automatically to non-optimized implementations if an error occurs.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlexecutionarrowsparkrenabled><span id=spark.sql.execution.arrow.sparkr.enabled> spark.sql.execution.arrow.sparkr.enabled<a class=headerlink href=#sparksqlexecutionarrowsparkrenabled title="Permanent link">&para;</a></h2> <p>When true, make use of Apache Arrow for columnar data transfers in SparkR. This optimization applies to:</p> <ol> <li>createDataFrame when its input is an R DataFrame</li> <li>collect</li> <li>dapply</li> <li>gapply</li> </ol> <p>The following data types are unsupported: FloatType, BinaryType, <a href=../types/ArrayType/ >ArrayType</a>, StructType and MapType.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlexecutionpandasudfbuffersize><span id=spark.sql.execution.pandas.udf.buffer.size> spark.sql.execution.pandas.udf.buffer.size<a class=headerlink href=#sparksqlexecutionpandasudfbuffersize title="Permanent link">&para;</a></h2> <p>Same as <code>${BUFFER_SIZE.key}</code> but only applies to Pandas UDF executions. If it is not set, the fallback is <code>${BUFFER_SIZE.key}</code>. Note that Pandas execution requires more than 4 bytes. Lowering this value could make small Pandas UDF batch iterated and pipelined; however, it might degrade performance. See SPARK-27870.</p> <p>Default: <code>65536</code></p> <h2 id=sparksqlexecutionpandasconverttoarrowarraysafely><span id=spark.sql.execution.pandas.convertToArrowArraySafely> spark.sql.execution.pandas.convertToArrowArraySafely<a class=headerlink href=#sparksqlexecutionpandasconverttoarrowarraysafely title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, Arrow will perform safe type conversion when converting Pandas. Series to Arrow array during serialization. Arrow will raise errors when detecting unsafe type conversion like overflow. When false, disabling Arrow's type check and do type conversions anyway. This config only works for Arrow 0.11.0+.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlstatisticshistogramenabled><span id=spark.sql.statistics.histogram.enabled> spark.sql.statistics.histogram.enabled<a class=headerlink href=#sparksqlstatisticshistogramenabled title="Permanent link">&para;</a></h2> <p>Enables generating histograms for <a href=../sql/AstBuilder/#visitAnalyze>ANALYZE TABLE</a> SQL statement</p> <p>Default: <code>false</code></p> <div class="admonition note"> <p class=admonition-title>Equi-Height Histogram</p> <p>Histograms can provide better estimation accuracy. Currently, Spark only supports equi-height histogram. Note that collecting histograms takes extra cost. For example, collecting column statistics usually takes only one table scan, but generating equi-height histogram will cause an extra table scan.</p> </div> <p>Use <a href=../SQLConf/#histogramEnabled>SQLConf.histogramEnabled</a> method to access the current value.</p> <h2 id=sparksqlsessiontimezone><span id=spark.sql.session.timeZone> spark.sql.session.timeZone<a class=headerlink href=#sparksqlsessiontimezone title="Permanent link">&para;</a></h2> <p>The ID of session-local timezone (e.g. "GMT", "America/Los_Angeles")</p> <p>Default: Java's <code>TimeZone.getDefault.getID</code></p> <p>Use <a href=../SQLConf/#sessionLocalTimeZone>SQLConf.sessionLocalTimeZone</a> method to access the current value.</p> <h2 id=sparksqlsourcescommitprotocolclass><span id=spark.sql.sources.commitProtocolClass> spark.sql.sources.commitProtocolClass<a class=headerlink href=#sparksqlsourcescommitprotocolclass title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Fully-qualified class name of the <code>FileCommitProtocol</code> (<a href=https://books.japila.pl/apache-spark-internals/FileCommitProtocol>Spark Core</a>)</p> <p>Default: <a href=../datasources/SQLHadoopMapReduceCommitProtocol/ >SQLHadoopMapReduceCommitProtocol</a></p> <p>Use <a href=../SQLConf/#fileCommitProtocolClass>SQLConf.fileCommitProtocolClass</a> method to access the current value.</p> <h2 id=sparksqlsourcesignoredatalocality><span id=spark.sql.sources.ignoreDataLocality> spark.sql.sources.ignoreDataLocality<a class=headerlink href=#sparksqlsourcesignoredatalocality title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, Spark will not fetch the block locations for each file on listing files. This speeds up file listing, but the scheduler cannot schedule tasks to take advantage of data locality. It can be particularly useful if data is read from a remote cluster so the scheduler could never take advantage of locality anyway.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlsourcesoutputcommitterclass><span id=spark.sql.sources.outputCommitterClass><span id=OUTPUT_COMMITTER_CLASS> spark.sql.sources.outputCommitterClass<a class=headerlink href=#sparksqlsourcesoutputcommitterclass title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The fully-qualified class name of the user-defined Hadoop <a href=https://hadoop.apache.org/docs/r3.3.2/api/org/apache/hadoop/mapreduce/OutputCommitter.html>OutputCommitter</a> used by data sources</p> <p>Default: <code>undefined</code></p> <p>Use <a href=../SQLConf/#OUTPUT_COMMITTER_CLASS>SQLConf.OUTPUT_COMMITTER_CLASS</a> to access the property</p> <h2 id=sparksqlsourcesvalidatepartitioncolumns><span id=spark.sql.sources.validatePartitionColumns> spark.sql.sources.validatePartitionColumns<a class=headerlink href=#sparksqlsourcesvalidatepartitioncolumns title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When this option is set to true, partition column values will be validated with user-specified schema. If the validation fails, a runtime exception is thrown. When this option is set to false, the partition column value will be converted to null if it can not be casted to corresponding user-specified schema.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlsourcesusev1sourcelist><span id=spark.sql.sources.useV1SourceList><span id=USE_V1_SOURCE_LIST> spark.sql.sources.useV1SourceList<a class=headerlink href=#sparksqlsourcesusev1sourcelist title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> A comma-separated list of data source short names (<a href=../DataSourceRegister/ >DataSourceRegister</a>s) or fully-qualified canonical class names of the data sources (<a href=../connector/TableProvider/ >TableProvider</a>s) for which DataSource V2 code path is disabled (and Data Source V1 code path used).</p> <p>Default: <code>avro,csv,json,kafka,orc,parquet,text</code></p> <p>Used when:</p> <ul> <li><code>DataSource</code> utility is used to <a href=../DataSource/#lookupDataSourceV2>lookupDataSourceV2</a></li> </ul> <h2 id=sparksqlstoreassignmentpolicy><span id=spark.sql.storeAssignmentPolicy> spark.sql.storeAssignmentPolicy<a class=headerlink href=#sparksqlstoreassignmentpolicy title="Permanent link">&para;</a></h2> <p>When inserting a value into a column with different data type, Spark will perform type coercion. Currently, we support 3 policies for the type coercion rules: ANSI, legacy and strict. With ANSI policy, Spark performs the type coercion as per ANSI SQL. In practice, the behavior is mostly the same as PostgreSQL. It disallows certain unreasonable type conversions such as converting <code>string</code> to <code>int</code> or <code>double</code> to <code>boolean</code>. With legacy policy, Spark allows the type coercion as long as it is a valid <code>Cast</code>, which is very loose. e.g. converting <code>string</code> to <code>int</code> or <code>double</code> to <code>boolean</code> is allowed. It is also the only behavior in Spark 2.x and it is compatible with Hive. With strict policy, Spark doesn't allow any possible precision loss or data truncation in type coercion, e.g. converting <code>double</code> to <code>int</code> or <code>decimal</code> to <code>double</code> is not allowed.</p> <p>Possible values: <code>ANSI</code>, <code>LEGACY</code>, <code>STRICT</code></p> <p>Default: <code>ANSI</code></p> <h2 id=sparksqlthriftserverinterruptoncancel><span id=spark.sql.thriftServer.interruptOnCancel> spark.sql.thriftServer.interruptOnCancel<a class=headerlink href=#sparksqlthriftserverinterruptoncancel title="Permanent link">&para;</a></h2> <p>When <code>true</code>, all running tasks will be interrupted if one cancels a query. When <code>false</code>, all running tasks will remain until finished.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#THRIFTSERVER_FORCE_CANCEL>SQLConf.THRIFTSERVER_FORCE_CANCEL</a> to access the property</p> <h2 id=sparksqlhivetablepropertylengththreshold><span id=spark.sql.hive.tablePropertyLengthThreshold> spark.sql.hive.tablePropertyLengthThreshold<a class=headerlink href=#sparksqlhivetablepropertylengththreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The maximum length allowed in a single cell when storing Spark-specific information in Hive's metastore as table properties. Currently it covers 2 things: the schema's JSON string, the histogram of column statistics.</p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#dynamicPartitionPruningEnabled>SQLConf.dynamicPartitionPruningEnabled</a> to access the current value.</p> <h2 id=sparksqlorcmergeschema><span id=spark.sql.orc.mergeSchema> spark.sql.orc.mergeSchema<a class=headerlink href=#sparksqlorcmergeschema title="Permanent link">&para;</a></h2> <p>When true, the Orc data source merges schemas collected from all data files, otherwise the schema is picked from a random data file.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlsourcesbucketingautobucketedscanenabled><span id=spark.sql.sources.bucketing.autoBucketedScan.enabled> spark.sql.sources.bucketing.autoBucketedScan.enabled<a class=headerlink href=#sparksqlsourcesbucketingautobucketedscanenabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, decide whether to do bucketed scan on input tables based on query plan automatically. Do not use bucketed scan if 1. query does not have operators to utilize bucketing (e.g. join, group-by, etc), or 2. there's an exchange operator between these operators and table scan.</p> <p>Note when <a href=#spark.sql.sources.bucketing.enabled>spark.sql.sources.bucketing.enabled</a> is set to <code>false</code>, this configuration does not take any effect.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#autoBucketedScanEnabled>SQLConf.autoBucketedScanEnabled</a> to access the property</p> <h2 id=sparksqldatetimejava8apienabled><span id=spark.sql.datetime.java8API.enabled> spark.sql.datetime.java8API.enabled<a class=headerlink href=#sparksqldatetimejava8apienabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, java.time.Instant and java.time.LocalDate classes of Java 8 API are used as external types for Catalyst's TimestampType and DateType. When <code>false</code>, java.sql.Timestamp and java.sql.Date are used for the same purpose.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyintervalenabled><span id=spark.sql.legacy.interval.enabled> spark.sql.legacy.interval.enabled<a class=headerlink href=#sparksqllegacyintervalenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, Spark SQL uses the mixed legacy interval type <code>CalendarIntervalType</code> instead of the ANSI compliant interval types <code>YearMonthIntervalType</code> and <code>DayTimeIntervalType</code>. For instance, the date subtraction expression returns <code>CalendarIntervalType</code> when the SQL config is set to <code>true</code> otherwise an ANSI interval.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#legacyIntervalEnabled>SQLConf.legacyIntervalEnabled</a> to access the current value</p> <h2 id=sparksqlsourcesbinaryfilemaxlength><span id=spark.sql.sources.binaryFile.maxLength> spark.sql.sources.binaryFile.maxLength<a class=headerlink href=#sparksqlsourcesbinaryfilemaxlength title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The max length of a file that can be read by the binary file data source. Spark will fail fast and not attempt to read the file if its length exceeds this value. The theoretical max is Int.MaxValue, though VMs might implement a smaller max.</p> <p>Default: <code>Int.MaxValue</code></p> <h2 id=sparksqlmapkeydeduppolicy><span id=spark.sql.mapKeyDedupPolicy> spark.sql.mapKeyDedupPolicy<a class=headerlink href=#sparksqlmapkeydeduppolicy title="Permanent link">&para;</a></h2> <p>The policy to deduplicate map keys in builtin function: CreateMap, MapFromArrays, MapFromEntries, StringToMap, MapConcat and TransformKeys. When EXCEPTION, the query fails if duplicated map keys are detected. When LAST_WIN, the map key that is inserted at last takes precedence.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LAST_WIN</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqlmaxconcurrentoutputfilewriters><span id=spark.sql.maxConcurrentOutputFileWriters> spark.sql.maxConcurrentOutputFileWriters<a class=headerlink href=#sparksqlmaxconcurrentoutputfilewriters title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Maximum number of output file writers for <code>FileFormatWriter</code> to use concurrently (<a href=../datasources/FileFormatWriter/#write>writing out a query result</a>). If number of writers needed reaches this limit, a task will sort rest of output then writing them.</p> <p>Default: <code>0</code></p> <p>Use <a href=../SQLConf/#maxConcurrentOutputFileWriters>SQLConf.maxConcurrentOutputFileWriters</a> for the current value</p> <h2 id=sparksqlmaxmetadatastringlength><span id=spark.sql.maxMetadataStringLength> spark.sql.maxMetadataStringLength<a class=headerlink href=#sparksqlmaxmetadatastringlength title="Permanent link">&para;</a></h2> <p>Maximum number of characters to output for a metadata string (e.g., <code>Location</code> in <a href=../datasources/FileScan/#getMetaData>FileScan</a>)</p> <p>Default: <code>100</code></p> <p>Must be bigger than <code>3</code></p> <p>Use <a href=../SQLConf/#maxMetadataStringLength>SQLConf.maxMetadataStringLength</a> for the current value</p> <h2 id=sparksqlmavenadditionalremoterepositories><span id=spark.sql.maven.additionalRemoteRepositories> spark.sql.maven.additionalRemoteRepositories<a class=headerlink href=#sparksqlmavenadditionalremoterepositories title="Permanent link">&para;</a></h2> <p>A comma-delimited string config of the optional additional remote Maven mirror repositories. This is only used for downloading Hive jars in IsolatedClientLoader if the default Maven Central repo is unreachable.</p> <p>Default: <code>https://maven-central.storage-download.googleapis.com/maven2/</code></p> <h2 id=sparksqlmaxplanstringlength><span id=spark.sql.maxPlanStringLength> spark.sql.maxPlanStringLength<a class=headerlink href=#sparksqlmaxplanstringlength title="Permanent link">&para;</a></h2> <p>Maximum number of characters to output for a plan string. If the plan is longer, further output will be truncated. The default setting always generates a full plan. Set this to a lower value such as 8k if plan strings are taking up too much memory or are causing OutOfMemory errors in the driver or UI processes.</p> <p>Default: <code>Integer.MAX_VALUE - 15</code></p> <h2 id=sparksqladdpartitioninbatchsize><span id=spark.sql.addPartitionInBatch.size> spark.sql.addPartitionInBatch.size<a class=headerlink href=#sparksqladdpartitioninbatchsize title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The number of partitions to be handled in one turn when use <code>AlterTableAddPartitionCommand</code> to add partitions into table. The smaller batch size is, the less memory is required for the real handler, e.g. Hive Metastore.</p> <p>Default: <code>100</code></p> <h2 id=sparksqlscripttransformationexittimeoutinseconds><span id=spark.sql.scriptTransformation.exitTimeoutInSeconds> spark.sql.scriptTransformation.exitTimeoutInSeconds<a class=headerlink href=#sparksqlscripttransformationexittimeoutinseconds title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Timeout for executor to wait for the termination of transformation script when EOF.</p> <p>Default: <code>10</code> seconds</p> <h2 id=sparksqlautobroadcastjointhreshold><span id=spark.sql.autoBroadcastJoinThreshold><span id=AUTO_BROADCASTJOIN_THRESHOLD> spark.sql.autoBroadcastJoinThreshold<a class=headerlink href=#sparksqlautobroadcastjointhreshold title="Permanent link">&para;</a></h2> <p>Maximum size (in bytes) for a table that can be broadcast (to all worker nodes) in a join</p> <p>Default: <code>10M</code></p> <p><code>-1</code> (or any negative value) disables broadcasting</p> <p>Use <a href=../SQLConf/#autoBroadcastJoinThreshold>SQLConf.autoBroadcastJoinThreshold</a> method to access the current value.</p> <h2 id=sparksqlavrocompressioncodec><span id=spark.sql.avro.compression.codec> spark.sql.avro.compression.codec<a class=headerlink href=#sparksqlavrocompressioncodec title="Permanent link">&para;</a></h2> <p>The compression codec to use when writing Avro data to disk</p> <p>Default: <code>snappy</code></p> <p>The supported codecs are:</p> <ul> <li><code>uncompressed</code></li> <li><code>deflate</code></li> <li><code>snappy</code></li> <li><code>bzip2</code></li> <li><code>xz</code></li> </ul> <p>Use <a href=../SQLConf/#avroCompressionCodec>SQLConf.avroCompressionCodec</a> method to access the current value.</p> <h2 id=sparksqlbroadcasttimeout><span id=spark.sql.broadcastTimeout> spark.sql.broadcastTimeout<a class=headerlink href=#sparksqlbroadcasttimeout title="Permanent link">&para;</a></h2> <p>Timeout in seconds for the broadcast wait time in broadcast joins.</p> <p>Default: <code>5 * 60</code></p> <p>When negative, it is assumed infinite (i.e. <code>Duration.Inf</code>)</p> <p>Use <a href=../SQLConf/#broadcastTimeout>SQLConf.broadcastTimeout</a> method to access the current value.</p> <h2 id=sparksqlbucketingcoalescebucketsinjoinenabled><span id=spark.sql.bucketing.coalesceBucketsInJoin.enabled> spark.sql.bucketing.coalesceBucketsInJoin.enabled<a class=headerlink href=#sparksqlbucketingcoalescebucketsinjoinenabled title="Permanent link">&para;</a></h2> <p>When enabled (<code>true</code>), if two bucketed tables with the different number of buckets are joined, the side with a bigger number of buckets will be coalesced to have the same number of buckets as the other side. Bigger number of buckets is divisible by the smaller number of buckets. Bucket coalescing is applied to sort-merge joins and shuffled hash join.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>Coalescing bucketed table can avoid unnecessary shuffling in join, but it also reduces parallelism and could possibly cause OOM for shuffled hash join.</p> </div> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#coalesceBucketsInJoinEnabled>SQLConf.coalesceBucketsInJoinEnabled</a> method to access the current value.</p> <h2 id=sparksqlcasesensitive><span id=spark.sql.caseSensitive> spark.sql.caseSensitive<a class=headerlink href=#sparksqlcasesensitive title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether the query analyzer should be case sensitive (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>false</code></p> <p>It is highly discouraged to turn on case sensitive mode.</p> <p>Use <a href=../SQLConf/#caseSensitiveAnalysis>SQLConf.caseSensitiveAnalysis</a> method to access the current value.</p> <h2 id=sparksqlcatalogspark_catalog><span id=spark.sql.catalog.spark_catalog><span id=V2_SESSION_CATALOG_IMPLEMENTATION> spark.sql.catalog.spark_catalog<a class=headerlink href=#sparksqlcatalogspark_catalog title="Permanent link">&para;</a></h2> <p>The <a href=../connector/catalog/CatalogPlugin/ >CatalogPlugin</a> for <code>spark_catalog</code></p> <p>Default: <a href=../connector/catalog/CatalogManager/#defaultSessionCatalog>defaultSessionCatalog</a></p> <h2 id=sparksqlcboenabled><span id=spark.sql.cbo.enabled> spark.sql.cbo.enabled<a class=headerlink href=#sparksqlcboenabled title="Permanent link">&para;</a></h2> <p>Enables <a href=../cost-based-optimization/ >Cost-Based Optimization</a> (CBO) for estimation of plan statistics when <code>true</code>.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#cboEnabled>SQLConf.cboEnabled</a> method to access the current value.</p> <h2 id=sparksqlcbojoinreorderenabled><span id=spark.sql.cbo.joinReorder.enabled> spark.sql.cbo.joinReorder.enabled<a class=headerlink href=#sparksqlcbojoinreorderenabled title="Permanent link">&para;</a></h2> <p>Enables join reorder for cost-based optimization (CBO).</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#joinReorderEnabled>SQLConf.joinReorderEnabled</a> method to access the current value.</p> <h2 id=sparksqlcboplanstatsenabled><span id=spark.sql.cbo.planStats.enabled> spark.sql.cbo.planStats.enabled<a class=headerlink href=#sparksqlcboplanstatsenabled title="Permanent link">&para;</a></h2> <p>When <code>true</code>, the logical plan will fetch row counts and column statistics from catalog.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlcbostarschemadetection><span id=spark.sql.cbo.starSchemaDetection> spark.sql.cbo.starSchemaDetection<a class=headerlink href=#sparksqlcbostarschemadetection title="Permanent link">&para;</a></h2> <p>Enables <em>join reordering</em> based on star schema detection for cost-based optimization (CBO) in <a href=../logical-optimizations/ReorderJoin/ >ReorderJoin</a> logical plan optimization.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#starSchemaDetection>SQLConf.starSchemaDetection</a> method to access the current value.</p> <h2 id=sparksqlcodegenaggregatemapvectorizedenable_1><span id=spark.sql.codegen.aggregate.map.vectorized.enable> spark.sql.codegen.aggregate.map.vectorized.enable<a class=headerlink href=#sparksqlcodegenaggregatemapvectorizedenable_1 title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables vectorized aggregate hash map. This is for testing/benchmarking only.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlcodegenaggregatesplitaggregatefuncenabled><span id=spark.sql.codegen.aggregate.splitAggregateFunc.enabled> spark.sql.codegen.aggregate.splitAggregateFunc.enabled<a class=headerlink href=#sparksqlcodegenaggregatesplitaggregatefuncenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, the code generator would split aggregate code into individual methods instead of a single big method. This can be used to avoid oversized function that can miss the opportunity of JIT optimization.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlcodegencomments><span id=spark.sql.codegen.comments> spark.sql.codegen.comments<a class=headerlink href=#sparksqlcodegencomments title="Permanent link">&para;</a></h2> <p>Controls whether <code>CodegenContext</code> should <a href=../physical-operators/CodegenSupport/#registerComment>register comments</a> (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>false</code></p> <h2 id=sparksqlcodegenfactorymode><span id=spark.sql.codegen.factoryMode> spark.sql.codegen.factoryMode<a class=headerlink href=#sparksqlcodegenfactorymode title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Determines the codegen generator fallback behavior</p> <p>Default: <code>FALLBACK</code></p> <p>Acceptable values:</p> <ul> <li><code>CODEGEN_ONLY</code> - disable fallback mode</li> <li><code>FALLBACK</code> - try codegen first and, if any compile error happens, fallback to interpreted mode</li> <li><code>NO_CODEGEN</code> - skips codegen and always uses interpreted path</li> </ul> <p>Used when <code>CodeGeneratorWithInterpretedFallback</code> is requested to <a href=../expressions/CodeGeneratorWithInterpretedFallback/#createObject>createObject</a> (when <code>UnsafeProjection</code> is requested to <a href=../expressions/UnsafeProjection/#create>create an UnsafeProjection for Catalyst expressions</a>)</p> <h2 id=sparksqlcodegenfallback><span id=spark.sql.codegen.fallback> spark.sql.codegen.fallback<a class=headerlink href=#sparksqlcodegenfallback title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Whether the whole stage codegen could be temporary disabled for the part of a query that has failed to compile generated code (<code>true</code>) or not (<code>false</code>).</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageFallback>SQLConf.wholeStageFallback</a> method to access the current value.</p> <h2 id=sparksqlcodegenhugemethodlimit><span id=spark.sql.codegen.hugeMethodLimit> spark.sql.codegen.hugeMethodLimit<a class=headerlink href=#sparksqlcodegenhugemethodlimit title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The maximum bytecode size of a single compiled Java function generated by whole-stage codegen.</p> <p>Default: <code>65535</code></p> <p>The default value <code>65535</code> is the largest bytecode size possible for a valid Java method. When running on HotSpot, it may be preferable to set the value to <code>8000</code> (which is the value of <code>HugeMethodLimit</code> in the OpenJDK JVM settings)</p> <p>Use <a href=../SQLConf/#hugeMethodLimit>SQLConf.hugeMethodLimit</a> method to access the current value.</p> <h2 id=sparksqlcodegenuseidinclassname><span id=spark.sql.codegen.useIdInClassName> spark.sql.codegen.useIdInClassName<a class=headerlink href=#sparksqlcodegenuseidinclassname title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether to embed the (whole-stage) codegen stage ID into the class name of the generated class as a suffix (<code>true</code>) or not (<code>false</code>)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageUseIdInClassName>SQLConf.wholeStageUseIdInClassName</a> method to access the current value.</p> <h2 id=sparksqlcodegenmaxfields><span id=spark.sql.codegen.maxFields> spark.sql.codegen.maxFields<a class=headerlink href=#sparksqlcodegenmaxfields title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Maximum number of output fields (including nested fields) that whole-stage codegen supports. Going above the number deactivates whole-stage codegen.</p> <p>Default: <code>100</code></p> <p>Use <a href=../SQLConf/#wholeStageMaxNumFields>SQLConf.wholeStageMaxNumFields</a> method to access the current value.</p> <h2 id=sparksqlcodegensplitconsumefuncbyoperator><span id=spark.sql.codegen.splitConsumeFuncByOperator> spark.sql.codegen.splitConsumeFuncByOperator<a class=headerlink href=#sparksqlcodegensplitconsumefuncbyoperator title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether whole stage codegen puts the logic of consuming rows of each physical operator into individual methods, instead of a single big method. This can be used to avoid oversized function that can miss the opportunity of JIT optimization.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#wholeStageSplitConsumeFuncByOperator>SQLConf.wholeStageSplitConsumeFuncByOperator</a> method to access the current value.</p> <h2 id=sparksqlcolumnvectoroffheapenabled><span id=spark.sql.columnVector.offheap.enabled> spark.sql.columnVector.offheap.enabled<a class=headerlink href=#sparksqlcolumnvectoroffheapenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables <a href=../OffHeapColumnVector/ >OffHeapColumnVector</a> in <a href=../ColumnarBatch/ >ColumnarBatch</a> (<code>true</code>) or not (<code>false</code>). When <code>false</code>, <a href=../OnHeapColumnVector/ >OnHeapColumnVector</a> is used instead.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#offHeapColumnVectorEnabled>SQLConf.offHeapColumnVectorEnabled</a> method to access the current value.</p> <h2 id=sparksqlcolumnnameofcorruptrecord><span id=spark.sql.columnNameOfCorruptRecord> spark.sql.columnNameOfCorruptRecord<a class=headerlink href=#sparksqlcolumnnameofcorruptrecord title="Permanent link">&para;</a></h2> <h2 id=sparksqlconstraintpropagationenabled><span id=spark.sql.constraintPropagation.enabled> spark.sql.constraintPropagation.enabled<a class=headerlink href=#sparksqlconstraintpropagationenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, the query optimizer will infer and propagate data constraints in the query plan to optimize them. Constraint propagation can sometimes be computationally expensive for certain kinds of query plans (such as those with a large number of predicates and aliases) which might negatively impact overall runtime.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#constraintPropagationEnabled>SQLConf.constraintPropagationEnabled</a> method to access the current value.</p> <h2 id=sparksqlcsvfilterpushdownenabled><span id=spark.sql.csv.filterPushdown.enabled> spark.sql.csv.filterPushdown.enabled<a class=headerlink href=#sparksqlcsvfilterpushdownenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, enable filter pushdown to CSV datasource.</p> <p>Default: <code>true</code></p> <h2 id=sparksqldefaultsizeinbytes><span id=spark.sql.defaultSizeInBytes> spark.sql.defaultSizeInBytes<a class=headerlink href=#sparksqldefaultsizeinbytes title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Estimated size of a table or relation used in query planning</p> <p>Default: Java's <code>Long.MaxValue</code></p> <p>Set to Java's <code>Long.MaxValue</code> which is larger than <a href=#spark.sql.autoBroadcastJoinThreshold>spark.sql.autoBroadcastJoinThreshold</a> to be more conservative. That is to say by default the optimizer will not choose to broadcast a table unless it knows for sure that the table size is small enough.</p> <p>Used by the planner to decide when it is safe to broadcast a relation. By default, the system will assume that tables are too large to broadcast.</p> <p>Use <a href=../SQLConf/#defaultSizeInBytes>SQLConf.defaultSizeInBytes</a> method to access the current value.</p> <h2 id=sparksqldialect><span id=spark.sql.dialect> spark.sql.dialect<a class=headerlink href=#sparksqldialect title="Permanent link">&para;</a></h2> <h2 id=sparksqlexchangereuse><span id=spark.sql.exchange.reuse> spark.sql.exchange.reuse<a class=headerlink href=#sparksqlexchangereuse title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When enabled (<code>true</code>), the <a href=../SparkPlanner/ >Spark planner</a> will find duplicated exchanges and subqueries and re-use them.</p> <p>When disabled (<code>false</code>), <a href=../physical-optimizations/ReuseExchange/ >ReuseExchange</a> and <a href=../physical-optimizations/ReuseSubquery/ >ReuseSubquery</a> physical optimizations (that the Spark planner uses for physical query plan optimization) do nothing.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#exchangeReuseEnabled>SQLConf.exchangeReuseEnabled</a> method to access the current value.</p> <h2 id=executionuseobjecthashaggregateexec><span id=spark.sql.execution.useObjectHashAggregateExec> execution.useObjectHashAggregateExec<a class=headerlink href=#executionuseobjecthashaggregateexec title="Permanent link">&para;</a></h2> <p><strong>spark.sql.execution.useObjectHashAggregateExec</strong></p> <p><strong>(internal)</strong> <a href=../AggUtils/#createAggregate>Prefers ObjectHashAggregateExec (over SortAggregateExec) for aggregation</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#useObjectHashAggregation>SQLConf.useObjectHashAggregation</a> method to access the current value.</p> <h2 id=sparksqlfilesignorecorruptfiles><span id=spark.sql.files.ignoreCorruptFiles> spark.sql.files.ignoreCorruptFiles<a class=headerlink href=#sparksqlfilesignorecorruptfiles title="Permanent link">&para;</a></h2> <p>Controls whether to ignore corrupt files (<code>true</code>) or not (<code>false</code>). If <code>true</code>, the Spark jobs will continue to run when encountering corrupted files and the contents that have been read will still be returned.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#ignoreCorruptFiles>SQLConf.ignoreCorruptFiles</a> method to access the current value.</p> <h2 id=sparksqlfilesignoremissingfiles><span id=spark.sql.files.ignoreMissingFiles> spark.sql.files.ignoreMissingFiles<a class=headerlink href=#sparksqlfilesignoremissingfiles title="Permanent link">&para;</a></h2> <p>Controls whether to ignore missing files (<code>true</code>) or not (<code>false</code>). If <code>true</code>, the Spark jobs will continue to run when encountering missing files and the contents that have been read will still be returned.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#ignoreMissingFiles>SQLConf.ignoreMissingFiles</a> method to access the current value.</p> <h2 id=sparksqlfilesmaxrecordsperfile><span id=spark.sql.files.maxRecordsPerFile> spark.sql.files.maxRecordsPerFile<a class=headerlink href=#sparksqlfilesmaxrecordsperfile title="Permanent link">&para;</a></h2> <p>Maximum number of records to write out to a single file. If this value is <code>0</code> or negative, there is no limit.</p> <p>Default: <code>0</code></p> <p>Use <a href=../SQLConf/#maxRecordsPerFile>SQLConf.maxRecordsPerFile</a> method to access the current value.</p> <h2 id=sparksqlfilesmaxpartitionbytes><span id=spark.sql.files.maxPartitionBytes><span id=FILES_MAX_PARTITION_BYTES> spark.sql.files.maxPartitionBytes<a class=headerlink href=#sparksqlfilesmaxpartitionbytes title="Permanent link">&para;</a></h2> <p>Maximum number of bytes to pack into a single partition when reading files</p> <p>Default: <code>128MB</code> (like <code>parquet.block.size</code>)</p> <p>Use <a href=../SQLConf/#filesMaxPartitionBytes>SQLConf.filesMaxPartitionBytes</a> for the current value</p> <h2 id=sparksqlfilesminpartitionnum><span id=spark.sql.files.minPartitionNum> spark.sql.files.minPartitionNum<a class=headerlink href=#sparksqlfilesminpartitionnum title="Permanent link">&para;</a></h2> <p>The suggested (not guaranteed) minimum number of split file partitions for file-based data sources such as Parquet, JSON and ORC.</p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#filesMinPartitionNum>SQLConf.filesMinPartitionNum</a> method to access the current value.</p> <h2 id=sparksqlfilesopencostinbytes><span id=spark.sql.files.openCostInBytes> spark.sql.files.openCostInBytes<a class=headerlink href=#sparksqlfilesopencostinbytes title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The estimated cost to open a file, measured by the number of bytes could be scanned at the same time (to include multiple files into a partition).</p> <p>Default: <code>4 * 1024 * 1024</code></p> <p>It's better to over estimate it, then the partitions with small files will be faster than partitions with bigger files (which is scheduled first).</p> <p>Use <a href=../SQLConf/#filesOpenCostInBytes>SQLConf.filesOpenCostInBytes</a> method to access the current value.</p> <h2 id=sparksqlinmemorycolumnarstoragecompressed><span id=spark.sql.inMemoryColumnarStorage.compressed> spark.sql.inMemoryColumnarStorage.compressed<a class=headerlink href=#sparksqlinmemorycolumnarstoragecompressed title="Permanent link">&para;</a></h2> <p>When enabled, Spark SQL will automatically select a compression codec for each column based on statistics of the data.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#useCompression>SQLConf.useCompression</a> method to access the current value.</p> <h2 id=sparksqlinmemorycolumnarstoragebatchsize><span id=spark.sql.inMemoryColumnarStorage.batchSize> spark.sql.inMemoryColumnarStorage.batchSize<a class=headerlink href=#sparksqlinmemorycolumnarstoragebatchsize title="Permanent link">&para;</a></h2> <p>Controls the size of batches for columnar caching. Larger batch sizes can improve memory utilization and compression, but risk OOMs when caching data.</p> <p>Default: <code>10000</code></p> <p>Use <a href=../SQLConf/#columnBatchSize>SQLConf.columnBatchSize</a> method to access the current value.</p> <h2 id=sparksqlinmemorytablescanstatisticsenable><span id=spark.sql.inMemoryTableScanStatistics.enable> spark.sql.inMemoryTableScanStatistics.enable<a class=headerlink href=#sparksqlinmemorytablescanstatisticsenable title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, enable in-memory table scan accumulators.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlinmemorycolumnarstorageenablevectorizedreader><span id=spark.sql.inMemoryColumnarStorage.enableVectorizedReader> spark.sql.inMemoryColumnarStorage.enableVectorizedReader<a class=headerlink href=#sparksqlinmemorycolumnarstorageenablevectorizedreader title="Permanent link">&para;</a></h2> <p>Enables <a href=../vectorized-query-execution/ >vectorized reader</a> for columnar caching.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#cacheVectorizedReaderEnabled>SQLConf.cacheVectorizedReaderEnabled</a> method to access the current value.</p> <h2 id=sparksqlinmemorycolumnarstoragepartitionpruning><span id=spark.sql.inMemoryColumnarStorage.partitionPruning> spark.sql.inMemoryColumnarStorage.partitionPruning<a class=headerlink href=#sparksqlinmemorycolumnarstoragepartitionpruning title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables partition pruning for in-memory columnar tables</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#inMemoryPartitionPruning>SQLConf.inMemoryPartitionPruning</a> method to access the current value.</p> <h2 id=sparksqljoinprefersortmergejoin><span id=spark.sql.join.preferSortMergeJoin> spark.sql.join.preferSortMergeJoin<a class=headerlink href=#sparksqljoinprefersortmergejoin title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether <a href=../execution-planning-strategies/JoinSelection/ >JoinSelection</a> execution planning strategy prefers <a href=../physical-operators/SortMergeJoinExec/ >sort merge join</a> over <a href=../physical-operators/ShuffledHashJoinExec/ >shuffled hash join</a>.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#preferSortMergeJoin>SQLConf.preferSortMergeJoin</a> method to access the current value.</p> <h2 id=sparksqljsongeneratorignorenullfields><span id=spark.sql.jsonGenerator.ignoreNullFields> spark.sql.jsonGenerator.ignoreNullFields<a class=headerlink href=#sparksqljsongeneratorignorenullfields title="Permanent link">&para;</a></h2> <p>Whether to ignore null fields when generating JSON objects in JSON data source and JSON functions such as to_json. If false, it generates null for null fields in JSON objects.</p> <p>Default: <code>true</code></p> <h2 id=sparksqlleafnodedefaultparallelism><span id=spark.sql.leafNodeDefaultParallelism><span id=LEAF_NODE_DEFAULT_PARALLELISM> spark.sql.leafNodeDefaultParallelism<a class=headerlink href=#sparksqlleafnodedefaultparallelism title="Permanent link">&para;</a></h2> <p>The <a href=../SparkSession/#leafNodeDefaultParallelism>default parallelism of leaf operators</a> that produce data</p> <p>Must be positive</p> <p>Default: <code>SparkContext.defaultParallelism</code> (<a href=https://books.japila.pl/apache-spark-internals/SparkContext#defaultParallelism>Spark Core</a>)</p> <h2 id=sparksqllegacydolooseupcast><span id=spark.sql.legacy.doLooseUpcast> spark.sql.legacy.doLooseUpcast<a class=headerlink href=#sparksqllegacydolooseupcast title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the upcast will be loose and allows string to atomic types.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacycteprecedencepolicy><span id=spark.sql.legacy.ctePrecedencePolicy> spark.sql.legacy.ctePrecedencePolicy<a class=headerlink href=#sparksqllegacycteprecedencepolicy title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> This config will be removed in future versions and <code>CORRECTED</code> will be the only behavior.</p> <p>Possible values:</p> <ol> <li><code>CORRECTED</code> - inner CTE definitions take precedence</li> <li><code>EXCEPTION</code> - <code>AnalysisException</code> is thrown while name conflict is detected in nested CTE</li> <li><code>LEGACY</code> - outer CTE definitions takes precedence over inner definitions</li> </ol> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacytimeparserpolicy><span id=spark.sql.legacy.timeParserPolicy> spark.sql.legacy.timeParserPolicy<a class=headerlink href=#sparksqllegacytimeparserpolicy title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, java.text.SimpleDateFormat is used for formatting and parsing dates/timestamps in a locale-sensitive manner, which is the approach before Spark 3.0. When set to CORRECTED, classes from <code>java.time.*</code> packages are used for the same purpose. The default value is EXCEPTION, RuntimeException is thrown when we will get different results.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyfollowthreevaluedlogicinarrayexists><span id=spark.sql.legacy.followThreeValuedLogicInArrayExists> spark.sql.legacy.followThreeValuedLogicInArrayExists<a class=headerlink href=#sparksqllegacyfollowthreevaluedlogicinarrayexists title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When true, the ArrayExists will follow the three-valued boolean logic.</p> <p>Default: <code>true</code></p> <h2 id=sparksqllegacyfromdaytimestringenabled><span id=spark.sql.legacy.fromDayTimeString.enabled> spark.sql.legacy.fromDayTimeString.enabled<a class=headerlink href=#sparksqllegacyfromdaytimestringenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the <code>from</code> bound is not taken into account in conversion of a day-time string to an interval, and the <code>to</code> bound is used to skip all interval units out of the specified range. When <code>false</code>, <code>ParseException</code> is thrown if the input does not match to the pattern defined by <code>from</code> and <code>to</code>.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacynotreserveproperties><span id=spark.sql.legacy.notReserveProperties> spark.sql.legacy.notReserveProperties<a class=headerlink href=#sparksqllegacynotreserveproperties title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, all database and table properties are not reserved and available for create/alter syntaxes. But please be aware that the reserved properties will be silently removed.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyaddsinglefileinaddfile><span id=spark.sql.legacy.addSingleFileInAddFile> spark.sql.legacy.addSingleFileInAddFile<a class=headerlink href=#sparksqllegacyaddsinglefileinaddfile title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, only a single file can be added using ADD FILE. If false, then users can add directory by passing directory path to ADD FILE.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyexponentliteralasdecimalenabled><span id=spark.sql.legacy.exponentLiteralAsDecimal.enabled> spark.sql.legacy.exponentLiteralAsDecimal.enabled<a class=headerlink href=#sparksqllegacyexponentliteralasdecimalenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, a literal with an exponent (e.g. 1E-30) would be parsed as Decimal rather than Double.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyallownegativescaleofdecimal><span id=spark.sql.legacy.allowNegativeScaleOfDecimal> spark.sql.legacy.allowNegativeScaleOfDecimal<a class=headerlink href=#sparksqllegacyallownegativescaleofdecimal title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, negative scale of Decimal type is allowed. For example, the type of number 1E10BD under legacy mode is DecimalType(2, -9), but is Decimal(11, 0) in non legacy mode.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacybucketedtablescanoutputordering><span id=spark.sql.legacy.bucketedTableScan.outputOrdering> spark.sql.legacy.bucketedTableScan.outputOrdering<a class=headerlink href=#sparksqllegacybucketedtablescanoutputordering title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the bucketed table scan will list files during planning to figure out the output ordering, which is expensive and may make the planning quite slow.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyjsonallowemptystringenabled><span id=spark.sql.legacy.json.allowEmptyString.enabled> spark.sql.legacy.json.allowEmptyString.enabled<a class=headerlink href=#sparksqllegacyjsonallowemptystringenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the parser of JSON data source treats empty strings as null for some data types such as <code>IntegerType</code>.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacycreateemptycollectionusingstringtype><span id=spark.sql.legacy.createEmptyCollectionUsingStringType> spark.sql.legacy.createEmptyCollectionUsingStringType<a class=headerlink href=#sparksqllegacycreateemptycollectionusingstringtype title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, Spark returns an empty collection with <code>StringType</code> as element type if the <code>array</code>/<code>map</code> function is called without any parameters. Otherwise, Spark returns an empty collection with <code>NullType</code> as element type.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyallowuntypedscalaudf><span id=spark.sql.legacy.allowUntypedScalaUDF> spark.sql.legacy.allowUntypedScalaUDF<a class=headerlink href=#sparksqllegacyallowuntypedscalaudf title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, user is allowed to use <code>org.apache.spark.sql.functions.udf(f: AnyRef, dataType: DataType)</code>. Otherwise, an exception will be thrown at runtime.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacydatasetnamenonstructgroupingkeyasvalue><span id=spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue> spark.sql.legacy.dataset.nameNonStructGroupingKeyAsValue<a class=headerlink href=#sparksqllegacydatasetnamenonstructgroupingkeyasvalue title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, the key attribute resulted from running <code>Dataset.groupByKey</code> for non-struct key type, will be named as <code>value</code>, following the behavior of Spark version 2.4 and earlier.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacysetcommandrejectssparkcoreconfs><span id=spark.sql.legacy.setCommandRejectsSparkCoreConfs> spark.sql.legacy.setCommandRejectsSparkCoreConfs<a class=headerlink href=#sparksqllegacysetcommandrejectssparkcoreconfs title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> If it is set to true, SET command will fail when the key is registered as a SparkConf entry.</p> <p>Default: <code>true</code></p> <h2 id=sparksqllegacytypecoerciondatetimetostringenabled><span id=spark.sql.legacy.typeCoercion.datetimeToString.enabled> spark.sql.legacy.typeCoercion.datetimeToString.enabled<a class=headerlink href=#sparksqllegacytypecoerciondatetimetostringenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, date/timestamp will cast to string in binary comparisons with String</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyallowhashonmaptype><span id=spark.sql.legacy.allowHashOnMapType> spark.sql.legacy.allowHashOnMapType<a class=headerlink href=#sparksqllegacyallowhashonmaptype title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>true</code>, hash expressions can be applied on elements of MapType. Otherwise, an analysis exception will be thrown.</p> <p>Default: <code>false</code></p> <h2 id=sparksqllegacyparquetdatetimerebasemodeinwrite><span id=spark.sql.legacy.parquet.datetimeRebaseModeInWrite> spark.sql.legacy.parquet.datetimeRebaseModeInWrite<a class=headerlink href=#sparksqllegacyparquetdatetimerebasemodeinwrite title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from Proleptic Gregorian calendar to the legacy hybrid (Julian + Gregorian) calendar when writing Parquet files. When CORRECTED, Spark will not do rebase and write the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the writing if it sees ancient dates/timestamps that are ambiguous between the two calendars.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyparquetdatetimerebasemodeinread><span id=spark.sql.legacy.parquet.datetimeRebaseModeInRead> spark.sql.legacy.parquet.datetimeRebaseModeInRead<a class=headerlink href=#sparksqllegacyparquetdatetimerebasemodeinread title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from the legacy hybrid (Julian + Gregorian) calendar to Proleptic Gregorian calendar when reading Parquet files. When CORRECTED, Spark will not do rebase and read the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the reading if it sees ancient dates/timestamps that are ambiguous between the two calendars. This config is only effective if the writer info (like Spark, Hive) of the Parquet files is unknown.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyavrodatetimerebasemodeinwrite><span id=spark.sql.legacy.avro.datetimeRebaseModeInWrite> spark.sql.legacy.avro.datetimeRebaseModeInWrite<a class=headerlink href=#sparksqllegacyavrodatetimerebasemodeinwrite title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from Proleptic Gregorian calendar to the legacy hybrid (Julian + Gregorian) calendar when writing Avro files. When CORRECTED, Spark will not do rebase and write the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the writing if it sees ancient dates/timestamps that are ambiguous between the two calendars.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyavrodatetimerebasemodeinread><span id=spark.sql.legacy.avro.datetimeRebaseModeInRead> spark.sql.legacy.avro.datetimeRebaseModeInRead<a class=headerlink href=#sparksqllegacyavrodatetimerebasemodeinread title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When LEGACY, Spark will rebase dates/timestamps from the legacy hybrid (Julian + Gregorian) calendar to Proleptic Gregorian calendar when reading Avro files. When CORRECTED, Spark will not do rebase and read the dates/timestamps as it is. When EXCEPTION, which is the default, Spark will fail the reading if it sees ancient dates/timestamps that are ambiguous between the two calendars. This config is only effective if the writer info (like Spark, Hive) of the Avro files is unknown.</p> <p>Possible values: <code>EXCEPTION</code>, <code>LEGACY</code>, <code>CORRECTED</code></p> <p>Default: <code>EXCEPTION</code></p> <h2 id=sparksqllegacyrddapplyconf><span id=spark.sql.legacy.rdd.applyConf> spark.sql.legacy.rdd.applyConf<a class=headerlink href=#sparksqllegacyrddapplyconf title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables propagation of <a href=../SQLConf/#getAllConfs>SQL configurations</a> when executing operations on the <a href=../QueryExecution/#toRdd>RDD that represents a structured query</a>. This is the (buggy) behavior up to 2.4.4.</p> <p>Default: <code>true</code></p> <p>This is for cases not tracked by <a href=../SQLExecution/ >SQL execution</a>, when a <code>Dataset</code> is converted to an RDD either using Dataset.md#rdd[rdd] operation or <a href=../QueryExecution/#toRdd>QueryExecution</a>, and then the returned RDD is used to invoke actions on it.</p> <p>This config is deprecated and will be removed in 3.0.0.</p> <h2 id=sparksqllegacyreplacedatabrickssparkavroenabled><span id=spark.sql.legacy.replaceDatabricksSparkAvro.enabled> spark.sql.legacy.replaceDatabricksSparkAvro.enabled<a class=headerlink href=#sparksqllegacyreplacedatabrickssparkavroenabled title="Permanent link">&para;</a></h2> <p>Enables resolving (<em>mapping</em>) the data source provider <code>com.databricks.spark.avro</code> to the built-in (but external) Avro data source module for backward compatibility.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#replaceDatabricksSparkAvroEnabled>SQLConf.replaceDatabricksSparkAvroEnabled</a> method to access the current value.</p> <h2 id=sparksqllimitscaleupfactor><span id=spark.sql.limit.scaleUpFactor> spark.sql.limit.scaleUpFactor<a class=headerlink href=#sparksqllimitscaleupfactor title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Minimal increase rate in the number of partitions between attempts when executing <code>take</code> operator on a structured query. Higher values lead to more partitions read. Lower values might lead to longer execution times as more jobs will be run.</p> <p>Default: <code>4</code></p> <p>Use <a href=../SQLConf/#limitScaleUpFactor>SQLConf.limitScaleUpFactor</a> method to access the current value.</p> <h2 id=sparksqloptimizenullawareantijoin><span id=spark.sql.optimizeNullAwareAntiJoin> spark.sql.optimizeNullAwareAntiJoin<a class=headerlink href=#sparksqloptimizenullawareantijoin title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables <a href=../ExtractSingleColumnNullAwareAntiJoin/#unapply>single-column NULL-aware anti join execution planning</a> into <a href=../physical-operators/BroadcastHashJoinExec/ >BroadcastHashJoinExec</a> (with flag <a href=../physical-operators/BroadcastHashJoinExec/#isNullAwareAntiJoin>isNullAwareAntiJoin</a> enabled), optimized from O(M*N) calculation into O(M) calculation using hash lookup instead of looping lookup.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#optimizeNullAwareAntiJoin>SQLConf.optimizeNullAwareAntiJoin</a> method to access the current value.</p> <h2 id=sparksqlorcimpl><span id=spark.sql.orc.impl> spark.sql.orc.impl<a class=headerlink href=#sparksqlorcimpl title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When <code>native</code>, use the native version of ORC support instead of the ORC library in Hive 1.2.1.</p> <p>Default: <code>native</code></p> <p>Acceptable values:</p> <ul> <li><code>hive</code></li> <li><code>native</code></li> </ul> <h2 id=sparksqlplanchangeloglevel><span id=spark.sql.planChangeLog.level> spark.sql.planChangeLog.level<a class=headerlink href=#sparksqlplanchangeloglevel title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Log level for logging the change from the original plan to the new plan after a rule or batch is applied.</p> <p>Default: <code>trace</code></p> <p>Supported Values (case-insensitive):</p> <ul> <li>trace</li> <li>debug</li> <li>info</li> <li>warn</li> <li>error</li> </ul> <p>Use <a href=../SQLConf/#planChangeLogLevel>SQLConf.planChangeLogLevel</a> method to access the current value.</p> <h2 id=sparksqlplanchangelogbatches><span id=spark.sql.planChangeLog.batches> spark.sql.planChangeLog.batches<a class=headerlink href=#sparksqlplanchangelogbatches title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Comma-separated list of batch names for plan changes logging</p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#planChangeBatches>SQLConf.planChangeBatches</a> method to access the current value.</p> <h2 id=sparksqlplanchangelogrules><span id=spark.sql.planChangeLog.rules> spark.sql.planChangeLog.rules<a class=headerlink href=#sparksqlplanchangelogrules title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Comma-separated list of rule names for plan changes logging</p> <p>Default: (undefined)</p> <p>Use <a href=../SQLConf/#planChangeRules>SQLConf.planChangeRules</a> method to access the current value.</p> <h2 id=sparksqlpysparkjvmstacktraceenabled><span id=spark.sql.pyspark.jvmStacktrace.enabled> spark.sql.pyspark.jvmStacktrace.enabled<a class=headerlink href=#sparksqlpysparkjvmstacktraceenabled title="Permanent link">&para;</a></h2> <p>When true, it shows the JVM stacktrace in the user-facing PySpark exception together with Python stacktrace. By default, it is disabled and hides JVM stacktrace and shows a Python-friendly exception only.</p> <p>Default: <code>false</code></p> <h2 id=sparksqlparquetbinaryasstring><span id=spark.sql.parquet.binaryAsString> spark.sql.parquet.binaryAsString<a class=headerlink href=#sparksqlparquetbinaryasstring title="Permanent link">&para;</a></h2> <p>Some other Parquet-producing systems, in particular Impala and older versions of Spark SQL, do not differentiate between binary data and strings when writing out the Parquet schema. This flag tells Spark SQL to interpret binary data as a string to provide compatibility with these systems.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#isParquetBinaryAsString>SQLConf.isParquetBinaryAsString</a> method to access the current value.</p> <h2 id=sparksqlparquetcolumnarreaderbatchsize><span id=spark.sql.parquet.columnarReaderBatchSize> spark.sql.parquet.columnarReaderBatchSize<a class=headerlink href=#sparksqlparquetcolumnarreaderbatchsize title="Permanent link">&para;</a></h2> <p>The number of rows to include in a parquet vectorized reader batch (the capacity of <a href=../datasources/parquet/VectorizedParquetRecordReader/ >VectorizedParquetRecordReader</a>).</p> <p>Default: <code>4096</code> (4k)</p> <p>The number should be carefully chosen to minimize overhead and avoid OOMs while reading data.</p> <p>Use <a href=../SQLConf/#parquetVectorizedReaderBatchSize>SQLConf.parquetVectorizedReaderBatchSize</a> method to access the current value.</p> <h2 id=sparksqlparquetcompressioncodec><span id=spark.sql.parquet.compression.codec> spark.sql.parquet.compression.codec<a class=headerlink href=#sparksqlparquetcompressioncodec title="Permanent link">&para;</a></h2> <p>Sets the compression codec used when writing Parquet files. If either <code>compression</code> or <code>parquet.compression</code> is specified in the table-specific options/properties, the precedence would be <code>compression</code>, <code>parquet.compression</code>, <code>spark.sql.parquet.compression.codec</code>.</p> <p>Acceptable values:</p> <ul> <li><code>brotli</code></li> <li><code>gzip</code></li> <li><code>lz4</code></li> <li><code>lzo</code></li> <li><code>none</code></li> <li><code>snappy</code></li> <li><code>uncompressed</code></li> <li><code>zstd</code></li> </ul> <p>Default: <code>snappy</code></p> <p>Use <a href=../SQLConf/#parquetCompressionCodec>SQLConf.parquetCompressionCodec</a> method to access the current value.</p> <h2 id=sparksqlparquetenablevectorizedreader><span id=spark.sql.parquet.enableVectorizedReader> spark.sql.parquet.enableVectorizedReader<a class=headerlink href=#sparksqlparquetenablevectorizedreader title="Permanent link">&para;</a></h2> <p>Enables <a href=../vectorized-parquet-reader/ >vectorized parquet decoding</a>.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetVectorizedReaderEnabled>SQLConf.parquetVectorizedReaderEnabled</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdown><span id=spark.sql.parquet.filterPushdown> spark.sql.parquet.filterPushdown<a class=headerlink href=#sparksqlparquetfilterpushdown title="Permanent link">&para;</a></h2> <p>Controls the <a href=../logical-optimizations/PushDownPredicate/ >filter predicate push-down optimization</a> for data sources using <a href=../datasources/parquet/ParquetFileFormat/ >parquet</a> file format</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDown>SQLConf.parquetFilterPushDown</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdowndate><span id=spark.sql.parquet.filterPushdown.date> spark.sql.parquet.filterPushdown.date<a class=headerlink href=#sparksqlparquetfilterpushdowndate title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>Date</code> type (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownDate>SQLConf.parquetFilterPushDownDate</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdowndecimal><span id=spark.sql.parquet.filterPushdown.decimal> spark.sql.parquet.filterPushdown.decimal<a class=headerlink href=#sparksqlparquetfilterpushdowndecimal title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>Decimal</code> type (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownDecimal>SQLConf.parquetFilterPushDownDecimal</a> method to access the current value.</p> <h2 id=sparksqlparquetint96rebasemodeinwrite><span id=spark.sql.parquet.int96RebaseModeInWrite> spark.sql.parquet.int96RebaseModeInWrite<a class=headerlink href=#sparksqlparquetint96rebasemodeinwrite title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables rebasing timestamps while writing Parquet files</p> <p>Formerly known as <a href=#spark.sql.legacy.parquet.int96RebaseModeInWrite>spark.sql.legacy.parquet.int96RebaseModeInWrite</a></p> <p>Acceptable values:</p> <ul> <li><code>EXCEPTION</code> - Fail writing parquet files if there are ancient timestamps that are ambiguous between the two calendars</li> <li><code>LEGACY</code> - Rebase <code>INT96</code> timestamps from Proleptic Gregorian calendar to the legacy hybrid (Julian + Gregorian) calendar (gives maximum interoperability)</li> <li><code>CORRECTED</code> - Write datetime values with no change (<em>rabase</em>). Only when you are 100% sure that the written files will only be read by Spark 3.0+ or other systems that use Proleptic Gregorian calendar</li> </ul> <p>Default: <code>EXCEPTION</code></p> <p>Writing dates before <code>1582-10-15</code> or timestamps before <code>1900-01-01T00:00:00Z</code> can be dangerous, as the files may be read by Spark 2.x or legacy versions of Hive later, which uses a legacy hybrid calendar that is different from Spark 3.0+'s Proleptic Gregorian calendar.</p> <p>See more details in SPARK-31404.</p> <h2 id=sparksqlparquetpushdowninfilterthreshold><span id=spark.sql.parquet.pushdown.inFilterThreshold> spark.sql.parquet.pushdown.inFilterThreshold<a class=headerlink href=#sparksqlparquetpushdowninfilterthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> For IN predicate, Parquet filter will push-down a set of OR clauses if its number of values not exceeds this threshold. Otherwise, Parquet filter will push-down a value greater than or equal to its minimum value and less than or equal to its maximum value (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Disabled when <code>0</code></p> <p>Default: <code>10</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownInFilterThreshold>SQLConf.parquetFilterPushDownInFilterThreshold</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdownstringstartswith><span id=spark.sql.parquet.filterPushdown.string.startsWith> spark.sql.parquet.filterPushdown.string.startsWith<a class=headerlink href=#sparksqlparquetfilterpushdownstringstartswith title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>startsWith</code> function (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownStringStartWith>SQLConf.parquetFilterPushDownStringStartWith</a> method to access the current value.</p> <h2 id=sparksqlparquetfilterpushdowntimestamp><span id=spark.sql.parquet.filterPushdown.timestamp> spark.sql.parquet.filterPushdown.timestamp<a class=headerlink href=#sparksqlparquetfilterpushdowntimestamp title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parquet filter push-down optimization for <code>Timestamp</code> type. It can only have an effect when the following hold:</p> <ol> <li><a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled</li> <li><code>Timestamp</code> stored as <code>TIMESTAMP_MICROS</code> or <code>TIMESTAMP_MILLIS</code> type</li> </ol> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parquetFilterPushDownTimestamp>SQLConf.parquetFilterPushDownTimestamp</a> method to access the current value.</p> <h2 id=sparksqlparquetint96astimestamp><span id=spark.sql.parquet.int96AsTimestamp> spark.sql.parquet.int96AsTimestamp<a class=headerlink href=#sparksqlparquetint96astimestamp title="Permanent link">&para;</a></h2> <p>Some Parquet-producing systems, in particular Impala, store Timestamp into INT96. Spark would also store Timestamp as INT96 because we need to avoid precision lost of the nanoseconds field. This flag tells Spark SQL to interpret INT96 data as a timestamp to provide compatibility with these systems.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#isParquetINT96AsTimestamp>SQLConf.isParquetINT96AsTimestamp</a> method to access the current value.</p> <h2 id=sparksqlparquetint96timestampconversion><span id=spark.sql.parquet.int96TimestampConversion> spark.sql.parquet.int96TimestampConversion<a class=headerlink href=#sparksqlparquetint96timestampconversion title="Permanent link">&para;</a></h2> <p>Controls whether timestamp adjustments should be applied to INT96 data when converting to timestamps, for data written by Impala.</p> <p>Default: <code>false</code></p> <p>This is necessary because Impala stores INT96 data with a different timezone offset than Hive and Spark.</p> <p>Use <a href=../SQLConf/#isParquetINT96TimestampConversion>SQLConf.isParquetINT96TimestampConversion</a> method to access the current value.</p> <h2 id=sparksqlparquetmergeschema><span id=spark.sql.parquet.mergeSchema> spark.sql.parquet.mergeSchema<a class=headerlink href=#sparksqlparquetmergeschema title="Permanent link">&para;</a></h2> <p>Controls whether the Parquet data source merges schemas collected from all data files or not. If <code>false</code>, the schema is picked from the summary file or a random data file if no summary file is available.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#isParquetSchemaMergingEnabled>SQLConf.isParquetSchemaMergingEnabled</a> method to access the current value.</p> <h2 id=sparksqlparquetoutputcommitterclass><span id=spark.sql.parquet.output.committer.class> spark.sql.parquet.output.committer.class<a class=headerlink href=#sparksqlparquetoutputcommitterclass title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The output committer class used by <a href=../datasources/parquet/ >parquet</a> data source. The specified class needs to be a subclass of <code>org.apache.hadoop.mapreduce.OutputCommitter</code>. Typically, it's also a subclass of <code>org.apache.parquet.hadoop.ParquetOutputCommitter</code>. If it is not, then metadata summaries will never be created, irrespective of the value of <code>parquet.summary.metadata.level</code>.</p> <p>Default: <code>org.apache.parquet.hadoop.ParquetOutputCommitter</code></p> <p>Use <a href=../SQLConf/#parquetOutputCommitterClass>SQLConf.parquetOutputCommitterClass</a> method to access the current value.</p> <h2 id=sparksqlparquetoutputtimestamptype><span id=spark.sql.parquet.outputTimestampType> spark.sql.parquet.outputTimestampType<a class=headerlink href=#sparksqlparquetoutputtimestamptype title="Permanent link">&para;</a></h2> <p>Sets which Parquet timestamp type to use when Spark writes data to Parquet files. INT96 is a non-standard but commonly used timestamp type in Parquet. TIMESTAMP_MICROS is a standard timestamp type in Parquet, which stores number of microseconds from the Unix epoch. TIMESTAMP_MILLIS is also standard, but with millisecond precision, which means Spark has to truncate the microsecond portion of its timestamp value.</p> <p>Acceptable values:</p> <ul> <li><code>INT96</code></li> <li><code>TIMESTAMP_MICROS</code></li> <li><code>TIMESTAMP_MILLIS</code></li> </ul> <p>Default: <code>INT96</code></p> <p>Use <a href=../SQLConf/#parquetOutputTimestampType>SQLConf.parquetOutputTimestampType</a> method to access the current value.</p> <h2 id=sparksqlparquetrecordlevelfilterenabled><span id=spark.sql.parquet.recordLevelFilter.enabled> spark.sql.parquet.recordLevelFilter.enabled<a class=headerlink href=#sparksqlparquetrecordlevelfilterenabled title="Permanent link">&para;</a></h2> <p>Enables Parquet's native record-level filtering using the pushed down filters (when <a href=#spark.sql.parquet.filterPushdown>spark.sql.parquet.filterPushdown</a> is enabled).</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#parquetRecordFilterEnabled>SQLConf.parquetRecordFilterEnabled</a> method to access the current value.</p> <h2 id=sparksqlparquetrespectsummaryfiles><span id=spark.sql.parquet.respectSummaryFiles> spark.sql.parquet.respectSummaryFiles<a class=headerlink href=#sparksqlparquetrespectsummaryfiles title="Permanent link">&para;</a></h2> <p>When true, we make assumption that all part-files of Parquet are consistent with summary files and we will ignore them when merging schema. Otherwise, if this is false, which is the default, we will merge all part-files. This should be considered as expert-only option, and shouldn't be enabled before knowing what it means exactly.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#isParquetSchemaRespectSummaries>SQLConf.isParquetSchemaRespectSummaries</a> method to access the current value.</p> <h2 id=sparksqlparserquotedregexcolumnnames><span id=spark.sql.parser.quotedRegexColumnNames> spark.sql.parser.quotedRegexColumnNames<a class=headerlink href=#sparksqlparserquotedregexcolumnnames title="Permanent link">&para;</a></h2> <p>Controls whether quoted identifiers (using backticks) in SELECT statements should be interpreted as regular expressions.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#supportQuotedRegexColumnName>SQLConf.supportQuotedRegexColumnName</a> method to access the current value.</p> <h2 id=sparksqlpivotmaxvalues><span id=spark.sql.pivotMaxValues> spark.sql.pivotMaxValues<a class=headerlink href=#sparksqlpivotmaxvalues title="Permanent link">&para;</a></h2> <p>Maximum number of (distinct) values that will be collected without error (when doing a <a href=../basic-aggregation/RelationalGroupedDataset/#pivot>pivot</a> without specifying the values for the pivot column)</p> <p>Default: <code>10000</code></p> <p>Use <a href=../SQLConf/#dataFramePivotMaxValues>SQLConf.dataFramePivotMaxValues</a> method to access the current value.</p> <h2 id=sparksqlredactionoptionsregex><span id=spark.sql.redaction.options.regex> spark.sql.redaction.options.regex<a class=headerlink href=#sparksqlredactionoptionsregex title="Permanent link">&para;</a></h2> <p>Regular expression to find options of a Spark SQL command with sensitive information</p> <p>Default: <code>(?i)secret!password</code></p> <p>The values of the options matched will be redacted in the explain output.</p> <p>This redaction is applied on top of the global redaction configuration defined by <code>spark.redaction.regex</code> configuration.</p> <p>Used exclusively when <code>SQLConf</code> is requested to <a href=../SQLConf/#redactOptions>redactOptions</a>.</p> <h2 id=sparksqlredactionstringregex><span id=spark.sql.redaction.string.regex> spark.sql.redaction.string.regex<a class=headerlink href=#sparksqlredactionstringregex title="Permanent link">&para;</a></h2> <p>Regular expression to point at sensitive information in text output</p> <p>Default: <code>(undefined)</code></p> <p>When this regex matches a string part, it is replaced by a dummy value (i.e. <code>*********(redacted)</code>). This is currently used to redact the output of SQL explain commands.</p> <p>NOTE: When this conf is not set, the value of <code>spark.redaction.string.regex</code> is used instead.</p> <p>Use <a href=../SQLConf/#stringRedactionPattern>SQLConf.stringRedactionPattern</a> method to access the current value.</p> <h2 id=sparksqlretaingroupcolumns><span id=spark.sql.retainGroupColumns> spark.sql.retainGroupColumns<a class=headerlink href=#sparksqlretaingroupcolumns title="Permanent link">&para;</a></h2> <p>Controls whether to retain columns used for aggregation or not (in <a href=../basic-aggregation/RelationalGroupedDataset/ >RelationalGroupedDataset</a> operators).</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#dataFrameRetainGroupColumns>SQLConf.dataFrameRetainGroupColumns</a> method to access the current value.</p> <h2 id=sparksqlrunsqlonfiles><span id=spark.sql.runSQLOnFiles> spark.sql.runSQLOnFiles<a class=headerlink href=#sparksqlrunsqlonfiles title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether Spark SQL could use <code>datasource</code>.<code>path</code> as a table in a SQL query.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#runSQLonFile>SQLConf.runSQLonFile</a> method to access the current value.</p> <h2 id=sparksqlselfjoinautoresolveambiguity><span id=spark.sql.selfJoinAutoResolveAmbiguity> spark.sql.selfJoinAutoResolveAmbiguity<a class=headerlink href=#sparksqlselfjoinautoresolveambiguity title="Permanent link">&para;</a></h2> <p>Controls whether to resolve ambiguity in join conditions for <a href=../joins/#join>self-joins</a> automatically (<code>true</code>) or not (<code>false</code>)</p> <p>Default: <code>true</code></p> <h2 id=sparksqlsortenableradixsort><span id=spark.sql.sort.enableRadixSort> spark.sql.sort.enableRadixSort<a class=headerlink href=#sparksqlsortenableradixsort title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Controls whether to use radix sort (<code>true</code>) or not (<code>false</code>) in <a href=../physical-operators/ShuffleExchangeExec/ >ShuffleExchangeExec</a> and <a href=../physical-operators/SortExec/ >SortExec</a> physical operators</p> <p>Default: <code>true</code></p> <p>Radix sort is much faster but requires additional memory to be reserved up-front. The memory overhead may be significant when sorting very small rows (up to 50% more).</p> <p>Use <a href=../SQLConf/#enableRadixSort>SQLConf.enableRadixSort</a> method to access the current value.</p> <h2 id=sparksqlsourcesbucketingenabled><span id=spark.sql.sources.bucketing.enabled> spark.sql.sources.bucketing.enabled<a class=headerlink href=#sparksqlsourcesbucketingenabled title="Permanent link">&para;</a></h2> <p>Enables <a href=../bucketing/ >bucketing</a> support. When disabled (i.e. <code>false</code>), bucketed tables are considered regular (non-bucketed) tables.</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#bucketingEnabled>SQLConf.bucketingEnabled</a> method to access the current value.</p> <h2 id=sparksqlsourcesdefault><span id=spark.sql.sources.default><span id=DEFAULT_DATA_SOURCE_NAME> spark.sql.sources.default<a class=headerlink href=#sparksqlsourcesdefault title="Permanent link">&para;</a></h2> <p>Default data source to use for loading or saving data</p> <p>Default: <a href=../datasources/parquet/ >parquet</a></p> <p>Use <a href=../SQLConf/#defaultDataSourceName>SQLConf.defaultDataSourceName</a> method to access the current value.</p> <h2 id=sparksqlstatisticsfallbacktohdfs><span id=spark.sql.statistics.fallBackToHdfs> spark.sql.statistics.fallBackToHdfs<a class=headerlink href=#sparksqlstatisticsfallbacktohdfs title="Permanent link">&para;</a></h2> <p>Enables automatic calculation of table size statistic by falling back to HDFS if the table statistics are not available from table metadata.</p> <p>Default: <code>false</code></p> <p>This can be useful in determining if a table is small enough for auto broadcast joins in query planning.</p> <p>Use <a href=../SQLConf/#fallBackToHdfsForStatsEnabled>SQLConf.fallBackToHdfsForStatsEnabled</a> method to access the current value.</p> <h2 id=sparksqlstatisticshistogramnumbins><span id=spark.sql.statistics.histogram.numBins> spark.sql.statistics.histogram.numBins<a class=headerlink href=#sparksqlstatisticshistogramnumbins title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The number of bins when generating histograms.</p> <p>Default: <code>254</code></p> <p>NOTE: The number of bins must be greater than 1.</p> <p>Use <a href=../SQLConf/#histogramNumBins>SQLConf.histogramNumBins</a> method to access the current value.</p> <h2 id=sparksqlstatisticsparallelfilelistinginstatscomputationenabled><span id=spark.sql.statistics.parallelFileListingInStatsComputation.enabled> spark.sql.statisticsparallelFileListingInStatsComputation.enabled*<a class=headerlink href=#sparksqlstatisticsparallelfilelistinginstatscomputationenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables parallel file listing in SQL commands, e.g. <code>ANALYZE TABLE</code> (as opposed to single thread listing that can be particularly slow with tables with hundreds of partitions)</p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#parallelFileListingInStatsComputation>SQLConf.parallelFileListingInStatsComputation</a> method to access the current value.</p> <h2 id=sparksqlstatisticsndvmaxerror><span id=spark.sql.statistics.ndv.maxError> spark.sql.statistics.ndv.maxError<a class=headerlink href=#sparksqlstatisticsndvmaxerror title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> The maximum estimation error allowed in HyperLogLog++ algorithm when generating column level statistics.</p> <p>Default: <code>0.05</code></p> <h2 id=sparksqlstatisticspercentileaccuracy><span id=spark.sql.statistics.percentile.accuracy> spark.sql.statistics.percentile.accuracy<a class=headerlink href=#sparksqlstatisticspercentileaccuracy title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Accuracy of percentile approximation when generating equi-height histograms. Larger value means better accuracy. The relative error can be deduced by 1.0 / PERCENTILE_ACCURACY.</p> <p>Default: <code>10000</code></p> <h2 id=sparksqlstatisticssizeautoupdateenabled><span id=spark.sql.statistics.size.autoUpdate.enabled> spark.sql.statistics.size.autoUpdate.enabled<a class=headerlink href=#sparksqlstatisticssizeautoupdateenabled title="Permanent link">&para;</a></h2> <p>Enables automatic update of the table size statistic of a table after the table has changed.</p> <p>Default: <code>false</code></p> <p>IMPORTANT: If the total number of files of the table is very large this can be expensive and slow down data change commands.</p> <p>Use <a href=../SQLConf/#autoSizeUpdateEnabled>SQLConf.autoSizeUpdateEnabled</a> method to access the current value.</p> <h2 id=sparksqlsubexpressioneliminationenabled><span id=spark.sql.subexpressionElimination.enabled> spark.sql.subexpressionElimination.enabled<a class=headerlink href=#sparksqlsubexpressioneliminationenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Enables <a href=../subexpression-elimination/ >Subexpression Elimination</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#subexpressionEliminationEnabled>SQLConf.subexpressionEliminationEnabled</a> method to access the current value.</p> <h2 id=sparksqlshufflepartitions><span id=spark.sql.shuffle.partitions> spark.sql.shuffle.partitions<a class=headerlink href=#sparksqlshufflepartitions title="Permanent link">&para;</a></h2> <p>The default number of partitions to use when shuffling data for joins or aggregations.</p> <p>Default: <code>200</code></p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>Corresponds to Apache Hive's <a href=https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-mapred.reduce.tasks>mapred.reduce.tasks</a> property that Spark SQL considers deprecated.</p> </div> <div class="admonition note"> <p class=admonition-title>Spark Structured Streaming</p> <p><code>spark.sql.shuffle.partitions</code> cannot be changed in Spark Structured Streaming between query restarts from the same checkpoint location.</p> </div> <p>Use <a href=../SQLConf/#numShufflePartitions>SQLConf.numShufflePartitions</a> method to access the current value.</p> <h2 id=sparksqlsourcesfilecompressionfactor><span id=spark.sql.sources.fileCompressionFactor> spark.sql.sources.fileCompressionFactor<a class=headerlink href=#sparksqlsourcesfilecompressionfactor title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> When estimating the output data size of a table scan, multiply the file size with this factor as the estimated data size, in case the data is compressed in the file and lead to a heavily underestimated result.</p> <p>Default: <code>1.0</code></p> <p>Use <a href=../SQLConf/#fileCompressionFactor>SQLConf.fileCompressionFactor</a> method to access the current value.</p> <h2 id=sparksqlsourcespartitionoverwritemode><span id=spark.sql.sources.partitionOverwriteMode> spark.sql.sources.partitionOverwriteMode<a class=headerlink href=#sparksqlsourcespartitionoverwritemode title="Permanent link">&para;</a></h2> <p>Enables <a href=../dynamic-partition-inserts/ >dynamic partition inserts</a> when <code>dynamic</code></p> <p>Default: <code>static</code></p> <p>When <code>INSERT OVERWRITE</code> a partitioned data source table with dynamic partition columns, Spark SQL supports two modes (case-insensitive):</p> <ul> <li> <p><strong>static</strong> - Spark deletes all the partitions that match the partition specification (e.g. <code>PARTITION(a=1,b)</code>) in the INSERT statement, before overwriting</p> </li> <li> <p><strong>dynamic</strong> - Spark doesn't delete partitions ahead, and only overwrites those partitions that have data written into it</p> </li> </ul> <p>The default <code>STATIC</code> overwrite mode is to keep the same behavior of Spark prior to 2.3. Note that this config doesn't affect Hive serde tables, as they are always overwritten with dynamic mode.</p> <p>Use <a href=../SQLConf/#partitionOverwriteMode>SQLConf.partitionOverwriteMode</a> method to access the current value.</p> <h2 id=sparksqltruncatetableignorepermissionaclenabled><span id=spark.sql.truncateTable.ignorePermissionAcl.enabled> spark.sql.truncateTable.ignorePermissionAcl.enabled<a class=headerlink href=#sparksqltruncatetableignorepermissionaclenabled title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Disables setting back original permission and ACLs when re-creating the table/partition paths for <a href=../logical-operators/TruncateTableCommand/ >TRUNCATE TABLE</a> command.</p> <p>Default: <code>false</code></p> <p>Use <a href=../SQLConf/#truncateTableIgnorePermissionAcl>SQLConf.truncateTableIgnorePermissionAcl</a> method to access the current value.</p> <h2 id=sparksqluiretainedexecutions><span id=spark.sql.ui.retainedExecutions> spark.sql.ui.retainedExecutions<a class=headerlink href=#sparksqluiretainedexecutions title="Permanent link">&para;</a></h2> <p>Number of <code>SQLExecutionUIData</code>s to keep in <code>failedExecutions</code> and <code>completedExecutions</code> internal registries.</p> <p>Default: <code>1000</code></p> <p>When a query execution finishes, the execution is removed from the internal <code>activeExecutions</code> registry and stored in <code>failedExecutions</code> or <code>completedExecutions</code> given the end execution status. It is when <code>SQLListener</code> makes sure that the number of <code>SQLExecutionUIData</code> entires does not exceed <code>spark.sql.ui.retainedExecutions</code> Spark property and removes the excess of entries.</p> <h2 id=sparksqlvariablesubstitute><span id=spark.sql.variable.substitute> spark.sql.variable.substitute<a class=headerlink href=#sparksqlvariablesubstitute title="Permanent link">&para;</a></h2> <p>Enables <a href=../variable-substitution/ >Variable Substitution</a></p> <p>Default: <code>true</code></p> <p>Use <a href=../SQLConf/#variableSubstituteEnabled>SQLConf.variableSubstituteEnabled</a> method to access the current value.</p> <h2 id=sparksqlwindowexecbufferinmemorythreshold><span id=spark.sql.windowExec.buffer.in.memory.threshold> spark.sql.windowExec.buffer.in.memory.threshold<a class=headerlink href=#sparksqlwindowexecbufferinmemorythreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Threshold for number of rows guaranteed to be held in memory by <a href=../physical-operators/WindowExec/ >WindowExec</a> physical operator.</p> <p>Default: <code>4096</code></p> <p>Use <a href=../SQLConf/#windowExecBufferInMemoryThreshold>SQLConf.windowExecBufferInMemoryThreshold</a> method to access the current value.</p> <h2 id=sparksqlwindowexecbufferspillthreshold><span id=spark.sql.windowExec.buffer.spill.threshold> spark.sql.windowExec.buffer.spill.threshold<a class=headerlink href=#sparksqlwindowexecbufferspillthreshold title="Permanent link">&para;</a></h2> <p><strong>(internal)</strong> Threshold for number of rows buffered in a <a href=../physical-operators/WindowExec/ >WindowExec</a> physical operator.</p> <p>Default: <code>4096</code></p> <p>Use <a href=../SQLConf/#windowExecBufferSpillThreshold>SQLConf.windowExecBufferSpillThreshold</a> method to access the current value.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <a href=# class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </a> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2023 Jacek Laskowski </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs Insiders </a> </div> <div class=md-social> <a href=https://github.com/jaceklaskowski target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> <a href=https://twitter.com/jaceklaskowski target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://linkedin.com/in/jaceklaskowski target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg> </a> <a href=https://jaceklaskowski.medium.com target=_blank rel=noopener title=jaceklaskowski.medium.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M180.5 74.262C80.813 74.262 0 155.633 0 256s80.819 181.738 180.5 181.738S361 356.373 361 256 280.191 74.262 180.5 74.262Zm288.25 10.646c-49.845 0-90.245 76.619-90.245 171.095s40.406 171.1 90.251 171.1 90.251-76.619 90.251-171.1H559c0-94.503-40.4-171.095-90.248-171.095Zm139.506 17.821c-17.526 0-31.735 68.628-31.735 153.274s14.2 153.274 31.735 153.274S640 340.631 640 256c0-84.649-14.215-153.271-31.742-153.271Z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["content.code.annotate", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../assets/javascripts/workers/search.f236eb64.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../assets/javascripts/bundle.abfe3e55.min.js></script> </body> </html>