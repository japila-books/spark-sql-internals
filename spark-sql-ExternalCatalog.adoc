== [[ExternalCatalog]] ExternalCatalog -- Base Metastore of Permanent Relational Entities

`ExternalCatalog` is the <<contract, contract>> of an *external system catalog* (aka _registry_ or _metastore_) of permanent relational entities, i.e. databases, tables, partitions, and functions.

[[features]]
.ExternalCatalog Features per Relational Entity
[cols="2,^1,^1,^1,^1",options="header",width="100%"]
|===
| Feature
| Function
| Partitions
| Tables
| Databases

| Create
| X
| X
| X
| [[createDatabase]] X

| Drop | X | X | X | X
| Rename | X | X | X |

| Get
| X
| [[getPartition]][[getPartitionOption]] X
| [[getTable]] X
|

| Check Existence | X | | X | X

| Alter
|
| [[alterPartitions]] X
| X
| X

| List
| [[listFunctions]] X
| [[listPartitions]][[listPartitionNames]][[listPartitionsByFilter]] X
| [[listTables]] X
| [[listDatabases]] X

| Load | | X | X | X
| Set | | | | X
|===

`ExternalCatalog` is available as link:spark-sql-SharedState.adoc#externalCatalog[externalCatalog] of link:spark-sql-SparkSession.adoc#sharedState[SharedState] (in `SparkSession`).

[source, scala]
----
scala> spark.version
res0: String = 2.3.0-SNAPSHOT

scala> :type spark
org.apache.spark.sql.SparkSession

scala> :type spark.sharedState.externalCatalog
org.apache.spark.sql.catalyst.catalog.ExternalCatalog
----

[[implementations]]
.ExternalCatalogs
[cols="1,2,2",options="header",width="100%"]
|===
| ExternalCatalog
| Alias
| Description

| link:spark-sql-InMemoryCatalog.adoc[InMemoryCatalog]
| [[in-memory]] `in-memory`
| An in-memory (ephemeral) system catalog

| link:spark-sql-HiveExternalCatalog.adoc[HiveExternalCatalog]
| [[hive]] `hive`
|
|===

`ExternalCatalog` is selected using link:spark-sql-StaticSQLConf.adoc#spark.sql.catalogImplementation[spark.sql.catalogImplementation] configuration property and can never be changed (after the first `SparkSession` has been created).

[source, scala]
----
scala> spark.version
res0: String = 2.3.0-SNAPSHOT

import org.apache.spark.sql.internal.StaticSQLConf
scala> spark.conf.get(StaticSQLConf.CATALOG_IMPLEMENTATION.key)
res1: String = hive
----

[IMPORTANT]
====
You cannot change `ExternalCatalog` after `SparkSession` has been created using link:spark-sql-StaticSQLConf.adoc#spark.sql.catalogImplementation[spark.sql.catalogImplementation] configuration property as it is a static configuration.

[source, scala]
----
import org.apache.spark.sql.internal.StaticSQLConf
scala> spark.conf.set(StaticSQLConf.CATALOG_IMPLEMENTATION.key, "hive")
org.apache.spark.sql.AnalysisException: Cannot modify the value of a static config: spark.sql.catalogImplementation;
  at org.apache.spark.sql.RuntimeConfig.requireNonStaticConf(RuntimeConfig.scala:144)
  at org.apache.spark.sql.RuntimeConfig.set(RuntimeConfig.scala:41)
  ... 49 elided
----
====

[[addListener]]
`ExternalCatalog` is a `ListenerBus` of `ExternalCatalogEventListener` listeners that handle `ExternalCatalogEvent` events.

TIP: Use `addListener` and `removeListener` to register and de-register `ExternalCatalogEventListener` listeners, accordingly.

TIP: Read https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-SparkListenerBus.html#ListenerBus[ListenerBus Event Bus Contract] in Mastering Apache Spark 2 gitbook to learn more on Spark Core's `ListenerBus`.

=== [[alterTableStats]] Altering Statistics of Table -- `alterTableStats` Method

[source, scala]
----
alterTableStats(db: String, table: String, stats: Option[CatalogStatistics]): Unit
----

`alterTableStats`...FIXME

NOTE: `alterTableStats` is used exclusively when `SessionCatalog` is requested for link:spark-sql-SessionCatalog.adoc#alterTableStats[altering the statistics of a table in a metastore].

=== [[alterTable]] Altering Table -- `alterTable` Method

[source, scala]
----
alterTable(tableDefinition: CatalogTable): Unit
----

`alterTable`...FIXME

NOTE: `alterTable` is used exclusively when `SessionCatalog` is requested for link:spark-sql-SessionCatalog.adoc#alterTable[altering the statistics of a table in a metastore].

=== [[contract]] ExternalCatalog Contract

[source, scala]
----
package org.apache.spark.sql.catalyst.catalog

abstract class ExternalCatalog {
  // only required methods that have no implementation
  def databaseExists(db: String): Boolean
  // FIXME The other methods
}
----

.(Subset of) ExternalCatalog Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[databaseExists]] `databaseExists`
| Used when...FIXME
|===

=== [[doAlterTableStats]] Altering Table Statistics -- `doAlterTableStats` Method

[source, scala]
----
doAlterTableStats(db: String, table: String, stats: Option[CatalogStatistics]): Unit
----

NOTE: `doAlterTableStats` is used exclusively when `ExternalCatalog` is requested to <<alterTableStats, alter the statistics of a table>>.

=== [[doAlterTable]] Altering Table -- `doAlterTable` Method

[source, scala]
----
doAlterTable(tableDefinition: CatalogTable): Unit
----

NOTE: `doAlterTable` is used exclusively when `ExternalCatalog` is requested to <<alterTable, alter a table>>.
