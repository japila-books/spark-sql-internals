== [[CodegenContext]] CodegenContext

`CodegenContext` is...FIXME

[[creating-instance]]
`CodegenContext` takes no input parameters.

[source, scala]
----
import org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext
val ctx = new CodegenContext
----

`CodegenContext` is <<creating-instance, created>> when:

1. `CodeGenerator` is requested for link:spark-sql-CodeGenerator.adoc#newCodeGenContext[one]

1. `WholeStageCodegenExec` is requested to link:spark-sql-SparkPlan-WholeStageCodegenExec.adoc#doCodeGen[generate a Java source code for a child subtree]

1. `GenerateUnsafeRowJoiner` is requested for a `UnsafeRowJoiner`

`CodegenContext` stores expressions that don't support codegen.

.Example of CodegenContext.subexpressionElimination (through CodegenContext.generateExpressions)
[source, scala]
----
import org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext
val ctx = new CodegenContext

// Use Catalyst DSL
import org.apache.spark.sql.catalyst.dsl.expressions._
val expressions = "hello".expr.as("world") :: "hello".expr.as("world") :: Nil

// FIXME Use a real-life query to extract the expressions

// Note the doSubexpressionElimination flag is on
// Triggers the subexpressionElimination private method
ctx.generateExpressions(expressions, doSubexpressionElimination = true)

// subexpressionElimination private method uses ctx.equivalentExpressions
val commonExprs = ctx.equivalentExpressions.getAllEquivalentExprs

assert(commonExprs.length > 0, "No common expressions found")
----

[[internal-registries]]
.CodegenContext's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[equivalentExpressions]] `equivalentExpressions`
a| link:spark-sql-EquivalentExpressions.adoc[EquivalentExpressions]

Expressions are link:spark-sql-EquivalentExpressions.adoc#addExprTree[added] and then link:spark-sql-EquivalentExpressions.adoc#getAllEquivalentExprs[fetched as equivalent sets] when `CodegenContext` is requested to <<subexpressionElimination, subexpressionElimination>> (for <<generateExpressions, generateExpressions>> with link:spark-sql-subexpression-elimination.adoc#spark.sql.subexpressionElimination.enabled[subexpression elimination] enabled)

| [[subExprEliminationExprs]] `subExprEliminationExprs`
| `SubExprEliminationStates` by link:spark-sql-Expression.adoc[Expression]

Used when...FIXME

| [[subexprFunctions]] `subexprFunctions`
| Names of the functions that...FIXME
|===

=== [[generateExpressions]] `generateExpressions` Method

[source, scala]
----
generateExpressions(
  expressions: Seq[Expression],
  doSubexpressionElimination: Boolean = false): Seq[ExprCode]
----

(only with link:spark-sql-subexpression-elimination.adoc#spark.sql.subexpressionElimination.enabled[subexpression elimination] enabled) `generateExpressions` does <<subexpressionElimination, subexpressionElimination>> of the input `expressions`.

In the end, `generateExpressions` requests every expressions to link:spark-sql-Expression.adoc#genCode[generate the Java source code for code-generated (non-interpreted) expression evaluation].

[NOTE]
====
`generateExpressions` is used when:

1. `GenerateMutableProjection` is requested to link:spark-sql-GenerateMutableProjection.adoc#create[create a MutableProjection]

1. `GenerateUnsafeProjection` is requested to link:spark-sql-GenerateUnsafeProjection.adoc#createCode[create an ExprCode for Catalyst expressions]

1. `HashAggregateExec` is requested to link:spark-sql-SparkPlan-HashAggregateExec.adoc#doConsumeWithKeys[generate the Java source code for whole-stage consume path with grouping keys]
====

=== [[subexpressionEliminationForWholeStageCodegen]] `subexpressionEliminationForWholeStageCodegen` Method

[source, scala]
----
subexpressionEliminationForWholeStageCodegen(expressions: Seq[Expression]): SubExprCodes
----

`subexpressionEliminationForWholeStageCodegen`...FIXME

NOTE: `subexpressionEliminationForWholeStageCodegen` is used exclusively when `HashAggregateExec` is requested to link:spark-sql-SparkPlan-HashAggregateExec.adoc#doConsume[generate a Java source code for whole-stage consume path] (link:spark-sql-SparkPlan-HashAggregateExec.adoc#doConsumeWithKeys[with grouping keys] or link:spark-sql-SparkPlan-HashAggregateExec.adoc#doConsumeWithoutKeys[not]).

=== [[addNewFunction]] `addNewFunction` Method

[source, scala]
----
addNewFunction(
  funcName: String,
  funcCode: String,
  inlineToOuterClass: Boolean = false): String
----

`addNewFunction`...FIXME

NOTE: `addNewFunction` is used when...FIXME

=== [[subexpressionElimination]] `subexpressionElimination` Internal Method

[source, scala]
----
subexpressionElimination(expressions: Seq[Expression]): Unit
----

`subexpressionElimination` requests <<equivalentExpressions, EquivalentExpressions>> to link:spark-sql-EquivalentExpressions.adoc#addExprTree[addExprTree] for every expression (in the input `expressions`).

`subexpressionElimination` requests <<equivalentExpressions, EquivalentExpressions>> for the link:spark-sql-EquivalentExpressions.adoc#getAllEquivalentExprs[equivalent sets of expressions] with at least two equivalent expressions (aka _common expressions_).

For every equivalent expression set, `subexpressionElimination` does the following:

1. Takes the first expression and requests it to link:spark-sql-Expression.adoc#genCode[generate a Java source code] for the expression tree

1. <<addNewFunction, addNewFunction>> and adds it to <<subexprFunctions, subexprFunctions>>

1. Creates a `SubExprEliminationState` and adds it with every common expression in the equivalent expression set to <<subExprEliminationExprs, subExprEliminationExprs>>

NOTE: `subexpressionElimination` is used exclusively when `CodegenContext` is requested to <<generateExpressions, generateExpressions>> (with link:spark-sql-subexpression-elimination.adoc#spark.sql.subexpressionElimination.enabled[subexpression elimination] enabled).
